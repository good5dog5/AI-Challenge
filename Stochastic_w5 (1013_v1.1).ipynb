{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "train_ini_00 = pd.read_csv(\"./stock_train_data_20171006.csv\", sep=',', delimiter=None)\n",
    "test_ini_00 = pd.read_csv(\"./stock_test_data_20171006.csv\", sep=',', delimiter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 僅限於week5 使用(column['feature77'] = 0.5)"
   ]
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 僅限於week5 使用(column['feature77'] = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ini_00['feature77'] = 0.5\n",
    "test_ini_00['feature77'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train_ini=train_ini_00.copy(deep=True)\n",
    "test_ini=test_ini_00.copy(deep=True)\n",
    "\n",
    "for i in range(1,89,1):\n",
    "    train_ini.iloc[:,i]=preprocessing.scale(train_ini_00.iloc[:,i])\n",
    "    test_ini.iloc[:,i]=preprocessing.scale(test_ini_00.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature79</th>\n",
       "      <th>feature80</th>\n",
       "      <th>feature81</th>\n",
       "      <th>feature82</th>\n",
       "      <th>feature83</th>\n",
       "      <th>feature84</th>\n",
       "      <th>feature85</th>\n",
       "      <th>feature86</th>\n",
       "      <th>feature87</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392418</td>\n",
       "      <td>0.088970</td>\n",
       "      <td>-0.012451</td>\n",
       "      <td>0.226408</td>\n",
       "      <td>-1.386858</td>\n",
       "      <td>-1.066616</td>\n",
       "      <td>0.636430</td>\n",
       "      <td>-0.805733</td>\n",
       "      <td>-0.478093</td>\n",
       "      <td>-0.536539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785307</td>\n",
       "      <td>-0.491378</td>\n",
       "      <td>-0.291151</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>-0.807633</td>\n",
       "      <td>-0.394544</td>\n",
       "      <td>-0.681540</td>\n",
       "      <td>-0.707518</td>\n",
       "      <td>-0.775872</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392419</td>\n",
       "      <td>-1.004904</td>\n",
       "      <td>-0.034484</td>\n",
       "      <td>-0.345187</td>\n",
       "      <td>0.179278</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.752589</td>\n",
       "      <td>2.233694</td>\n",
       "      <td>0.651315</td>\n",
       "      <td>1.896860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079682</td>\n",
       "      <td>1.490679</td>\n",
       "      <td>-0.082252</td>\n",
       "      <td>-1.079956</td>\n",
       "      <td>1.607502</td>\n",
       "      <td>-1.805872</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>-0.108615</td>\n",
       "      <td>1.492027</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392420</td>\n",
       "      <td>1.100924</td>\n",
       "      <td>-0.023984</td>\n",
       "      <td>-0.329857</td>\n",
       "      <td>0.661071</td>\n",
       "      <td>1.076176</td>\n",
       "      <td>0.414028</td>\n",
       "      <td>0.194951</td>\n",
       "      <td>0.833402</td>\n",
       "      <td>0.778437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.596572</td>\n",
       "      <td>0.640618</td>\n",
       "      <td>1.219347</td>\n",
       "      <td>-1.060589</td>\n",
       "      <td>0.290406</td>\n",
       "      <td>0.772820</td>\n",
       "      <td>1.368938</td>\n",
       "      <td>1.088984</td>\n",
       "      <td>-0.433057</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>392421</td>\n",
       "      <td>0.939863</td>\n",
       "      <td>-0.018097</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>-1.418409</td>\n",
       "      <td>0.359216</td>\n",
       "      <td>-0.135353</td>\n",
       "      <td>-1.482310</td>\n",
       "      <td>-0.057569</td>\n",
       "      <td>0.169539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.516610</td>\n",
       "      <td>-0.260976</td>\n",
       "      <td>0.265216</td>\n",
       "      <td>1.133491</td>\n",
       "      <td>0.500493</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>-0.783961</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392422</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>-0.577442</td>\n",
       "      <td>-0.068010</td>\n",
       "      <td>-1.572975</td>\n",
       "      <td>-0.329777</td>\n",
       "      <td>0.267620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737593</td>\n",
       "      <td>0.037424</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.544575</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>-0.131309</td>\n",
       "      <td>-0.877661</td>\n",
       "      <td>0.461268</td>\n",
       "      <td>-0.238349</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>392423</td>\n",
       "      <td>0.837824</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.273588</td>\n",
       "      <td>1.056372</td>\n",
       "      <td>-0.230143</td>\n",
       "      <td>0.573043</td>\n",
       "      <td>0.645608</td>\n",
       "      <td>-0.483777</td>\n",
       "      <td>-0.217809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996371</td>\n",
       "      <td>-0.438168</td>\n",
       "      <td>0.167159</td>\n",
       "      <td>1.013741</td>\n",
       "      <td>-0.541207</td>\n",
       "      <td>-0.093378</td>\n",
       "      <td>-0.391347</td>\n",
       "      <td>0.692741</td>\n",
       "      <td>-0.636414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>392424</td>\n",
       "      <td>1.040767</td>\n",
       "      <td>-0.152174</td>\n",
       "      <td>0.344835</td>\n",
       "      <td>-0.737765</td>\n",
       "      <td>0.245411</td>\n",
       "      <td>1.330195</td>\n",
       "      <td>-0.122921</td>\n",
       "      <td>0.752297</td>\n",
       "      <td>0.385699</td>\n",
       "      <td>...</td>\n",
       "      <td>3.819098</td>\n",
       "      <td>1.698990</td>\n",
       "      <td>0.942540</td>\n",
       "      <td>-1.111067</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>1.077803</td>\n",
       "      <td>1.040696</td>\n",
       "      <td>2.926289</td>\n",
       "      <td>1.866744</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>392425</td>\n",
       "      <td>-0.699206</td>\n",
       "      <td>-0.035928</td>\n",
       "      <td>0.175071</td>\n",
       "      <td>-0.173649</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>0.419827</td>\n",
       "      <td>-0.073032</td>\n",
       "      <td>0.496059</td>\n",
       "      <td>-0.486717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748197</td>\n",
       "      <td>-0.190228</td>\n",
       "      <td>-0.558712</td>\n",
       "      <td>1.102890</td>\n",
       "      <td>-0.556398</td>\n",
       "      <td>0.783577</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>-0.633712</td>\n",
       "      <td>0.313645</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>392426</td>\n",
       "      <td>-1.250826</td>\n",
       "      <td>-0.018475</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-1.590578</td>\n",
       "      <td>-1.054722</td>\n",
       "      <td>-0.402337</td>\n",
       "      <td>0.551442</td>\n",
       "      <td>-1.204170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653698</td>\n",
       "      <td>-0.896002</td>\n",
       "      <td>-1.498425</td>\n",
       "      <td>0.071348</td>\n",
       "      <td>-0.934304</td>\n",
       "      <td>-2.766871</td>\n",
       "      <td>-0.817718</td>\n",
       "      <td>-0.609713</td>\n",
       "      <td>-0.771024</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>392427</td>\n",
       "      <td>1.069376</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.642103</td>\n",
       "      <td>0.213534</td>\n",
       "      <td>-0.151496</td>\n",
       "      <td>-0.172658</td>\n",
       "      <td>-0.396895</td>\n",
       "      <td>-0.149623</td>\n",
       "      <td>-0.384482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680009</td>\n",
       "      <td>0.175432</td>\n",
       "      <td>-0.185755</td>\n",
       "      <td>-0.756882</td>\n",
       "      <td>-0.433311</td>\n",
       "      <td>0.301302</td>\n",
       "      <td>0.215193</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>392428</td>\n",
       "      <td>-0.917364</td>\n",
       "      <td>-0.118647</td>\n",
       "      <td>-0.285822</td>\n",
       "      <td>0.533232</td>\n",
       "      <td>-0.187045</td>\n",
       "      <td>-0.718213</td>\n",
       "      <td>-1.453297</td>\n",
       "      <td>0.059654</td>\n",
       "      <td>-0.444266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079491</td>\n",
       "      <td>-0.538677</td>\n",
       "      <td>-0.726547</td>\n",
       "      <td>0.533653</td>\n",
       "      <td>-0.352214</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-0.554619</td>\n",
       "      <td>-0.170540</td>\n",
       "      <td>-0.312947</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>392429</td>\n",
       "      <td>-0.713333</td>\n",
       "      <td>-0.103237</td>\n",
       "      <td>-0.571024</td>\n",
       "      <td>0.984154</td>\n",
       "      <td>0.525436</td>\n",
       "      <td>0.782510</td>\n",
       "      <td>-0.287802</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>0.990423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327812</td>\n",
       "      <td>0.662191</td>\n",
       "      <td>0.897151</td>\n",
       "      <td>-0.068489</td>\n",
       "      <td>0.541205</td>\n",
       "      <td>-0.984759</td>\n",
       "      <td>-0.007678</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.218440</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>392430</td>\n",
       "      <td>-1.046641</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.243694</td>\n",
       "      <td>1.692588</td>\n",
       "      <td>1.320556</td>\n",
       "      <td>-0.212556</td>\n",
       "      <td>-1.111035</td>\n",
       "      <td>-0.062676</td>\n",
       "      <td>-0.542785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365200</td>\n",
       "      <td>-0.742857</td>\n",
       "      <td>-0.958454</td>\n",
       "      <td>1.056052</td>\n",
       "      <td>-0.698245</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>-0.373747</td>\n",
       "      <td>-0.296632</td>\n",
       "      <td>0.157238</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>392431</td>\n",
       "      <td>-1.328634</td>\n",
       "      <td>-0.047121</td>\n",
       "      <td>-0.366175</td>\n",
       "      <td>-1.130283</td>\n",
       "      <td>-0.517681</td>\n",
       "      <td>0.633059</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.204533</td>\n",
       "      <td>-0.214171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679040</td>\n",
       "      <td>-0.232199</td>\n",
       "      <td>-0.428869</td>\n",
       "      <td>-1.190743</td>\n",
       "      <td>-0.248285</td>\n",
       "      <td>-0.180009</td>\n",
       "      <td>-0.688850</td>\n",
       "      <td>-0.596113</td>\n",
       "      <td>-0.368932</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>392432</td>\n",
       "      <td>-0.819428</td>\n",
       "      <td>-0.018268</td>\n",
       "      <td>-0.047686</td>\n",
       "      <td>-0.471116</td>\n",
       "      <td>-1.190888</td>\n",
       "      <td>-0.608216</td>\n",
       "      <td>-0.839902</td>\n",
       "      <td>-0.018879</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.957400</td>\n",
       "      <td>0.251832</td>\n",
       "      <td>-0.298243</td>\n",
       "      <td>-0.469795</td>\n",
       "      <td>-0.308584</td>\n",
       "      <td>-1.365618</td>\n",
       "      <td>-0.215089</td>\n",
       "      <td>-0.847685</td>\n",
       "      <td>0.694955</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>392433</td>\n",
       "      <td>0.437786</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>-0.466507</td>\n",
       "      <td>1.514302</td>\n",
       "      <td>2.746221</td>\n",
       "      <td>1.282836</td>\n",
       "      <td>-1.215845</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>0.619806</td>\n",
       "      <td>...</td>\n",
       "      <td>5.654401</td>\n",
       "      <td>0.937721</td>\n",
       "      <td>0.782412</td>\n",
       "      <td>-1.413585</td>\n",
       "      <td>0.208622</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.609862</td>\n",
       "      <td>3.137489</td>\n",
       "      <td>-0.137890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>392434</td>\n",
       "      <td>0.137740</td>\n",
       "      <td>-0.016819</td>\n",
       "      <td>0.092436</td>\n",
       "      <td>-0.545424</td>\n",
       "      <td>0.131016</td>\n",
       "      <td>-0.506191</td>\n",
       "      <td>0.209493</td>\n",
       "      <td>-0.450209</td>\n",
       "      <td>-0.487388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609673</td>\n",
       "      <td>-0.657740</td>\n",
       "      <td>-0.387053</td>\n",
       "      <td>1.177475</td>\n",
       "      <td>-0.711263</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>-0.687852</td>\n",
       "      <td>3.372954</td>\n",
       "      <td>-0.583500</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>392435</td>\n",
       "      <td>1.019507</td>\n",
       "      <td>-0.028070</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>-0.421863</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>-2.392677</td>\n",
       "      <td>-0.323490</td>\n",
       "      <td>2.167833</td>\n",
       "      <td>0.636916</td>\n",
       "      <td>...</td>\n",
       "      <td>2.542898</td>\n",
       "      <td>1.390568</td>\n",
       "      <td>1.577312</td>\n",
       "      <td>-1.745083</td>\n",
       "      <td>0.672999</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>2.503408</td>\n",
       "      <td>1.873678</td>\n",
       "      <td>0.600182</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>392436</td>\n",
       "      <td>-0.102105</td>\n",
       "      <td>-0.040849</td>\n",
       "      <td>-0.552134</td>\n",
       "      <td>1.862996</td>\n",
       "      <td>1.896060</td>\n",
       "      <td>-2.840276</td>\n",
       "      <td>1.624334</td>\n",
       "      <td>1.326741</td>\n",
       "      <td>2.270326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.179476</td>\n",
       "      <td>0.830638</td>\n",
       "      <td>2.209012</td>\n",
       "      <td>1.485389</td>\n",
       "      <td>1.845857</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>1.684238</td>\n",
       "      <td>0.949540</td>\n",
       "      <td>2.279930</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392437</td>\n",
       "      <td>0.775261</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.080540</td>\n",
       "      <td>-0.699094</td>\n",
       "      <td>-0.380927</td>\n",
       "      <td>-0.294925</td>\n",
       "      <td>-0.590150</td>\n",
       "      <td>-0.495735</td>\n",
       "      <td>-0.337198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978537</td>\n",
       "      <td>-0.407864</td>\n",
       "      <td>-0.045793</td>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.684786</td>\n",
       "      <td>0.744371</td>\n",
       "      <td>-0.304092</td>\n",
       "      <td>-0.831600</td>\n",
       "      <td>-0.855002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>392438</td>\n",
       "      <td>-1.517234</td>\n",
       "      <td>-0.028044</td>\n",
       "      <td>-0.171356</td>\n",
       "      <td>0.688223</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.053559</td>\n",
       "      <td>-0.437092</td>\n",
       "      <td>0.468593</td>\n",
       "      <td>-0.516839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115232</td>\n",
       "      <td>-0.670385</td>\n",
       "      <td>-1.360465</td>\n",
       "      <td>0.710794</td>\n",
       "      <td>0.151484</td>\n",
       "      <td>-1.288198</td>\n",
       "      <td>-0.853195</td>\n",
       "      <td>-0.309323</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>392439</td>\n",
       "      <td>-0.119101</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>-0.476054</td>\n",
       "      <td>-0.387816</td>\n",
       "      <td>0.376931</td>\n",
       "      <td>1.076661</td>\n",
       "      <td>-0.485520</td>\n",
       "      <td>-0.137305</td>\n",
       "      <td>0.575163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109986</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>-0.162897</td>\n",
       "      <td>-1.000919</td>\n",
       "      <td>0.657322</td>\n",
       "      <td>-0.175513</td>\n",
       "      <td>-0.433287</td>\n",
       "      <td>-0.164804</td>\n",
       "      <td>-0.084506</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>392440</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>-0.049330</td>\n",
       "      <td>-0.198842</td>\n",
       "      <td>-0.434550</td>\n",
       "      <td>-0.545066</td>\n",
       "      <td>0.878899</td>\n",
       "      <td>-1.554780</td>\n",
       "      <td>-0.847609</td>\n",
       "      <td>-0.150480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.853726</td>\n",
       "      <td>0.095309</td>\n",
       "      <td>-0.040793</td>\n",
       "      <td>-0.404032</td>\n",
       "      <td>-0.486408</td>\n",
       "      <td>0.040451</td>\n",
       "      <td>-0.803356</td>\n",
       "      <td>1.489539</td>\n",
       "      <td>-0.659932</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>392441</td>\n",
       "      <td>0.550419</td>\n",
       "      <td>-0.026467</td>\n",
       "      <td>-0.072219</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>-0.976189</td>\n",
       "      <td>1.323495</td>\n",
       "      <td>0.253387</td>\n",
       "      <td>1.844839</td>\n",
       "      <td>1.341516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160816</td>\n",
       "      <td>2.494855</td>\n",
       "      <td>1.591581</td>\n",
       "      <td>-1.216856</td>\n",
       "      <td>1.182917</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.575238</td>\n",
       "      <td>-1.000941</td>\n",
       "      <td>1.627632</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>392442</td>\n",
       "      <td>-2.039502</td>\n",
       "      <td>-0.218888</td>\n",
       "      <td>-1.583631</td>\n",
       "      <td>0.768805</td>\n",
       "      <td>-0.438828</td>\n",
       "      <td>0.191468</td>\n",
       "      <td>-0.582467</td>\n",
       "      <td>0.803562</td>\n",
       "      <td>2.687550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465200</td>\n",
       "      <td>0.739912</td>\n",
       "      <td>1.691338</td>\n",
       "      <td>0.422853</td>\n",
       "      <td>2.082296</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.047595</td>\n",
       "      <td>-0.373742</td>\n",
       "      <td>1.331072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>392443</td>\n",
       "      <td>-1.280876</td>\n",
       "      <td>-0.014128</td>\n",
       "      <td>0.404512</td>\n",
       "      <td>1.237853</td>\n",
       "      <td>0.735989</td>\n",
       "      <td>-0.206958</td>\n",
       "      <td>0.707058</td>\n",
       "      <td>0.851077</td>\n",
       "      <td>-1.284993</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140630</td>\n",
       "      <td>-1.158208</td>\n",
       "      <td>-1.326836</td>\n",
       "      <td>1.014244</td>\n",
       "      <td>-0.755766</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>-0.449904</td>\n",
       "      <td>-0.845454</td>\n",
       "      <td>-0.714069</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>392444</td>\n",
       "      <td>0.719944</td>\n",
       "      <td>-0.019219</td>\n",
       "      <td>-0.113005</td>\n",
       "      <td>0.408766</td>\n",
       "      <td>-0.015992</td>\n",
       "      <td>-0.594554</td>\n",
       "      <td>-1.076209</td>\n",
       "      <td>-0.907659</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>-0.549985</td>\n",
       "      <td>-0.236283</td>\n",
       "      <td>0.148215</td>\n",
       "      <td>-0.473299</td>\n",
       "      <td>0.354291</td>\n",
       "      <td>-0.128664</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>392445</td>\n",
       "      <td>0.680960</td>\n",
       "      <td>-0.017012</td>\n",
       "      <td>-0.207428</td>\n",
       "      <td>1.595523</td>\n",
       "      <td>-0.502677</td>\n",
       "      <td>1.371180</td>\n",
       "      <td>-0.136794</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>2.117736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542771</td>\n",
       "      <td>1.364404</td>\n",
       "      <td>1.837216</td>\n",
       "      <td>-0.092271</td>\n",
       "      <td>1.579427</td>\n",
       "      <td>0.319331</td>\n",
       "      <td>0.725922</td>\n",
       "      <td>0.303287</td>\n",
       "      <td>0.658043</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>392446</td>\n",
       "      <td>0.898747</td>\n",
       "      <td>-0.011921</td>\n",
       "      <td>0.137916</td>\n",
       "      <td>-0.924046</td>\n",
       "      <td>1.366975</td>\n",
       "      <td>-0.644433</td>\n",
       "      <td>-0.339379</td>\n",
       "      <td>-0.543002</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>...</td>\n",
       "      <td>2.314266</td>\n",
       "      <td>-0.007253</td>\n",
       "      <td>0.270167</td>\n",
       "      <td>-0.300871</td>\n",
       "      <td>-0.117714</td>\n",
       "      <td>0.296281</td>\n",
       "      <td>-0.369952</td>\n",
       "      <td>2.460227</td>\n",
       "      <td>-0.309228</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>392447</td>\n",
       "      <td>-3.063437</td>\n",
       "      <td>-1.469658</td>\n",
       "      <td>-3.516468</td>\n",
       "      <td>-0.635247</td>\n",
       "      <td>-0.133773</td>\n",
       "      <td>-0.122668</td>\n",
       "      <td>-1.005178</td>\n",
       "      <td>0.913962</td>\n",
       "      <td>-0.488834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.869591</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>-1.168895</td>\n",
       "      <td>-0.187472</td>\n",
       "      <td>1.836652</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>-0.718960</td>\n",
       "      <td>1.157783</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211645</th>\n",
       "      <td>604063</td>\n",
       "      <td>-0.102736</td>\n",
       "      <td>-0.024948</td>\n",
       "      <td>-0.144690</td>\n",
       "      <td>-0.092909</td>\n",
       "      <td>-1.101083</td>\n",
       "      <td>-0.435454</td>\n",
       "      <td>1.259344</td>\n",
       "      <td>-0.404340</td>\n",
       "      <td>-0.731295</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044008</td>\n",
       "      <td>-0.915253</td>\n",
       "      <td>-0.657344</td>\n",
       "      <td>0.702763</td>\n",
       "      <td>-0.406181</td>\n",
       "      <td>-1.008614</td>\n",
       "      <td>-0.788394</td>\n",
       "      <td>-0.715539</td>\n",
       "      <td>-0.390790</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211646</th>\n",
       "      <td>604064</td>\n",
       "      <td>1.210540</td>\n",
       "      <td>-0.015561</td>\n",
       "      <td>0.163281</td>\n",
       "      <td>-1.455785</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>0.794949</td>\n",
       "      <td>-1.119945</td>\n",
       "      <td>0.478652</td>\n",
       "      <td>0.239509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292945</td>\n",
       "      <td>0.695940</td>\n",
       "      <td>0.629866</td>\n",
       "      <td>-0.604865</td>\n",
       "      <td>0.408855</td>\n",
       "      <td>0.366074</td>\n",
       "      <td>0.769230</td>\n",
       "      <td>-0.079748</td>\n",
       "      <td>0.299464</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211647</th>\n",
       "      <td>604065</td>\n",
       "      <td>-0.869097</td>\n",
       "      <td>-0.054769</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>1.494902</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>-0.989741</td>\n",
       "      <td>-0.328674</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126951</td>\n",
       "      <td>0.190282</td>\n",
       "      <td>0.422340</td>\n",
       "      <td>0.559825</td>\n",
       "      <td>0.066547</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>-0.572396</td>\n",
       "      <td>0.299868</td>\n",
       "      <td>0.583064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211648</th>\n",
       "      <td>604066</td>\n",
       "      <td>-0.231139</td>\n",
       "      <td>-0.015213</td>\n",
       "      <td>0.279866</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>-1.602644</td>\n",
       "      <td>-2.899931</td>\n",
       "      <td>2.442186</td>\n",
       "      <td>3.257597</td>\n",
       "      <td>1.868830</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232617</td>\n",
       "      <td>0.328894</td>\n",
       "      <td>3.016022</td>\n",
       "      <td>0.931006</td>\n",
       "      <td>1.950742</td>\n",
       "      <td>2.523793</td>\n",
       "      <td>5.140957</td>\n",
       "      <td>-0.737889</td>\n",
       "      <td>2.032524</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211649</th>\n",
       "      <td>604067</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>0.273728</td>\n",
       "      <td>-0.666374</td>\n",
       "      <td>-0.350906</td>\n",
       "      <td>-0.681330</td>\n",
       "      <td>-0.392137</td>\n",
       "      <td>-0.753316</td>\n",
       "      <td>-0.483230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950815</td>\n",
       "      <td>-0.726685</td>\n",
       "      <td>-0.250510</td>\n",
       "      <td>0.501027</td>\n",
       "      <td>-0.633331</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>-0.199016</td>\n",
       "      <td>-0.789602</td>\n",
       "      <td>-0.406490</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211650</th>\n",
       "      <td>604068</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>0.081079</td>\n",
       "      <td>-0.074227</td>\n",
       "      <td>-0.212162</td>\n",
       "      <td>0.530137</td>\n",
       "      <td>0.579817</td>\n",
       "      <td>-0.549773</td>\n",
       "      <td>-0.327581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590500</td>\n",
       "      <td>-0.542091</td>\n",
       "      <td>-0.008257</td>\n",
       "      <td>0.492198</td>\n",
       "      <td>-0.537215</td>\n",
       "      <td>0.685286</td>\n",
       "      <td>-0.305631</td>\n",
       "      <td>-0.563828</td>\n",
       "      <td>-0.602673</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211651</th>\n",
       "      <td>604069</td>\n",
       "      <td>0.362527</td>\n",
       "      <td>-0.015975</td>\n",
       "      <td>0.236582</td>\n",
       "      <td>-0.601951</td>\n",
       "      <td>-0.313472</td>\n",
       "      <td>0.319458</td>\n",
       "      <td>-0.489490</td>\n",
       "      <td>-0.475623</td>\n",
       "      <td>-0.457444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935122</td>\n",
       "      <td>-0.637660</td>\n",
       "      <td>-0.111482</td>\n",
       "      <td>0.067674</td>\n",
       "      <td>-0.640131</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.571751</td>\n",
       "      <td>-0.523301</td>\n",
       "      <td>-0.548362</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211652</th>\n",
       "      <td>604070</td>\n",
       "      <td>-0.847096</td>\n",
       "      <td>-0.097315</td>\n",
       "      <td>-1.817370</td>\n",
       "      <td>-0.344799</td>\n",
       "      <td>0.533720</td>\n",
       "      <td>-2.352226</td>\n",
       "      <td>-0.291594</td>\n",
       "      <td>-0.093267</td>\n",
       "      <td>1.101918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310306</td>\n",
       "      <td>2.499150</td>\n",
       "      <td>0.138470</td>\n",
       "      <td>-0.099004</td>\n",
       "      <td>7.469451</td>\n",
       "      <td>-0.233889</td>\n",
       "      <td>-0.037993</td>\n",
       "      <td>-0.346893</td>\n",
       "      <td>3.368167</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211653</th>\n",
       "      <td>604071</td>\n",
       "      <td>-1.295880</td>\n",
       "      <td>-0.038054</td>\n",
       "      <td>-0.487036</td>\n",
       "      <td>-0.238179</td>\n",
       "      <td>-0.263573</td>\n",
       "      <td>-0.239702</td>\n",
       "      <td>-0.829190</td>\n",
       "      <td>0.368854</td>\n",
       "      <td>0.090189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242395</td>\n",
       "      <td>-0.275334</td>\n",
       "      <td>-0.846659</td>\n",
       "      <td>0.287407</td>\n",
       "      <td>0.350358</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>-0.439531</td>\n",
       "      <td>-0.232443</td>\n",
       "      <td>-0.128598</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211654</th>\n",
       "      <td>604072</td>\n",
       "      <td>-0.764565</td>\n",
       "      <td>-0.057455</td>\n",
       "      <td>-0.121488</td>\n",
       "      <td>-1.251892</td>\n",
       "      <td>-1.033843</td>\n",
       "      <td>0.840026</td>\n",
       "      <td>-0.452773</td>\n",
       "      <td>0.106175</td>\n",
       "      <td>-0.488507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667566</td>\n",
       "      <td>-0.159060</td>\n",
       "      <td>-0.434500</td>\n",
       "      <td>-0.231960</td>\n",
       "      <td>-0.709123</td>\n",
       "      <td>-0.483247</td>\n",
       "      <td>-0.804724</td>\n",
       "      <td>-0.616550</td>\n",
       "      <td>-0.634480</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211655</th>\n",
       "      <td>604073</td>\n",
       "      <td>-0.211790</td>\n",
       "      <td>-0.095839</td>\n",
       "      <td>-0.693170</td>\n",
       "      <td>-0.793088</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>-0.513209</td>\n",
       "      <td>-1.172506</td>\n",
       "      <td>-0.534579</td>\n",
       "      <td>-0.346006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232747</td>\n",
       "      <td>-0.090356</td>\n",
       "      <td>-0.554379</td>\n",
       "      <td>-0.105029</td>\n",
       "      <td>-0.236655</td>\n",
       "      <td>-0.600404</td>\n",
       "      <td>-0.781847</td>\n",
       "      <td>-0.221404</td>\n",
       "      <td>0.113776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211656</th>\n",
       "      <td>604074</td>\n",
       "      <td>0.235745</td>\n",
       "      <td>-0.031453</td>\n",
       "      <td>-0.324323</td>\n",
       "      <td>0.888638</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.720081</td>\n",
       "      <td>0.319641</td>\n",
       "      <td>0.639795</td>\n",
       "      <td>2.268958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374858</td>\n",
       "      <td>2.009821</td>\n",
       "      <td>1.619709</td>\n",
       "      <td>-0.527721</td>\n",
       "      <td>2.039762</td>\n",
       "      <td>1.116347</td>\n",
       "      <td>1.229387</td>\n",
       "      <td>0.673996</td>\n",
       "      <td>1.153014</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211657</th>\n",
       "      <td>604075</td>\n",
       "      <td>-1.151422</td>\n",
       "      <td>-0.031676</td>\n",
       "      <td>-0.466968</td>\n",
       "      <td>-0.838578</td>\n",
       "      <td>0.355424</td>\n",
       "      <td>0.171856</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>-0.113150</td>\n",
       "      <td>0.725805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290893</td>\n",
       "      <td>1.191346</td>\n",
       "      <td>-0.379162</td>\n",
       "      <td>-0.933363</td>\n",
       "      <td>2.005905</td>\n",
       "      <td>-0.742228</td>\n",
       "      <td>-0.683476</td>\n",
       "      <td>-0.302671</td>\n",
       "      <td>1.455318</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211658</th>\n",
       "      <td>604076</td>\n",
       "      <td>-1.643983</td>\n",
       "      <td>-0.024830</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>-0.867625</td>\n",
       "      <td>-1.334232</td>\n",
       "      <td>0.516803</td>\n",
       "      <td>0.180368</td>\n",
       "      <td>0.214681</td>\n",
       "      <td>-0.530186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115030</td>\n",
       "      <td>-0.038661</td>\n",
       "      <td>-0.905761</td>\n",
       "      <td>-0.679020</td>\n",
       "      <td>-0.755601</td>\n",
       "      <td>-1.321907</td>\n",
       "      <td>-0.899716</td>\n",
       "      <td>-0.854210</td>\n",
       "      <td>-0.070409</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211659</th>\n",
       "      <td>604077</td>\n",
       "      <td>-0.185171</td>\n",
       "      <td>-0.016721</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>-1.415731</td>\n",
       "      <td>0.176571</td>\n",
       "      <td>-0.478581</td>\n",
       "      <td>-0.439234</td>\n",
       "      <td>-0.131807</td>\n",
       "      <td>-0.396336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181898</td>\n",
       "      <td>-0.816408</td>\n",
       "      <td>-0.313912</td>\n",
       "      <td>1.050003</td>\n",
       "      <td>-0.658853</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>-0.690673</td>\n",
       "      <td>-0.218124</td>\n",
       "      <td>-0.188425</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211660</th>\n",
       "      <td>604078</td>\n",
       "      <td>1.109534</td>\n",
       "      <td>-0.018190</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>-0.955268</td>\n",
       "      <td>-0.031994</td>\n",
       "      <td>1.461562</td>\n",
       "      <td>-1.408107</td>\n",
       "      <td>-0.475621</td>\n",
       "      <td>-0.131553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.281571</td>\n",
       "      <td>0.343386</td>\n",
       "      <td>-1.316260</td>\n",
       "      <td>-0.259890</td>\n",
       "      <td>0.849384</td>\n",
       "      <td>-0.282967</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>-0.808002</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211661</th>\n",
       "      <td>604079</td>\n",
       "      <td>-0.354959</td>\n",
       "      <td>-0.104830</td>\n",
       "      <td>-0.481110</td>\n",
       "      <td>0.532517</td>\n",
       "      <td>-0.055479</td>\n",
       "      <td>0.990390</td>\n",
       "      <td>3.058267</td>\n",
       "      <td>-0.440216</td>\n",
       "      <td>0.822645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047586</td>\n",
       "      <td>1.392516</td>\n",
       "      <td>0.105898</td>\n",
       "      <td>-1.605966</td>\n",
       "      <td>1.114767</td>\n",
       "      <td>-0.029024</td>\n",
       "      <td>-0.779353</td>\n",
       "      <td>-0.131530</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211662</th>\n",
       "      <td>604080</td>\n",
       "      <td>-1.300627</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>0.648890</td>\n",
       "      <td>1.009564</td>\n",
       "      <td>-0.132813</td>\n",
       "      <td>-1.804049</td>\n",
       "      <td>1.991319</td>\n",
       "      <td>0.230198</td>\n",
       "      <td>-0.915582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732460</td>\n",
       "      <td>-1.578003</td>\n",
       "      <td>-1.109370</td>\n",
       "      <td>1.385595</td>\n",
       "      <td>-0.848648</td>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.642986</td>\n",
       "      <td>-0.671243</td>\n",
       "      <td>-0.161174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211663</th>\n",
       "      <td>604081</td>\n",
       "      <td>0.404423</td>\n",
       "      <td>-0.119930</td>\n",
       "      <td>-1.179075</td>\n",
       "      <td>1.730329</td>\n",
       "      <td>-1.223321</td>\n",
       "      <td>1.168269</td>\n",
       "      <td>-1.013117</td>\n",
       "      <td>0.129222</td>\n",
       "      <td>1.281188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>1.247979</td>\n",
       "      <td>1.495700</td>\n",
       "      <td>-1.786872</td>\n",
       "      <td>1.003547</td>\n",
       "      <td>0.590793</td>\n",
       "      <td>0.388370</td>\n",
       "      <td>-0.369971</td>\n",
       "      <td>-0.129248</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211664</th>\n",
       "      <td>604082</td>\n",
       "      <td>0.503981</td>\n",
       "      <td>-0.014440</td>\n",
       "      <td>0.214123</td>\n",
       "      <td>0.992274</td>\n",
       "      <td>0.582839</td>\n",
       "      <td>-0.454562</td>\n",
       "      <td>0.864876</td>\n",
       "      <td>-0.536695</td>\n",
       "      <td>-0.489296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151251</td>\n",
       "      <td>-0.836456</td>\n",
       "      <td>-0.288674</td>\n",
       "      <td>1.283885</td>\n",
       "      <td>-0.544375</td>\n",
       "      <td>0.171521</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>-0.192111</td>\n",
       "      <td>-0.486189</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211665</th>\n",
       "      <td>604083</td>\n",
       "      <td>0.421822</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.452965</td>\n",
       "      <td>-1.465315</td>\n",
       "      <td>-0.639441</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>-0.882634</td>\n",
       "      <td>-0.539281</td>\n",
       "      <td>-0.332060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396353</td>\n",
       "      <td>-0.373046</td>\n",
       "      <td>-0.041698</td>\n",
       "      <td>0.098077</td>\n",
       "      <td>-0.453290</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>-0.291763</td>\n",
       "      <td>-0.255386</td>\n",
       "      <td>-0.567615</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211666</th>\n",
       "      <td>604084</td>\n",
       "      <td>-1.405885</td>\n",
       "      <td>-0.015529</td>\n",
       "      <td>0.081315</td>\n",
       "      <td>0.476284</td>\n",
       "      <td>0.329192</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.231812</td>\n",
       "      <td>0.013826</td>\n",
       "      <td>-0.858074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>-0.796221</td>\n",
       "      <td>-0.819604</td>\n",
       "      <td>2.312094</td>\n",
       "      <td>-0.931063</td>\n",
       "      <td>-0.425722</td>\n",
       "      <td>-0.813524</td>\n",
       "      <td>-0.525662</td>\n",
       "      <td>-0.806874</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211667</th>\n",
       "      <td>604085</td>\n",
       "      <td>-0.255851</td>\n",
       "      <td>-0.015535</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.742090</td>\n",
       "      <td>-1.072810</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.818771</td>\n",
       "      <td>-0.379148</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860600</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.763121</td>\n",
       "      <td>-0.026385</td>\n",
       "      <td>-0.788844</td>\n",
       "      <td>-0.956820</td>\n",
       "      <td>-0.519904</td>\n",
       "      <td>-0.752493</td>\n",
       "      <td>-0.349251</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211668</th>\n",
       "      <td>604086</td>\n",
       "      <td>0.769109</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.517912</td>\n",
       "      <td>1.362700</td>\n",
       "      <td>-0.433119</td>\n",
       "      <td>-0.423982</td>\n",
       "      <td>-0.356866</td>\n",
       "      <td>0.511168</td>\n",
       "      <td>1.012104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>1.580103</td>\n",
       "      <td>-0.934321</td>\n",
       "      <td>1.041610</td>\n",
       "      <td>0.642434</td>\n",
       "      <td>1.698802</td>\n",
       "      <td>0.791768</td>\n",
       "      <td>-0.283639</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211669</th>\n",
       "      <td>604087</td>\n",
       "      <td>0.539653</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>-1.354061</td>\n",
       "      <td>-0.231431</td>\n",
       "      <td>-2.392217</td>\n",
       "      <td>-0.853211</td>\n",
       "      <td>-0.666104</td>\n",
       "      <td>-0.476928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990602</td>\n",
       "      <td>-0.286132</td>\n",
       "      <td>-0.132026</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>-0.304182</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>-0.573663</td>\n",
       "      <td>1.433907</td>\n",
       "      <td>0.635513</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211670</th>\n",
       "      <td>604088</td>\n",
       "      <td>0.939169</td>\n",
       "      <td>-0.031861</td>\n",
       "      <td>-0.297075</td>\n",
       "      <td>1.627091</td>\n",
       "      <td>1.444664</td>\n",
       "      <td>1.466964</td>\n",
       "      <td>-0.398424</td>\n",
       "      <td>1.083040</td>\n",
       "      <td>1.156888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.687512</td>\n",
       "      <td>1.555102</td>\n",
       "      <td>1.673512</td>\n",
       "      <td>-2.019056</td>\n",
       "      <td>0.793360</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>1.247109</td>\n",
       "      <td>0.743938</td>\n",
       "      <td>0.198913</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211671</th>\n",
       "      <td>604089</td>\n",
       "      <td>-2.738119</td>\n",
       "      <td>-0.023891</td>\n",
       "      <td>-0.079456</td>\n",
       "      <td>0.211851</td>\n",
       "      <td>-0.436666</td>\n",
       "      <td>-1.890149</td>\n",
       "      <td>1.163083</td>\n",
       "      <td>1.270928</td>\n",
       "      <td>0.269453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404973</td>\n",
       "      <td>-0.894813</td>\n",
       "      <td>-0.149381</td>\n",
       "      <td>1.356825</td>\n",
       "      <td>0.412399</td>\n",
       "      <td>-1.335880</td>\n",
       "      <td>-0.595696</td>\n",
       "      <td>-0.326018</td>\n",
       "      <td>0.838165</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211672</th>\n",
       "      <td>604090</td>\n",
       "      <td>0.573479</td>\n",
       "      <td>-0.013914</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>-1.117083</td>\n",
       "      <td>0.346173</td>\n",
       "      <td>1.154490</td>\n",
       "      <td>0.334465</td>\n",
       "      <td>-0.839889</td>\n",
       "      <td>-0.488286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745546</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>-0.119672</td>\n",
       "      <td>-1.101634</td>\n",
       "      <td>-0.688077</td>\n",
       "      <td>-0.118480</td>\n",
       "      <td>-0.746325</td>\n",
       "      <td>0.447293</td>\n",
       "      <td>-0.563384</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211673</th>\n",
       "      <td>604091</td>\n",
       "      <td>0.466841</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.505160</td>\n",
       "      <td>0.648125</td>\n",
       "      <td>-0.650331</td>\n",
       "      <td>-0.081008</td>\n",
       "      <td>0.780131</td>\n",
       "      <td>-0.787532</td>\n",
       "      <td>-0.488666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075811</td>\n",
       "      <td>-0.855960</td>\n",
       "      <td>-0.400367</td>\n",
       "      <td>1.704200</td>\n",
       "      <td>-0.838864</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>-0.712978</td>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.447556</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211674</th>\n",
       "      <td>604092</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>-0.049562</td>\n",
       "      <td>-0.350616</td>\n",
       "      <td>1.418559</td>\n",
       "      <td>0.085509</td>\n",
       "      <td>1.219870</td>\n",
       "      <td>0.943165</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>1.046436</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000828</td>\n",
       "      <td>1.455837</td>\n",
       "      <td>1.320956</td>\n",
       "      <td>-1.608140</td>\n",
       "      <td>0.629994</td>\n",
       "      <td>1.545077</td>\n",
       "      <td>0.835327</td>\n",
       "      <td>0.851544</td>\n",
       "      <td>0.264917</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211675 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature0  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0       392418  0.088970 -0.012451  0.226408 -1.386858 -1.066616  0.636430   \n",
       "1       392419 -1.004904 -0.034484 -0.345187  0.179278 -0.393074  0.752589   \n",
       "2       392420  1.100924 -0.023984 -0.329857  0.661071  1.076176  0.414028   \n",
       "3       392421  0.939863 -0.018097  0.008183 -1.418409  0.359216 -0.135353   \n",
       "4       392422 -0.146653 -0.016357  0.019047  0.035251 -0.577442 -0.068010   \n",
       "5       392423  0.837824 -0.020683  0.273588  1.056372 -0.230143  0.573043   \n",
       "6       392424  1.040767 -0.152174  0.344835 -0.737765  0.245411  1.330195   \n",
       "7       392425 -0.699206 -0.035928  0.175071 -0.173649 -0.001234  0.419827   \n",
       "8       392426 -1.250826 -0.018475  0.129181 -0.010234 -1.590578 -1.054722   \n",
       "9       392427  1.069376  0.019059  0.642103  0.213534 -0.151496 -0.172658   \n",
       "10      392428 -0.917364 -0.118647 -0.285822  0.533232 -0.187045 -0.718213   \n",
       "11      392429 -0.713333 -0.103237 -0.571024  0.984154  0.525436  0.782510   \n",
       "12      392430 -1.046641 -0.016020  0.243694  1.692588  1.320556 -0.212556   \n",
       "13      392431 -1.328634 -0.047121 -0.366175 -1.130283 -0.517681  0.633059   \n",
       "14      392432 -0.819428 -0.018268 -0.047686 -0.471116 -1.190888 -0.608216   \n",
       "15      392433  0.437786 -0.049370 -0.466507  1.514302  2.746221  1.282836   \n",
       "16      392434  0.137740 -0.016819  0.092436 -0.545424  0.131016 -0.506191   \n",
       "17      392435  1.019507 -0.028070  0.019718 -0.421863  0.430075 -2.392677   \n",
       "18      392436 -0.102105 -0.040849 -0.552134  1.862996  1.896060 -2.840276   \n",
       "19      392437  0.775261 -0.016032  0.080540 -0.699094 -0.380927 -0.294925   \n",
       "20      392438 -1.517234 -0.028044 -0.171356  0.688223  0.112646  0.053559   \n",
       "21      392439 -0.119101 -0.027805 -0.476054 -0.387816  0.376931  1.076661   \n",
       "22      392440  0.585500 -0.049330 -0.198842 -0.434550 -0.545066  0.878899   \n",
       "23      392441  0.550419 -0.026467 -0.072219  0.762435 -0.976189  1.323495   \n",
       "24      392442 -2.039502 -0.218888 -1.583631  0.768805 -0.438828  0.191468   \n",
       "25      392443 -1.280876 -0.014128  0.404512  1.237853  0.735989 -0.206958   \n",
       "26      392444  0.719944 -0.019219 -0.113005  0.408766 -0.015992 -0.594554   \n",
       "27      392445  0.680960 -0.017012 -0.207428  1.595523 -0.502677  1.371180   \n",
       "28      392446  0.898747 -0.011921  0.137916 -0.924046  1.366975 -0.644433   \n",
       "29      392447 -3.063437 -1.469658 -3.516468 -0.635247 -0.133773 -0.122668   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "211645  604063 -0.102736 -0.024948 -0.144690 -0.092909 -1.101083 -0.435454   \n",
       "211646  604064  1.210540 -0.015561  0.163281 -1.455785  0.207474  0.794949   \n",
       "211647  604065 -0.869097 -0.054769  0.318353  0.149980  1.494902  0.054499   \n",
       "211648  604066 -0.231139 -0.015213  0.279866  0.023828 -1.602644 -2.899931   \n",
       "211649  604067  0.546341 -0.006732  0.273728 -0.666374 -0.350906 -0.681330   \n",
       "211650  604068  0.963833 -0.015971  0.081079 -0.074227 -0.212162  0.530137   \n",
       "211651  604069  0.362527 -0.015975  0.236582 -0.601951 -0.313472  0.319458   \n",
       "211652  604070 -0.847096 -0.097315 -1.817370 -0.344799  0.533720 -2.352226   \n",
       "211653  604071 -1.295880 -0.038054 -0.487036 -0.238179 -0.263573 -0.239702   \n",
       "211654  604072 -0.764565 -0.057455 -0.121488 -1.251892 -1.033843  0.840026   \n",
       "211655  604073 -0.211790 -0.095839 -0.693170 -0.793088 -0.705000 -0.513209   \n",
       "211656  604074  0.235745 -0.031453 -0.324323  0.888638  0.400635  0.720081   \n",
       "211657  604075 -1.151422 -0.031676 -0.466968 -0.838578  0.355424  0.171856   \n",
       "211658  604076 -1.643983 -0.024830  0.029919 -0.867625 -1.334232  0.516803   \n",
       "211659  604077 -0.185171 -0.016721  0.023699 -1.415731  0.176571 -0.478581   \n",
       "211660  604078  1.109534 -0.018190  0.016222 -0.955268 -0.031994  1.461562   \n",
       "211661  604079 -0.354959 -0.104830 -0.481110  0.532517 -0.055479  0.990390   \n",
       "211662  604080 -1.300627 -0.013230  0.648890  1.009564 -0.132813 -1.804049   \n",
       "211663  604081  0.404423 -0.119930 -1.179075  1.730329 -1.223321  1.168269   \n",
       "211664  604082  0.503981 -0.014440  0.214123  0.992274  0.582839 -0.454562   \n",
       "211665  604083  0.421822 -0.003974  0.452965 -1.465315 -0.639441  0.692669   \n",
       "211666  604084 -1.405885 -0.015529  0.081315  0.476284  0.329192  0.037508   \n",
       "211667  604085 -0.255851 -0.015535  0.071321  0.742090 -1.072810  0.793729   \n",
       "211668  604086  0.769109 -0.052867 -0.517912  1.362700 -0.433119 -0.423982   \n",
       "211669  604087  0.539653 -0.015061  0.160396 -1.354061 -0.231431 -2.392217   \n",
       "211670  604088  0.939169 -0.031861 -0.297075  1.627091  1.444664  1.466964   \n",
       "211671  604089 -2.738119 -0.023891 -0.079456  0.211851 -0.436666 -1.890149   \n",
       "211672  604090  0.573479 -0.013914  0.091884 -1.117083  0.346173  1.154490   \n",
       "211673  604091  0.466841  0.004306  0.505160  0.648125 -0.650331 -0.081008   \n",
       "211674  604092  0.267700 -0.049562 -0.350616  1.418559  0.085509  1.219870   \n",
       "\n",
       "        feature6  feature7  feature8  ...    feature79  feature80  feature81  \\\n",
       "0      -0.805733 -0.478093 -0.536539  ...    -0.785307  -0.491378  -0.291151   \n",
       "1       2.233694  0.651315  1.896860  ...    -0.079682   1.490679  -0.082252   \n",
       "2       0.194951  0.833402  0.778437  ...     1.596572   0.640618   1.219347   \n",
       "3      -1.482310 -0.057569  0.169539  ...     0.110845   0.145179   0.516610   \n",
       "4      -1.572975 -0.329777  0.267620  ...     0.737593   0.037424   0.027635   \n",
       "5       0.645608 -0.483777 -0.217809  ...     0.996371  -0.438168   0.167159   \n",
       "6      -0.122921  0.752297  0.385699  ...     3.819098   1.698990   0.942540   \n",
       "7      -0.073032  0.496059 -0.486717  ...    -0.748197  -0.190228  -0.558712   \n",
       "8      -0.402337  0.551442 -1.204170  ...    -0.653698  -0.896002  -1.498425   \n",
       "9      -0.396895 -0.149623 -0.384482  ...     0.680009   0.175432  -0.185755   \n",
       "10     -1.453297  0.059654 -0.444266  ...    -0.079491  -0.538677  -0.726547   \n",
       "11     -0.287802 -0.262987  0.990423  ...     1.327812   0.662191   0.897151   \n",
       "12     -1.111035 -0.062676 -0.542785  ...    -0.365200  -0.742857  -0.958454   \n",
       "13      0.131175  0.204533 -0.214171  ...    -0.679040  -0.232199  -0.428869   \n",
       "14     -0.839902 -0.018879  0.067261  ...    -0.957400   0.251832  -0.298243   \n",
       "15     -1.215845  0.104863  0.619806  ...     5.654401   0.937721   0.782412   \n",
       "16      0.209493 -0.450209 -0.487388  ...    -0.609673  -0.657740  -0.387053   \n",
       "17     -0.323490  2.167833  0.636916  ...     2.542898   1.390568   1.577312   \n",
       "18      1.624334  1.326741  2.270326  ...     2.179476   0.830638   2.209012   \n",
       "19     -0.590150 -0.495735 -0.337198  ...    -0.978537  -0.407864  -0.045793   \n",
       "20     -0.437092  0.468593 -0.516839  ...    -0.115232  -0.670385  -1.360465   \n",
       "21     -0.485520 -0.137305  0.575163  ...    -0.109986   0.545784  -0.162897   \n",
       "22     -1.554780 -0.847609 -0.150480  ...     1.853726   0.095309  -0.040793   \n",
       "23      0.253387  1.844839  1.341516  ...    -1.160816   2.494855   1.591581   \n",
       "24     -0.582467  0.803562  2.687550  ...    -0.465200   0.739912   1.691338   \n",
       "25      0.707058  0.851077 -1.284993  ...    -1.140630  -1.158208  -1.326836   \n",
       "26     -1.076209 -0.907659  0.060980  ...     0.094755   0.021680   0.196119   \n",
       "27     -0.136794  0.152394  2.117736  ...     0.542771   1.364404   1.837216   \n",
       "28     -0.339379 -0.543002 -0.269487  ...     2.314266  -0.007253   0.270167   \n",
       "29     -1.005178  0.913962 -0.488834  ...    -0.869591   0.114977  -1.168895   \n",
       "...          ...       ...       ...  ...          ...        ...        ...   \n",
       "211645  1.259344 -0.404340 -0.731295  ...    -1.044008  -0.915253  -0.657344   \n",
       "211646 -1.119945  0.478652  0.239509  ...     0.292945   0.695940   0.629866   \n",
       "211647 -0.989741 -0.328674  0.018314  ...     0.126951   0.190282   0.422340   \n",
       "211648  2.442186  3.257597  1.868830  ...    -1.232617   0.328894   3.016022   \n",
       "211649 -0.392137 -0.753316 -0.483230  ...    -0.950815  -0.726685  -0.250510   \n",
       "211650  0.579817 -0.549773 -0.327581  ...    -0.590500  -0.542091  -0.008257   \n",
       "211651 -0.489490 -0.475623 -0.457444  ...    -0.935122  -0.637660  -0.111482   \n",
       "211652 -0.291594 -0.093267  1.101918  ...    -0.310306   2.499150   0.138470   \n",
       "211653 -0.829190  0.368854  0.090189  ...    -0.242395  -0.275334  -0.846659   \n",
       "211654 -0.452773  0.106175 -0.488507  ...    -0.667566  -0.159060  -0.434500   \n",
       "211655 -1.172506 -0.534579 -0.346006  ...    -0.232747  -0.090356  -0.554379   \n",
       "211656  0.319641  0.639795  2.268958  ...     0.374858   2.009821   1.619709   \n",
       "211657  0.013278 -0.113150  0.725805  ...    -0.290893   1.191346  -0.379162   \n",
       "211658  0.180368  0.214681 -0.530186  ...    -1.115030  -0.038661  -0.905761   \n",
       "211659 -0.439234 -0.131807 -0.396336  ...    -0.181898  -0.816408  -0.313912   \n",
       "211660 -1.408107 -0.475621 -0.131553  ...     0.074200   0.281571   0.343386   \n",
       "211661  3.058267 -0.440216  0.822645  ...    -0.047586   1.392516   0.105898   \n",
       "211662  1.991319  0.230198 -0.915582  ...    -0.732460  -1.578003  -1.109370   \n",
       "211663 -1.013117  0.129222  1.281188  ...    -0.351451   1.247979   1.495700   \n",
       "211664  0.864876 -0.536695 -0.489296  ...     0.151251  -0.836456  -0.288674   \n",
       "211665 -0.882634 -0.539281 -0.332060  ...    -0.396353  -0.373046  -0.041698   \n",
       "211666  0.231812  0.013826 -0.858074  ...     0.032755  -0.796221  -0.819604   \n",
       "211667  0.818771 -0.379148 -0.822889  ...    -0.860600  -0.287712  -0.763121   \n",
       "211668 -0.356866  0.511168  1.012104  ...     0.784947   0.858856   1.580103   \n",
       "211669 -0.853211 -0.666104 -0.476928  ...     1.990602  -0.286132  -0.132026   \n",
       "211670 -0.398424  1.083040  1.156888  ...     1.687512   1.555102   1.673512   \n",
       "211671  1.163083  1.270928  0.269453  ...    -0.404973  -0.894813  -0.149381   \n",
       "211672  0.334465 -0.839889 -0.488286  ...     0.745546   0.061967  -0.119672   \n",
       "211673  0.780131 -0.787532 -0.488666  ...    -0.075811  -0.855960  -0.400367   \n",
       "211674  0.943165  0.012985  1.046436  ...     1.000828   1.455837   1.320956   \n",
       "\n",
       "        feature82  feature83  feature84  feature85  feature86  feature87  \\\n",
       "0        0.120415  -0.807633  -0.394544  -0.681540  -0.707518  -0.775872   \n",
       "1       -1.079956   1.607502  -1.805872  -0.149094  -0.108615   1.492027   \n",
       "2       -1.060589   0.290406   0.772820   1.368938   1.088984  -0.433057   \n",
       "3       -0.260976   0.265216   1.133491   0.500493   0.038265  -0.783961   \n",
       "4        0.544575   0.036731  -0.131309  -0.877661   0.461268  -0.238349   \n",
       "5        1.013741  -0.541207  -0.093378  -0.391347   0.692741  -0.636414   \n",
       "6       -1.111067   0.019530   1.077803   1.040696   2.926289   1.866744   \n",
       "7        1.102890  -0.556398   0.783577  -0.040264  -0.633712   0.313645   \n",
       "8        0.071348  -0.934304  -2.766871  -0.817718  -0.609713  -0.771024   \n",
       "9       -0.756882  -0.433311   0.301302   0.215193   0.201869   0.829680   \n",
       "10       0.533653  -0.352214   0.012316  -0.554619  -0.170540  -0.312947   \n",
       "11      -0.068489   0.541205  -0.984759  -0.007678   0.939193   0.218440   \n",
       "12       1.056052  -0.698245   0.012662  -0.373747  -0.296632   0.157238   \n",
       "13      -1.190743  -0.248285  -0.180009  -0.688850  -0.596113  -0.368932   \n",
       "14      -0.469795  -0.308584  -1.365618  -0.215089  -0.847685   0.694955   \n",
       "15      -1.413585   0.208622   0.013578   0.609862   3.137489  -0.137890   \n",
       "16       1.177475  -0.711263   0.013024  -0.687852   3.372954  -0.583500   \n",
       "17      -1.745083   0.672999   0.779755   2.503408   1.873678   0.600182   \n",
       "18       1.485389   1.845857   0.010711   1.684238   0.949540   2.279930   \n",
       "19       0.068662  -0.684786   0.744371  -0.304092  -0.831600  -0.855002   \n",
       "20       0.710794   0.151484  -1.288198  -0.853195  -0.309323   0.055747   \n",
       "21      -1.000919   0.657322  -0.175513  -0.433287  -0.164804  -0.084506   \n",
       "22      -0.404032  -0.486408   0.040451  -0.803356   1.489539  -0.659932   \n",
       "23      -1.216856   1.182917   0.012138   1.575238  -1.000941   1.627632   \n",
       "24       0.422853   2.082296   0.011965   0.047595  -0.373742   1.331072   \n",
       "25       1.014244  -0.755766   0.011154  -0.449904  -0.845454  -0.714069   \n",
       "26      -0.549985  -0.236283   0.148215  -0.473299   0.354291  -0.128664   \n",
       "27      -0.092271   1.579427   0.319331   0.725922   0.303287   0.658043   \n",
       "28      -0.300871  -0.117714   0.296281  -0.369952   2.460227  -0.309228   \n",
       "29      -0.187472   1.836652   0.011324   0.035404  -0.718960   1.157783   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "211645   0.702763  -0.406181  -1.008614  -0.788394  -0.715539  -0.390790   \n",
       "211646  -0.604865   0.408855   0.366074   0.769230  -0.079748   0.299464   \n",
       "211647   0.559825   0.066547   0.011043  -0.572396   0.299868   0.583064   \n",
       "211648   0.931006   1.950742   2.523793   5.140957  -0.737889   2.032524   \n",
       "211649   0.501027  -0.633331   0.212900  -0.199016  -0.789602  -0.406490   \n",
       "211650   0.492198  -0.537215   0.685286  -0.305631  -0.563828  -0.602673   \n",
       "211651   0.067674  -0.640131   0.010026  -0.571751  -0.523301  -0.548362   \n",
       "211652  -0.099004   7.469451  -0.233889  -0.037993  -0.346893   3.368167   \n",
       "211653   0.287407   0.350358   0.013183  -0.439531  -0.232443  -0.128598   \n",
       "211654  -0.231960  -0.709123  -0.483247  -0.804724  -0.616550  -0.634480   \n",
       "211655  -0.105029  -0.236655  -0.600404  -0.781847  -0.221404   0.113776   \n",
       "211656  -0.527721   2.039762   1.116347   1.229387   0.673996   1.153014   \n",
       "211657  -0.933363   2.005905  -0.742228  -0.683476  -0.302671   1.455318   \n",
       "211658  -0.679020  -0.755601  -1.321907  -0.899716  -0.854210  -0.070409   \n",
       "211659   1.050003  -0.658853   0.012438  -0.690673  -0.218124  -0.188425   \n",
       "211660  -1.316260  -0.259890   0.849384  -0.282967  -0.018520  -0.808002   \n",
       "211661  -1.605966   1.114767  -0.029024  -0.779353  -0.131530   0.943299   \n",
       "211662   1.385595  -0.848648  -0.050341  -0.642986  -0.671243  -0.161174   \n",
       "211663  -1.786872   1.003547   0.590793   0.388370  -0.369971  -0.129248   \n",
       "211664   1.283885  -0.544375   0.171521  -0.012841  -0.192111  -0.486189   \n",
       "211665   0.098077  -0.453290   0.011781  -0.291763  -0.255386  -0.567615   \n",
       "211666   2.312094  -0.931063  -0.425722  -0.813524  -0.525662  -0.806874   \n",
       "211667  -0.026385  -0.788844  -0.956820  -0.519904  -0.752493  -0.349251   \n",
       "211668  -0.934321   1.041610   0.642434   1.698802   0.791768  -0.283639   \n",
       "211669   0.005123  -0.304182   0.012896  -0.573663   1.433907   0.635513   \n",
       "211670  -2.019056   0.793360   0.547771   1.247109   0.743938   0.198913   \n",
       "211671   1.356825   0.412399  -1.335880  -0.595696  -0.326018   0.838165   \n",
       "211672  -1.101634  -0.688077  -0.118480  -0.746325   0.447293  -0.563384   \n",
       "211673   1.704200  -0.838864   0.011521  -0.712978  -0.038924  -0.447556   \n",
       "211674  -1.608140   0.629994   1.545077   0.835327   0.851544   0.264917   \n",
       "\n",
       "        group  \n",
       "0          19  \n",
       "1          15  \n",
       "2           9  \n",
       "3          14  \n",
       "4          15  \n",
       "5           1  \n",
       "6          21  \n",
       "7          19  \n",
       "8           7  \n",
       "9           7  \n",
       "10         13  \n",
       "11         16  \n",
       "12         14  \n",
       "13         15  \n",
       "14          4  \n",
       "15          1  \n",
       "16         24  \n",
       "17         15  \n",
       "18          6  \n",
       "19          1  \n",
       "20          6  \n",
       "21          2  \n",
       "22         17  \n",
       "23         13  \n",
       "24          7  \n",
       "25         16  \n",
       "26         20  \n",
       "27         27  \n",
       "28         16  \n",
       "29         21  \n",
       "...       ...  \n",
       "211645     27  \n",
       "211646     11  \n",
       "211647      3  \n",
       "211648      7  \n",
       "211649     17  \n",
       "211650     15  \n",
       "211651     17  \n",
       "211652     23  \n",
       "211653     23  \n",
       "211654      3  \n",
       "211655     20  \n",
       "211656     15  \n",
       "211657     15  \n",
       "211658     14  \n",
       "211659     17  \n",
       "211660     15  \n",
       "211661      6  \n",
       "211662     12  \n",
       "211663     21  \n",
       "211664     15  \n",
       "211665      4  \n",
       "211666     27  \n",
       "211667     13  \n",
       "211668     12  \n",
       "211669     10  \n",
       "211670     21  \n",
       "211671     20  \n",
       "211672     22  \n",
       "211673      5  \n",
       "211674     10  \n",
       "\n",
       "[211675 rows x 90 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group: (1,28) -> (0,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ini['group']=test_ini['group']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_ini['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ini['group']=train_ini['group']-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_test_OneHot = np_utils.to_categorical(test_ini['group'], num_classes=max(test_ini['group'])+1)\n",
    "group_train_OneHot = np_utils.to_categorical(train_ini['group'], num_classes=max(train_ini['group'])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_train_OneHot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ini['group'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_ini=pandas.DataFrame.as_matrix(train_ini)\n",
    "test_array_ini=pandas.DataFrame.as_matrix(test_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 93)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array_ini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 90)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array_ini.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ndarray, copy不需要deep (call by value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array=train_array_ini.copy()\n",
    "test_array=test_array_ini.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 93)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array=np.delete(train_array, numpy.s_[89:93], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array=np.delete(train_array, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 88)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 90)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_array=np.delete(test_array, 89, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_array=np.delete(test_array, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 88)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (完成)array預處理\n",
    "## 要把onehot加進去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 28)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_train_OneHot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 28)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_test_OneHot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array1=np.concatenate((train_array, group_train_OneHot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_array1=np.concatenate((test_array, group_test_OneHot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 116)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 116)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array1=preprocessing.scale(train_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_array1=preprocessing.scale(test_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 116)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4177785643614695e-14"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_array1.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000082259"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_array1.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5105033062333394e-15"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_array1.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000041245"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_array1.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 116)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 116)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> np.save('train_array1', train_array1)\n",
    ">>> np.save('test_array1', test_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.load('train_array1.npy')\n",
    "yy=np.load('test_array1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 116)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675, 116)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pandas.DataFrame.as_matrix(train_ini_00['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load('train_array1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    ">>> import numpy as np\n",
    ">>> clf = NearestCentroid()\n",
    ">>> clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  1. ...,  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=clf.predict(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211675,)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"./upload.csv\", sep=',', delimiter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label']=a*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://dataaspirant.com/2016/12/27/k-nearest-neighbor-algorithm-implementaion-python-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclideanDist(x, xi):\n",
    "    d = 0.0\n",
    "    for i in range(len(x)-1):\n",
    "        d += pow((float(x[i])-float(xi[i])),2)\n",
    "        d = math.sqrt(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from operator import itemgetter\n",
    "def knn_predict(test_data, train_data, k_value, train_label):\n",
    "    A=[]\n",
    "    for ii in range(0,test_data.shape[0],1):\n",
    "        eu_Distance =[]\n",
    "        knn = []\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for jj in range(0,train_data.shape[0],1):\n",
    "            i=test_data[ii]\n",
    "            j=train_data[jj]\n",
    "            eu_dist = euclideanDist(i, j)\n",
    "            eu_Distance.append([jj,eu_dist])\n",
    "            \n",
    "        #eu_Distance=sorted(eu_Distance, key=itemgetter(0))\n",
    "        #knn = eu_Distance[:k_value]    \n",
    "        knn = heapq.nsmallest(k_value, eu_Distance, key=itemgetter(0))\n",
    "            \n",
    "        for k in knn:\n",
    "            if train_label[k[0]] ==1:\n",
    "                good += 1\n",
    "            else:\n",
    "                bad +=1\n",
    "                \n",
    "        A.append(float(good)/float(k_value))\n",
    "        print(ii,\"/\",test_data.shape[0])\n",
    "        \n",
    "    return A\n",
    "        #if good > bad:\n",
    "        #    i.append('g')\n",
    "        #elif good < bad:\n",
    "        #    i.append('b')\n",
    "        #else:\n",
    "        #    i.append('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 392418\n",
      "1 / 392418\n",
      "2 / 392418\n",
      "3 / 392418\n",
      "4 / 392418\n",
      "5 / 392418\n",
      "6 / 392418\n",
      "7 / 392418\n",
      "8 / 392418\n",
      "9 / 392418\n",
      "10 / 392418\n",
      "11 / 392418\n",
      "12 / 392418\n",
      "13 / 392418\n",
      "14 / 392418\n",
      "15 / 392418\n",
      "16 / 392418\n",
      "17 / 392418\n",
      "18 / 392418\n",
      "19 / 392418\n",
      "20 / 392418\n",
      "21 / 392418\n",
      "22 / 392418\n",
      "23 / 392418\n",
      "24 / 392418\n",
      "25 / 392418\n",
      "26 / 392418\n",
      "27 / 392418\n",
      "28 / 392418\n",
      "29 / 392418\n",
      "30 / 392418\n",
      "31 / 392418\n",
      "32 / 392418\n",
      "33 / 392418\n",
      "34 / 392418\n",
      "35 / 392418\n",
      "36 / 392418\n",
      "37 / 392418\n",
      "38 / 392418\n",
      "39 / 392418\n",
      "40 / 392418\n",
      "41 / 392418\n",
      "42 / 392418\n",
      "43 / 392418\n",
      "44 / 392418\n",
      "45 / 392418\n",
      "46 / 392418\n",
      "47 / 392418\n",
      "48 / 392418\n",
      "49 / 392418\n",
      "50 / 392418\n",
      "51 / 392418\n",
      "52 / 392418\n",
      "53 / 392418\n",
      "54 / 392418\n",
      "55 / 392418\n",
      "56 / 392418\n",
      "57 / 392418\n",
      "58 / 392418\n",
      "59 / 392418\n",
      "60 / 392418\n",
      "61 / 392418\n",
      "62 / 392418\n",
      "63 / 392418\n",
      "64 / 392418\n",
      "65 / 392418\n",
      "66 / 392418\n",
      "67 / 392418\n",
      "68 / 392418\n",
      "69 / 392418\n",
      "70 / 392418\n",
      "71 / 392418\n",
      "72 / 392418\n",
      "73 / 392418\n",
      "74 / 392418\n",
      "75 / 392418\n",
      "76 / 392418\n",
      "77 / 392418\n",
      "78 / 392418\n",
      "79 / 392418\n",
      "80 / 392418\n",
      "81 / 392418\n",
      "82 / 392418\n",
      "83 / 392418\n",
      "84 / 392418\n",
      "85 / 392418\n",
      "86 / 392418\n",
      "87 / 392418\n",
      "88 / 392418\n",
      "89 / 392418\n",
      "90 / 392418\n",
      "91 / 392418\n",
      "92 / 392418\n",
      "93 / 392418\n",
      "94 / 392418\n",
      "95 / 392418\n",
      "96 / 392418\n",
      "97 / 392418\n",
      "98 / 392418\n",
      "99 / 392418\n",
      "100 / 392418\n",
      "101 / 392418\n",
      "102 / 392418\n",
      "103 / 392418\n",
      "104 / 392418\n",
      "105 / 392418\n",
      "106 / 392418\n",
      "107 / 392418\n",
      "108 / 392418\n",
      "109 / 392418\n",
      "110 / 392418\n",
      "111 / 392418\n",
      "112 / 392418\n",
      "113 / 392418\n",
      "114 / 392418\n",
      "115 / 392418\n",
      "116 / 392418\n",
      "117 / 392418\n",
      "118 / 392418\n",
      "119 / 392418\n",
      "120 / 392418\n",
      "121 / 392418\n",
      "122 / 392418\n",
      "123 / 392418\n",
      "124 / 392418\n",
      "125 / 392418\n",
      "126 / 392418\n",
      "127 / 392418\n",
      "128 / 392418\n",
      "129 / 392418\n",
      "130 / 392418\n",
      "131 / 392418\n",
      "132 / 392418\n",
      "133 / 392418\n",
      "134 / 392418\n",
      "135 / 392418\n",
      "136 / 392418\n",
      "137 / 392418\n",
      "138 / 392418\n",
      "139 / 392418\n",
      "140 / 392418\n",
      "141 / 392418\n",
      "142 / 392418\n",
      "143 / 392418\n",
      "144 / 392418\n",
      "145 / 392418\n",
      "146 / 392418\n",
      "147 / 392418\n",
      "148 / 392418\n",
      "149 / 392418\n",
      "150 / 392418\n",
      "151 / 392418\n",
      "152 / 392418\n",
      "153 / 392418\n",
      "154 / 392418\n",
      "155 / 392418\n",
      "156 / 392418\n",
      "157 / 392418\n",
      "158 / 392418\n",
      "159 / 392418\n",
      "160 / 392418\n",
      "161 / 392418\n",
      "162 / 392418\n",
      "163 / 392418\n",
      "164 / 392418\n",
      "165 / 392418\n",
      "166 / 392418\n",
      "167 / 392418\n",
      "168 / 392418\n",
      "169 / 392418\n",
      "170 / 392418\n",
      "171 / 392418\n",
      "172 / 392418\n",
      "173 / 392418\n",
      "174 / 392418\n",
      "175 / 392418\n",
      "176 / 392418\n",
      "177 / 392418\n",
      "178 / 392418\n",
      "179 / 392418\n",
      "180 / 392418\n",
      "181 / 392418\n",
      "182 / 392418\n",
      "183 / 392418\n",
      "184 / 392418\n",
      "185 / 392418\n",
      "186 / 392418\n",
      "187 / 392418\n",
      "188 / 392418\n",
      "189 / 392418\n",
      "190 / 392418\n",
      "191 / 392418\n",
      "192 / 392418\n",
      "193 / 392418\n",
      "194 / 392418\n",
      "195 / 392418\n",
      "196 / 392418\n",
      "197 / 392418\n",
      "198 / 392418\n",
      "199 / 392418\n",
      "200 / 392418\n",
      "201 / 392418\n",
      "202 / 392418\n",
      "203 / 392418\n",
      "204 / 392418\n",
      "205 / 392418\n",
      "206 / 392418\n",
      "207 / 392418\n",
      "208 / 392418\n",
      "209 / 392418\n",
      "210 / 392418\n",
      "211 / 392418\n",
      "212 / 392418\n",
      "213 / 392418\n",
      "214 / 392418\n",
      "215 / 392418\n",
      "216 / 392418\n",
      "217 / 392418\n",
      "218 / 392418\n",
      "219 / 392418\n",
      "220 / 392418\n",
      "221 / 392418\n",
      "222 / 392418\n",
      "223 / 392418\n",
      "224 / 392418\n",
      "225 / 392418\n",
      "226 / 392418\n",
      "227 / 392418\n",
      "228 / 392418\n",
      "229 / 392418\n",
      "230 / 392418\n",
      "231 / 392418\n",
      "232 / 392418\n",
      "233 / 392418\n",
      "234 / 392418\n",
      "235 / 392418\n",
      "236 / 392418\n",
      "237 / 392418\n",
      "238 / 392418\n",
      "239 / 392418\n",
      "240 / 392418\n",
      "241 / 392418\n",
      "242 / 392418\n",
      "243 / 392418\n",
      "244 / 392418\n",
      "245 / 392418\n",
      "246 / 392418\n",
      "247 / 392418\n",
      "248 / 392418\n",
      "249 / 392418\n",
      "250 / 392418\n",
      "251 / 392418\n",
      "252 / 392418\n",
      "253 / 392418\n",
      "254 / 392418\n",
      "255 / 392418\n",
      "256 / 392418\n",
      "257 / 392418\n",
      "258 / 392418\n",
      "259 / 392418\n",
      "260 / 392418\n",
      "261 / 392418\n",
      "262 / 392418\n",
      "263 / 392418\n",
      "264 / 392418\n",
      "265 / 392418\n",
      "266 / 392418\n",
      "267 / 392418\n",
      "268 / 392418\n",
      "269 / 392418\n",
      "270 / 392418\n",
      "271 / 392418\n",
      "272 / 392418\n",
      "273 / 392418\n",
      "274 / 392418\n",
      "275 / 392418\n",
      "276 / 392418\n",
      "277 / 392418\n",
      "278 / 392418\n",
      "279 / 392418\n",
      "280 / 392418\n",
      "281 / 392418\n",
      "282 / 392418\n",
      "283 / 392418\n",
      "284 / 392418\n",
      "285 / 392418\n",
      "286 / 392418\n",
      "287 / 392418\n",
      "288 / 392418\n",
      "289 / 392418\n",
      "290 / 392418\n",
      "291 / 392418\n",
      "292 / 392418\n",
      "293 / 392418\n",
      "294 / 392418\n",
      "295 / 392418\n",
      "296 / 392418\n",
      "297 / 392418\n",
      "298 / 392418\n",
      "299 / 392418\n",
      "300 / 392418\n",
      "301 / 392418\n",
      "302 / 392418\n",
      "303 / 392418\n",
      "304 / 392418\n",
      "305 / 392418\n",
      "306 / 392418\n",
      "307 / 392418\n",
      "308 / 392418\n",
      "309 / 392418\n",
      "310 / 392418\n",
      "311 / 392418\n",
      "312 / 392418\n",
      "313 / 392418\n",
      "314 / 392418\n",
      "315 / 392418\n",
      "316 / 392418\n",
      "317 / 392418\n",
      "318 / 392418\n",
      "319 / 392418\n",
      "320 / 392418\n",
      "321 / 392418\n",
      "322 / 392418\n",
      "323 / 392418\n",
      "324 / 392418\n",
      "325 / 392418\n",
      "326 / 392418\n",
      "327 / 392418\n",
      "328 / 392418\n",
      "329 / 392418\n",
      "330 / 392418\n",
      "331 / 392418\n",
      "332 / 392418\n",
      "333 / 392418\n",
      "334 / 392418\n",
      "335 / 392418\n",
      "336 / 392418\n",
      "337 / 392418\n",
      "338 / 392418\n",
      "339 / 392418\n",
      "340 / 392418\n",
      "341 / 392418\n",
      "342 / 392418\n",
      "343 / 392418\n",
      "344 / 392418\n",
      "345 / 392418\n",
      "346 / 392418\n",
      "347 / 392418\n",
      "348 / 392418\n",
      "349 / 392418\n",
      "350 / 392418\n",
      "351 / 392418\n",
      "352 / 392418\n",
      "353 / 392418\n",
      "354 / 392418\n",
      "355 / 392418\n",
      "356 / 392418\n",
      "357 / 392418\n",
      "358 / 392418\n",
      "359 / 392418\n",
      "360 / 392418\n",
      "361 / 392418\n",
      "362 / 392418\n",
      "363 / 392418\n",
      "364 / 392418\n",
      "365 / 392418\n",
      "366 / 392418\n",
      "367 / 392418\n",
      "368 / 392418\n",
      "369 / 392418\n",
      "370 / 392418\n",
      "371 / 392418\n",
      "372 / 392418\n",
      "373 / 392418\n",
      "374 / 392418\n",
      "375 / 392418\n",
      "376 / 392418\n",
      "377 / 392418\n",
      "378 / 392418\n",
      "379 / 392418\n",
      "380 / 392418\n",
      "381 / 392418\n",
      "382 / 392418\n",
      "383 / 392418\n",
      "384 / 392418\n",
      "385 / 392418\n",
      "386 / 392418\n",
      "387 / 392418\n",
      "388 / 392418\n",
      "389 / 392418\n",
      "390 / 392418\n",
      "391 / 392418\n",
      "392 / 392418\n",
      "393 / 392418\n",
      "394 / 392418\n",
      "395 / 392418\n",
      "396 / 392418\n",
      "397 / 392418\n",
      "398 / 392418\n",
      "399 / 392418\n",
      "400 / 392418\n",
      "401 / 392418\n",
      "402 / 392418\n",
      "403 / 392418\n",
      "404 / 392418\n",
      "405 / 392418\n",
      "406 / 392418\n",
      "407 / 392418\n",
      "408 / 392418\n",
      "409 / 392418\n",
      "410 / 392418\n",
      "411 / 392418\n",
      "412 / 392418\n",
      "413 / 392418\n",
      "414 / 392418\n",
      "415 / 392418\n",
      "416 / 392418\n",
      "417 / 392418\n",
      "418 / 392418\n",
      "419 / 392418\n",
      "420 / 392418\n",
      "421 / 392418\n",
      "422 / 392418\n",
      "423 / 392418\n",
      "424 / 392418\n",
      "425 / 392418\n",
      "426 / 392418\n",
      "427 / 392418\n",
      "428 / 392418\n",
      "429 / 392418\n",
      "430 / 392418\n",
      "431 / 392418\n",
      "432 / 392418\n",
      "433 / 392418\n",
      "434 / 392418\n",
      "435 / 392418\n",
      "436 / 392418\n",
      "437 / 392418\n",
      "438 / 392418\n",
      "439 / 392418\n",
      "440 / 392418\n",
      "441 / 392418\n",
      "442 / 392418\n",
      "443 / 392418\n",
      "444 / 392418\n",
      "445 / 392418\n",
      "446 / 392418\n",
      "447 / 392418\n",
      "448 / 392418\n",
      "449 / 392418\n",
      "450 / 392418\n",
      "451 / 392418\n",
      "452 / 392418\n",
      "453 / 392418\n",
      "454 / 392418\n",
      "455 / 392418\n",
      "456 / 392418\n",
      "457 / 392418\n",
      "458 / 392418\n",
      "459 / 392418\n",
      "460 / 392418\n",
      "461 / 392418\n",
      "462 / 392418\n",
      "463 / 392418\n",
      "464 / 392418\n",
      "465 / 392418\n",
      "466 / 392418\n",
      "467 / 392418\n",
      "468 / 392418\n",
      "469 / 392418\n",
      "470 / 392418\n",
      "471 / 392418\n",
      "472 / 392418\n",
      "473 / 392418\n",
      "474 / 392418\n",
      "475 / 392418\n",
      "476 / 392418\n",
      "477 / 392418\n",
      "478 / 392418\n",
      "479 / 392418\n",
      "480 / 392418\n",
      "481 / 392418\n",
      "482 / 392418\n",
      "483 / 392418\n",
      "484 / 392418\n",
      "485 / 392418\n",
      "486 / 392418\n",
      "487 / 392418\n",
      "488 / 392418\n",
      "489 / 392418\n",
      "490 / 392418\n",
      "491 / 392418\n",
      "492 / 392418\n",
      "493 / 392418\n",
      "494 / 392418\n",
      "495 / 392418\n",
      "496 / 392418\n",
      "497 / 392418\n",
      "498 / 392418\n",
      "499 / 392418\n",
      "500 / 392418\n",
      "501 / 392418\n",
      "502 / 392418\n",
      "503 / 392418\n",
      "504 / 392418\n",
      "505 / 392418\n",
      "506 / 392418\n",
      "507 / 392418\n",
      "508 / 392418\n",
      "509 / 392418\n",
      "510 / 392418\n",
      "511 / 392418\n",
      "512 / 392418\n",
      "513 / 392418\n",
      "514 / 392418\n",
      "515 / 392418\n",
      "516 / 392418\n",
      "517 / 392418\n",
      "518 / 392418\n",
      "519 / 392418\n",
      "520 / 392418\n",
      "521 / 392418\n",
      "522 / 392418\n",
      "523 / 392418\n",
      "524 / 392418\n",
      "525 / 392418\n",
      "526 / 392418\n",
      "527 / 392418\n",
      "528 / 392418\n",
      "529 / 392418\n",
      "530 / 392418\n",
      "531 / 392418\n",
      "532 / 392418\n",
      "533 / 392418\n",
      "534 / 392418\n",
      "535 / 392418\n",
      "536 / 392418\n",
      "537 / 392418\n",
      "538 / 392418\n",
      "539 / 392418\n",
      "540 / 392418\n",
      "541 / 392418\n",
      "542 / 392418\n",
      "543 / 392418\n",
      "544 / 392418\n",
      "545 / 392418\n",
      "546 / 392418\n",
      "547 / 392418\n",
      "548 / 392418\n",
      "549 / 392418\n",
      "550 / 392418\n",
      "551 / 392418\n",
      "552 / 392418\n",
      "553 / 392418\n",
      "554 / 392418\n",
      "555 / 392418\n",
      "556 / 392418\n",
      "557 / 392418\n",
      "558 / 392418\n",
      "559 / 392418\n",
      "560 / 392418\n",
      "561 / 392418\n",
      "562 / 392418\n",
      "563 / 392418\n",
      "564 / 392418\n",
      "565 / 392418\n",
      "566 / 392418\n",
      "567 / 392418\n",
      "568 / 392418\n",
      "569 / 392418\n",
      "570 / 392418\n",
      "571 / 392418\n",
      "572 / 392418\n",
      "573 / 392418\n",
      "574 / 392418\n",
      "575 / 392418\n",
      "576 / 392418\n",
      "577 / 392418\n",
      "578 / 392418\n",
      "579 / 392418\n",
      "580 / 392418\n",
      "581 / 392418\n",
      "582 / 392418\n",
      "583 / 392418\n",
      "584 / 392418\n",
      "585 / 392418\n",
      "586 / 392418\n",
      "587 / 392418\n",
      "588 / 392418\n",
      "589 / 392418\n",
      "590 / 392418\n",
      "591 / 392418\n",
      "592 / 392418\n",
      "593 / 392418\n",
      "594 / 392418\n",
      "595 / 392418\n",
      "596 / 392418\n",
      "597 / 392418\n",
      "598 / 392418\n",
      "599 / 392418\n",
      "600 / 392418\n",
      "601 / 392418\n",
      "602 / 392418\n",
      "603 / 392418\n",
      "604 / 392418\n",
      "605 / 392418\n",
      "606 / 392418\n",
      "607 / 392418\n",
      "608 / 392418\n",
      "609 / 392418\n",
      "610 / 392418\n",
      "611 / 392418\n",
      "612 / 392418\n",
      "613 / 392418\n",
      "614 / 392418\n",
      "615 / 392418\n",
      "616 / 392418\n",
      "617 / 392418\n",
      "618 / 392418\n",
      "619 / 392418\n",
      "620 / 392418\n",
      "621 / 392418\n",
      "622 / 392418\n",
      "623 / 392418\n",
      "624 / 392418\n",
      "625 / 392418\n",
      "626 / 392418\n",
      "627 / 392418\n",
      "628 / 392418\n",
      "629 / 392418\n",
      "630 / 392418\n",
      "631 / 392418\n",
      "632 / 392418\n",
      "633 / 392418\n",
      "634 / 392418\n",
      "635 / 392418\n",
      "636 / 392418\n",
      "637 / 392418\n",
      "638 / 392418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 / 392418\n",
      "640 / 392418\n",
      "641 / 392418\n",
      "642 / 392418\n",
      "643 / 392418\n",
      "644 / 392418\n",
      "645 / 392418\n",
      "646 / 392418\n",
      "647 / 392418\n",
      "648 / 392418\n",
      "649 / 392418\n",
      "650 / 392418\n",
      "651 / 392418\n",
      "652 / 392418\n",
      "653 / 392418\n",
      "654 / 392418\n",
      "655 / 392418\n",
      "656 / 392418\n",
      "657 / 392418\n",
      "658 / 392418\n",
      "659 / 392418\n",
      "660 / 392418\n",
      "661 / 392418\n",
      "662 / 392418\n",
      "663 / 392418\n",
      "664 / 392418\n",
      "665 / 392418\n",
      "666 / 392418\n",
      "667 / 392418\n",
      "668 / 392418\n",
      "669 / 392418\n",
      "670 / 392418\n",
      "671 / 392418\n",
      "672 / 392418\n",
      "673 / 392418\n",
      "674 / 392418\n",
      "675 / 392418\n",
      "676 / 392418\n",
      "677 / 392418\n",
      "678 / 392418\n",
      "679 / 392418\n",
      "680 / 392418\n",
      "681 / 392418\n",
      "682 / 392418\n",
      "683 / 392418\n",
      "684 / 392418\n",
      "685 / 392418\n",
      "686 / 392418\n",
      "687 / 392418\n",
      "688 / 392418\n",
      "689 / 392418\n",
      "690 / 392418\n",
      "691 / 392418\n",
      "692 / 392418\n",
      "693 / 392418\n",
      "694 / 392418\n",
      "695 / 392418\n",
      "696 / 392418\n",
      "697 / 392418\n",
      "698 / 392418\n",
      "699 / 392418\n",
      "700 / 392418\n",
      "701 / 392418\n",
      "702 / 392418\n",
      "703 / 392418\n",
      "704 / 392418\n",
      "705 / 392418\n",
      "706 / 392418\n",
      "707 / 392418\n",
      "708 / 392418\n",
      "709 / 392418\n",
      "710 / 392418\n",
      "711 / 392418\n",
      "712 / 392418\n",
      "713 / 392418\n",
      "714 / 392418\n",
      "715 / 392418\n",
      "716 / 392418\n",
      "717 / 392418\n",
      "718 / 392418\n",
      "719 / 392418\n",
      "720 / 392418\n",
      "721 / 392418\n",
      "722 / 392418\n",
      "723 / 392418\n",
      "724 / 392418\n",
      "725 / 392418\n",
      "726 / 392418\n",
      "727 / 392418\n",
      "728 / 392418\n",
      "729 / 392418\n",
      "730 / 392418\n",
      "731 / 392418\n",
      "732 / 392418\n",
      "733 / 392418\n",
      "734 / 392418\n",
      "735 / 392418\n",
      "736 / 392418\n",
      "737 / 392418\n",
      "738 / 392418\n",
      "739 / 392418\n",
      "740 / 392418\n",
      "741 / 392418\n",
      "742 / 392418\n",
      "743 / 392418\n",
      "744 / 392418\n",
      "745 / 392418\n",
      "746 / 392418\n",
      "747 / 392418\n",
      "748 / 392418\n",
      "749 / 392418\n",
      "750 / 392418\n",
      "751 / 392418\n",
      "752 / 392418\n",
      "753 / 392418\n",
      "754 / 392418\n",
      "755 / 392418\n",
      "756 / 392418\n",
      "757 / 392418\n",
      "758 / 392418\n",
      "759 / 392418\n",
      "760 / 392418\n",
      "761 / 392418\n",
      "762 / 392418\n",
      "763 / 392418\n",
      "764 / 392418\n",
      "765 / 392418\n",
      "766 / 392418\n",
      "767 / 392418\n",
      "768 / 392418\n",
      "769 / 392418\n",
      "770 / 392418\n",
      "771 / 392418\n",
      "772 / 392418\n",
      "773 / 392418\n",
      "774 / 392418\n",
      "775 / 392418\n",
      "776 / 392418\n",
      "777 / 392418\n",
      "778 / 392418\n",
      "779 / 392418\n",
      "780 / 392418\n",
      "781 / 392418\n",
      "782 / 392418\n",
      "783 / 392418\n",
      "784 / 392418\n",
      "785 / 392418\n",
      "786 / 392418\n",
      "787 / 392418\n",
      "788 / 392418\n",
      "789 / 392418\n",
      "790 / 392418\n",
      "791 / 392418\n",
      "792 / 392418\n",
      "793 / 392418\n",
      "794 / 392418\n",
      "795 / 392418\n",
      "796 / 392418\n",
      "797 / 392418\n",
      "798 / 392418\n",
      "799 / 392418\n",
      "800 / 392418\n",
      "801 / 392418\n",
      "802 / 392418\n",
      "803 / 392418\n",
      "804 / 392418\n",
      "805 / 392418\n",
      "806 / 392418\n",
      "807 / 392418\n",
      "808 / 392418\n",
      "809 / 392418\n",
      "810 / 392418\n",
      "811 / 392418\n",
      "812 / 392418\n",
      "813 / 392418\n",
      "814 / 392418\n",
      "815 / 392418\n",
      "816 / 392418\n",
      "817 / 392418\n",
      "818 / 392418\n",
      "819 / 392418\n",
      "820 / 392418\n",
      "821 / 392418\n",
      "822 / 392418\n",
      "823 / 392418\n",
      "824 / 392418\n",
      "825 / 392418\n",
      "826 / 392418\n",
      "827 / 392418\n",
      "828 / 392418\n",
      "829 / 392418\n",
      "830 / 392418\n",
      "831 / 392418\n",
      "832 / 392418\n",
      "833 / 392418\n",
      "834 / 392418\n",
      "835 / 392418\n",
      "836 / 392418\n",
      "837 / 392418\n",
      "838 / 392418\n",
      "839 / 392418\n",
      "840 / 392418\n",
      "841 / 392418\n",
      "842 / 392418\n",
      "843 / 392418\n",
      "844 / 392418\n",
      "845 / 392418\n",
      "846 / 392418\n",
      "847 / 392418\n",
      "848 / 392418\n",
      "849 / 392418\n",
      "850 / 392418\n",
      "851 / 392418\n",
      "852 / 392418\n",
      "853 / 392418\n",
      "854 / 392418\n",
      "855 / 392418\n",
      "856 / 392418\n",
      "857 / 392418\n",
      "858 / 392418\n",
      "859 / 392418\n",
      "860 / 392418\n",
      "861 / 392418\n",
      "862 / 392418\n",
      "863 / 392418\n",
      "864 / 392418\n",
      "865 / 392418\n",
      "866 / 392418\n",
      "867 / 392418\n",
      "868 / 392418\n",
      "869 / 392418\n",
      "870 / 392418\n",
      "871 / 392418\n",
      "872 / 392418\n",
      "873 / 392418\n",
      "874 / 392418\n",
      "875 / 392418\n",
      "876 / 392418\n",
      "877 / 392418\n",
      "878 / 392418\n",
      "879 / 392418\n",
      "880 / 392418\n",
      "881 / 392418\n",
      "882 / 392418\n",
      "883 / 392418\n",
      "884 / 392418\n",
      "885 / 392418\n",
      "886 / 392418\n",
      "887 / 392418\n",
      "888 / 392418\n",
      "889 / 392418\n",
      "890 / 392418\n",
      "891 / 392418\n",
      "892 / 392418\n",
      "893 / 392418\n",
      "894 / 392418\n",
      "895 / 392418\n",
      "896 / 392418\n",
      "897 / 392418\n",
      "898 / 392418\n",
      "899 / 392418\n",
      "900 / 392418\n",
      "901 / 392418\n",
      "902 / 392418\n",
      "903 / 392418\n",
      "904 / 392418\n",
      "905 / 392418\n",
      "906 / 392418\n",
      "907 / 392418\n",
      "908 / 392418\n",
      "909 / 392418\n",
      "910 / 392418\n",
      "911 / 392418\n",
      "912 / 392418\n",
      "913 / 392418\n",
      "914 / 392418\n",
      "915 / 392418\n",
      "916 / 392418\n",
      "917 / 392418\n",
      "918 / 392418\n",
      "919 / 392418\n",
      "920 / 392418\n",
      "921 / 392418\n",
      "922 / 392418\n",
      "923 / 392418\n",
      "924 / 392418\n",
      "925 / 392418\n",
      "926 / 392418\n",
      "927 / 392418\n",
      "928 / 392418\n",
      "929 / 392418\n",
      "930 / 392418\n",
      "931 / 392418\n",
      "932 / 392418\n",
      "933 / 392418\n",
      "934 / 392418\n",
      "935 / 392418\n",
      "936 / 392418\n",
      "937 / 392418\n",
      "938 / 392418\n",
      "939 / 392418\n",
      "940 / 392418\n",
      "941 / 392418\n",
      "942 / 392418\n",
      "943 / 392418\n",
      "944 / 392418\n",
      "945 / 392418\n",
      "946 / 392418\n",
      "947 / 392418\n",
      "948 / 392418\n",
      "949 / 392418\n",
      "950 / 392418\n",
      "951 / 392418\n",
      "952 / 392418\n",
      "953 / 392418\n",
      "954 / 392418\n",
      "955 / 392418\n",
      "956 / 392418\n",
      "957 / 392418\n",
      "958 / 392418\n",
      "959 / 392418\n",
      "960 / 392418\n",
      "961 / 392418\n",
      "962 / 392418\n",
      "963 / 392418\n",
      "964 / 392418\n",
      "965 / 392418\n",
      "966 / 392418\n",
      "967 / 392418\n",
      "968 / 392418\n",
      "969 / 392418\n",
      "970 / 392418\n",
      "971 / 392418\n",
      "972 / 392418\n",
      "973 / 392418\n",
      "974 / 392418\n",
      "975 / 392418\n",
      "976 / 392418\n",
      "977 / 392418\n",
      "978 / 392418\n",
      "979 / 392418\n",
      "980 / 392418\n",
      "981 / 392418\n",
      "982 / 392418\n",
      "983 / 392418\n",
      "984 / 392418\n",
      "985 / 392418\n",
      "986 / 392418\n",
      "987 / 392418\n",
      "988 / 392418\n",
      "989 / 392418\n",
      "990 / 392418\n",
      "991 / 392418\n",
      "992 / 392418\n",
      "993 / 392418\n",
      "994 / 392418\n",
      "995 / 392418\n",
      "996 / 392418\n",
      "997 / 392418\n",
      "998 / 392418\n",
      "999 / 392418\n",
      "1000 / 392418\n",
      "1001 / 392418\n",
      "1002 / 392418\n",
      "1003 / 392418\n",
      "1004 / 392418\n",
      "1005 / 392418\n",
      "1006 / 392418\n",
      "1007 / 392418\n",
      "1008 / 392418\n",
      "1009 / 392418\n",
      "1010 / 392418\n",
      "1011 / 392418\n",
      "1012 / 392418\n",
      "1013 / 392418\n",
      "1014 / 392418\n",
      "1015 / 392418\n",
      "1016 / 392418\n",
      "1017 / 392418\n",
      "1018 / 392418\n",
      "1019 / 392418\n",
      "1020 / 392418\n",
      "1021 / 392418\n",
      "1022 / 392418\n",
      "1023 / 392418\n",
      "1024 / 392418\n",
      "1025 / 392418\n",
      "1026 / 392418\n",
      "1027 / 392418\n",
      "1028 / 392418\n",
      "1029 / 392418\n",
      "1030 / 392418\n",
      "1031 / 392418\n",
      "1032 / 392418\n",
      "1033 / 392418\n",
      "1034 / 392418\n",
      "1035 / 392418\n",
      "1036 / 392418\n",
      "1037 / 392418\n",
      "1038 / 392418\n",
      "1039 / 392418\n",
      "1040 / 392418\n",
      "1041 / 392418\n",
      "1042 / 392418\n",
      "1043 / 392418\n",
      "1044 / 392418\n",
      "1045 / 392418\n",
      "1046 / 392418\n",
      "1047 / 392418\n",
      "1048 / 392418\n",
      "1049 / 392418\n",
      "1050 / 392418\n",
      "1051 / 392418\n",
      "1052 / 392418\n",
      "1053 / 392418\n",
      "1054 / 392418\n",
      "1055 / 392418\n",
      "1056 / 392418\n",
      "1057 / 392418\n",
      "1058 / 392418\n",
      "1059 / 392418\n",
      "1060 / 392418\n",
      "1061 / 392418\n",
      "1062 / 392418\n",
      "1063 / 392418\n",
      "1064 / 392418\n",
      "1065 / 392418\n",
      "1066 / 392418\n",
      "1067 / 392418\n",
      "1068 / 392418\n",
      "1069 / 392418\n",
      "1070 / 392418\n",
      "1071 / 392418\n",
      "1072 / 392418\n",
      "1073 / 392418\n",
      "1074 / 392418\n",
      "1075 / 392418\n",
      "1076 / 392418\n",
      "1077 / 392418\n",
      "1078 / 392418\n",
      "1079 / 392418\n",
      "1080 / 392418\n",
      "1081 / 392418\n",
      "1082 / 392418\n",
      "1083 / 392418\n",
      "1084 / 392418\n",
      "1085 / 392418\n",
      "1086 / 392418\n",
      "1087 / 392418\n",
      "1088 / 392418\n",
      "1089 / 392418\n",
      "1090 / 392418\n",
      "1091 / 392418\n",
      "1092 / 392418\n",
      "1093 / 392418\n",
      "1094 / 392418\n",
      "1095 / 392418\n",
      "1096 / 392418\n",
      "1097 / 392418\n",
      "1098 / 392418\n",
      "1099 / 392418\n",
      "1100 / 392418\n",
      "1101 / 392418\n",
      "1102 / 392418\n",
      "1103 / 392418\n",
      "1104 / 392418\n",
      "1105 / 392418\n",
      "1106 / 392418\n",
      "1107 / 392418\n",
      "1108 / 392418\n",
      "1109 / 392418\n",
      "1110 / 392418\n",
      "1111 / 392418\n",
      "1112 / 392418\n",
      "1113 / 392418\n",
      "1114 / 392418\n",
      "1115 / 392418\n",
      "1116 / 392418\n",
      "1117 / 392418\n",
      "1118 / 392418\n",
      "1119 / 392418\n",
      "1120 / 392418\n",
      "1121 / 392418\n",
      "1122 / 392418\n",
      "1123 / 392418\n",
      "1124 / 392418\n",
      "1125 / 392418\n",
      "1126 / 392418\n",
      "1127 / 392418\n",
      "1128 / 392418\n",
      "1129 / 392418\n",
      "1130 / 392418\n",
      "1131 / 392418\n",
      "1132 / 392418\n",
      "1133 / 392418\n",
      "1134 / 392418\n",
      "1135 / 392418\n",
      "1136 / 392418\n",
      "1137 / 392418\n",
      "1138 / 392418\n",
      "1139 / 392418\n",
      "1140 / 392418\n",
      "1141 / 392418\n",
      "1142 / 392418\n",
      "1143 / 392418\n",
      "1144 / 392418\n",
      "1145 / 392418\n",
      "1146 / 392418\n",
      "1147 / 392418\n",
      "1148 / 392418\n",
      "1149 / 392418\n",
      "1150 / 392418\n",
      "1151 / 392418\n",
      "1152 / 392418\n",
      "1153 / 392418\n",
      "1154 / 392418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-c92e402b937e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-324-2045b4ed5720>\u001b[0m in \u001b[0;36mknn_predict\u001b[0;34m(test_data, train_data, k_value, train_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0meu_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclideanDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0meu_Distance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meu_dist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-254-9786b656491c>\u001b[0m in \u001b[0;36meuclideanDist\u001b[0;34m(x, xi)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A=knn_predict(X, yy, 5, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "        eu_Distance =[]\n",
    "        knn = []\n",
    "        good = 0        \n",
    "        bad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=X\n",
    "train_data=yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "jj=0\n",
    "i=test_data[ii]\n",
    "j=train_data[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116,)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116,)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eu_dist = euclideanDist(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0254513781711219"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eu_Distance.append([jj,eu_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1.0254513781711219}, {-0.9745486218288781, 2}]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eu_Distance.append([2,1.0])\n",
    "eu_Distance.append([1,0.8])\n",
    "eu_Distance.append([3,-0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "hi=sorted(eu_Distance, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, -0.2], [1, 0.8], [2, 1.0]]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1.0254513781711219}, {-0.9745486218288781, 2}]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0254513781711219"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclideanDist(X[0], yy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392418"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a.tofile('foo.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 116)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418,)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6110.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_array1[:,115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature79</th>\n",
       "      <th>feature80</th>\n",
       "      <th>feature81</th>\n",
       "      <th>feature82</th>\n",
       "      <th>feature83</th>\n",
       "      <th>feature84</th>\n",
       "      <th>feature85</th>\n",
       "      <th>feature86</th>\n",
       "      <th>feature87</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392418</td>\n",
       "      <td>0.088970</td>\n",
       "      <td>-0.012451</td>\n",
       "      <td>0.226408</td>\n",
       "      <td>-1.386858</td>\n",
       "      <td>-1.066616</td>\n",
       "      <td>0.636430</td>\n",
       "      <td>-0.805733</td>\n",
       "      <td>-0.478093</td>\n",
       "      <td>-0.536539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785307</td>\n",
       "      <td>-0.491378</td>\n",
       "      <td>-0.291151</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>-0.807633</td>\n",
       "      <td>-0.394544</td>\n",
       "      <td>-0.681540</td>\n",
       "      <td>-0.707518</td>\n",
       "      <td>-0.775872</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392419</td>\n",
       "      <td>-1.004904</td>\n",
       "      <td>-0.034484</td>\n",
       "      <td>-0.345187</td>\n",
       "      <td>0.179278</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.752589</td>\n",
       "      <td>2.233694</td>\n",
       "      <td>0.651315</td>\n",
       "      <td>1.896860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079682</td>\n",
       "      <td>1.490679</td>\n",
       "      <td>-0.082252</td>\n",
       "      <td>-1.079956</td>\n",
       "      <td>1.607502</td>\n",
       "      <td>-1.805872</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>-0.108615</td>\n",
       "      <td>1.492027</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392420</td>\n",
       "      <td>1.100924</td>\n",
       "      <td>-0.023984</td>\n",
       "      <td>-0.329857</td>\n",
       "      <td>0.661071</td>\n",
       "      <td>1.076176</td>\n",
       "      <td>0.414028</td>\n",
       "      <td>0.194951</td>\n",
       "      <td>0.833402</td>\n",
       "      <td>0.778437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.596572</td>\n",
       "      <td>0.640618</td>\n",
       "      <td>1.219347</td>\n",
       "      <td>-1.060589</td>\n",
       "      <td>0.290406</td>\n",
       "      <td>0.772820</td>\n",
       "      <td>1.368938</td>\n",
       "      <td>1.088984</td>\n",
       "      <td>-0.433057</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>392421</td>\n",
       "      <td>0.939863</td>\n",
       "      <td>-0.018097</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>-1.418409</td>\n",
       "      <td>0.359216</td>\n",
       "      <td>-0.135353</td>\n",
       "      <td>-1.482310</td>\n",
       "      <td>-0.057569</td>\n",
       "      <td>0.169539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.516610</td>\n",
       "      <td>-0.260976</td>\n",
       "      <td>0.265216</td>\n",
       "      <td>1.133491</td>\n",
       "      <td>0.500493</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>-0.783961</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392422</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>-0.577442</td>\n",
       "      <td>-0.068010</td>\n",
       "      <td>-1.572975</td>\n",
       "      <td>-0.329777</td>\n",
       "      <td>0.267620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737593</td>\n",
       "      <td>0.037424</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.544575</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>-0.131309</td>\n",
       "      <td>-0.877661</td>\n",
       "      <td>0.461268</td>\n",
       "      <td>-0.238349</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>392423</td>\n",
       "      <td>0.837824</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.273588</td>\n",
       "      <td>1.056372</td>\n",
       "      <td>-0.230143</td>\n",
       "      <td>0.573043</td>\n",
       "      <td>0.645608</td>\n",
       "      <td>-0.483777</td>\n",
       "      <td>-0.217809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996371</td>\n",
       "      <td>-0.438168</td>\n",
       "      <td>0.167159</td>\n",
       "      <td>1.013741</td>\n",
       "      <td>-0.541207</td>\n",
       "      <td>-0.093378</td>\n",
       "      <td>-0.391347</td>\n",
       "      <td>0.692741</td>\n",
       "      <td>-0.636414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>392424</td>\n",
       "      <td>1.040767</td>\n",
       "      <td>-0.152174</td>\n",
       "      <td>0.344835</td>\n",
       "      <td>-0.737765</td>\n",
       "      <td>0.245411</td>\n",
       "      <td>1.330195</td>\n",
       "      <td>-0.122921</td>\n",
       "      <td>0.752297</td>\n",
       "      <td>0.385699</td>\n",
       "      <td>...</td>\n",
       "      <td>3.819098</td>\n",
       "      <td>1.698990</td>\n",
       "      <td>0.942540</td>\n",
       "      <td>-1.111067</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>1.077803</td>\n",
       "      <td>1.040696</td>\n",
       "      <td>2.926289</td>\n",
       "      <td>1.866744</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>392425</td>\n",
       "      <td>-0.699206</td>\n",
       "      <td>-0.035928</td>\n",
       "      <td>0.175071</td>\n",
       "      <td>-0.173649</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>0.419827</td>\n",
       "      <td>-0.073032</td>\n",
       "      <td>0.496059</td>\n",
       "      <td>-0.486717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748197</td>\n",
       "      <td>-0.190228</td>\n",
       "      <td>-0.558712</td>\n",
       "      <td>1.102890</td>\n",
       "      <td>-0.556398</td>\n",
       "      <td>0.783577</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>-0.633712</td>\n",
       "      <td>0.313645</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>392426</td>\n",
       "      <td>-1.250826</td>\n",
       "      <td>-0.018475</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-1.590578</td>\n",
       "      <td>-1.054722</td>\n",
       "      <td>-0.402337</td>\n",
       "      <td>0.551442</td>\n",
       "      <td>-1.204170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653698</td>\n",
       "      <td>-0.896002</td>\n",
       "      <td>-1.498425</td>\n",
       "      <td>0.071348</td>\n",
       "      <td>-0.934304</td>\n",
       "      <td>-2.766871</td>\n",
       "      <td>-0.817718</td>\n",
       "      <td>-0.609713</td>\n",
       "      <td>-0.771024</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>392427</td>\n",
       "      <td>1.069376</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.642103</td>\n",
       "      <td>0.213534</td>\n",
       "      <td>-0.151496</td>\n",
       "      <td>-0.172658</td>\n",
       "      <td>-0.396895</td>\n",
       "      <td>-0.149623</td>\n",
       "      <td>-0.384482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680009</td>\n",
       "      <td>0.175432</td>\n",
       "      <td>-0.185755</td>\n",
       "      <td>-0.756882</td>\n",
       "      <td>-0.433311</td>\n",
       "      <td>0.301302</td>\n",
       "      <td>0.215193</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>392428</td>\n",
       "      <td>-0.917364</td>\n",
       "      <td>-0.118647</td>\n",
       "      <td>-0.285822</td>\n",
       "      <td>0.533232</td>\n",
       "      <td>-0.187045</td>\n",
       "      <td>-0.718213</td>\n",
       "      <td>-1.453297</td>\n",
       "      <td>0.059654</td>\n",
       "      <td>-0.444266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079491</td>\n",
       "      <td>-0.538677</td>\n",
       "      <td>-0.726547</td>\n",
       "      <td>0.533653</td>\n",
       "      <td>-0.352214</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-0.554619</td>\n",
       "      <td>-0.170540</td>\n",
       "      <td>-0.312947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>392429</td>\n",
       "      <td>-0.713333</td>\n",
       "      <td>-0.103237</td>\n",
       "      <td>-0.571024</td>\n",
       "      <td>0.984154</td>\n",
       "      <td>0.525436</td>\n",
       "      <td>0.782510</td>\n",
       "      <td>-0.287802</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>0.990423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327812</td>\n",
       "      <td>0.662191</td>\n",
       "      <td>0.897151</td>\n",
       "      <td>-0.068489</td>\n",
       "      <td>0.541205</td>\n",
       "      <td>-0.984759</td>\n",
       "      <td>-0.007678</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.218440</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>392430</td>\n",
       "      <td>-1.046641</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.243694</td>\n",
       "      <td>1.692588</td>\n",
       "      <td>1.320556</td>\n",
       "      <td>-0.212556</td>\n",
       "      <td>-1.111035</td>\n",
       "      <td>-0.062676</td>\n",
       "      <td>-0.542785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365200</td>\n",
       "      <td>-0.742857</td>\n",
       "      <td>-0.958454</td>\n",
       "      <td>1.056052</td>\n",
       "      <td>-0.698245</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>-0.373747</td>\n",
       "      <td>-0.296632</td>\n",
       "      <td>0.157238</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>392431</td>\n",
       "      <td>-1.328634</td>\n",
       "      <td>-0.047121</td>\n",
       "      <td>-0.366175</td>\n",
       "      <td>-1.130283</td>\n",
       "      <td>-0.517681</td>\n",
       "      <td>0.633059</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.204533</td>\n",
       "      <td>-0.214171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679040</td>\n",
       "      <td>-0.232199</td>\n",
       "      <td>-0.428869</td>\n",
       "      <td>-1.190743</td>\n",
       "      <td>-0.248285</td>\n",
       "      <td>-0.180009</td>\n",
       "      <td>-0.688850</td>\n",
       "      <td>-0.596113</td>\n",
       "      <td>-0.368932</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>392432</td>\n",
       "      <td>-0.819428</td>\n",
       "      <td>-0.018268</td>\n",
       "      <td>-0.047686</td>\n",
       "      <td>-0.471116</td>\n",
       "      <td>-1.190888</td>\n",
       "      <td>-0.608216</td>\n",
       "      <td>-0.839902</td>\n",
       "      <td>-0.018879</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.957400</td>\n",
       "      <td>0.251832</td>\n",
       "      <td>-0.298243</td>\n",
       "      <td>-0.469795</td>\n",
       "      <td>-0.308584</td>\n",
       "      <td>-1.365618</td>\n",
       "      <td>-0.215089</td>\n",
       "      <td>-0.847685</td>\n",
       "      <td>0.694955</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>392433</td>\n",
       "      <td>0.437786</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>-0.466507</td>\n",
       "      <td>1.514302</td>\n",
       "      <td>2.746221</td>\n",
       "      <td>1.282836</td>\n",
       "      <td>-1.215845</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>0.619806</td>\n",
       "      <td>...</td>\n",
       "      <td>5.654401</td>\n",
       "      <td>0.937721</td>\n",
       "      <td>0.782412</td>\n",
       "      <td>-1.413585</td>\n",
       "      <td>0.208622</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.609862</td>\n",
       "      <td>3.137489</td>\n",
       "      <td>-0.137890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>392434</td>\n",
       "      <td>0.137740</td>\n",
       "      <td>-0.016819</td>\n",
       "      <td>0.092436</td>\n",
       "      <td>-0.545424</td>\n",
       "      <td>0.131016</td>\n",
       "      <td>-0.506191</td>\n",
       "      <td>0.209493</td>\n",
       "      <td>-0.450209</td>\n",
       "      <td>-0.487388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609673</td>\n",
       "      <td>-0.657740</td>\n",
       "      <td>-0.387053</td>\n",
       "      <td>1.177475</td>\n",
       "      <td>-0.711263</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>-0.687852</td>\n",
       "      <td>3.372954</td>\n",
       "      <td>-0.583500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>392435</td>\n",
       "      <td>1.019507</td>\n",
       "      <td>-0.028070</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>-0.421863</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>-2.392677</td>\n",
       "      <td>-0.323490</td>\n",
       "      <td>2.167833</td>\n",
       "      <td>0.636916</td>\n",
       "      <td>...</td>\n",
       "      <td>2.542898</td>\n",
       "      <td>1.390568</td>\n",
       "      <td>1.577312</td>\n",
       "      <td>-1.745083</td>\n",
       "      <td>0.672999</td>\n",
       "      <td>0.779755</td>\n",
       "      <td>2.503408</td>\n",
       "      <td>1.873678</td>\n",
       "      <td>0.600182</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>392436</td>\n",
       "      <td>-0.102105</td>\n",
       "      <td>-0.040849</td>\n",
       "      <td>-0.552134</td>\n",
       "      <td>1.862996</td>\n",
       "      <td>1.896060</td>\n",
       "      <td>-2.840276</td>\n",
       "      <td>1.624334</td>\n",
       "      <td>1.326741</td>\n",
       "      <td>2.270326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.179476</td>\n",
       "      <td>0.830638</td>\n",
       "      <td>2.209012</td>\n",
       "      <td>1.485389</td>\n",
       "      <td>1.845857</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>1.684238</td>\n",
       "      <td>0.949540</td>\n",
       "      <td>2.279930</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392437</td>\n",
       "      <td>0.775261</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.080540</td>\n",
       "      <td>-0.699094</td>\n",
       "      <td>-0.380927</td>\n",
       "      <td>-0.294925</td>\n",
       "      <td>-0.590150</td>\n",
       "      <td>-0.495735</td>\n",
       "      <td>-0.337198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978537</td>\n",
       "      <td>-0.407864</td>\n",
       "      <td>-0.045793</td>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.684786</td>\n",
       "      <td>0.744371</td>\n",
       "      <td>-0.304092</td>\n",
       "      <td>-0.831600</td>\n",
       "      <td>-0.855002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>392438</td>\n",
       "      <td>-1.517234</td>\n",
       "      <td>-0.028044</td>\n",
       "      <td>-0.171356</td>\n",
       "      <td>0.688223</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.053559</td>\n",
       "      <td>-0.437092</td>\n",
       "      <td>0.468593</td>\n",
       "      <td>-0.516839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115232</td>\n",
       "      <td>-0.670385</td>\n",
       "      <td>-1.360465</td>\n",
       "      <td>0.710794</td>\n",
       "      <td>0.151484</td>\n",
       "      <td>-1.288198</td>\n",
       "      <td>-0.853195</td>\n",
       "      <td>-0.309323</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>392439</td>\n",
       "      <td>-0.119101</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>-0.476054</td>\n",
       "      <td>-0.387816</td>\n",
       "      <td>0.376931</td>\n",
       "      <td>1.076661</td>\n",
       "      <td>-0.485520</td>\n",
       "      <td>-0.137305</td>\n",
       "      <td>0.575163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109986</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>-0.162897</td>\n",
       "      <td>-1.000919</td>\n",
       "      <td>0.657322</td>\n",
       "      <td>-0.175513</td>\n",
       "      <td>-0.433287</td>\n",
       "      <td>-0.164804</td>\n",
       "      <td>-0.084506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>392440</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>-0.049330</td>\n",
       "      <td>-0.198842</td>\n",
       "      <td>-0.434550</td>\n",
       "      <td>-0.545066</td>\n",
       "      <td>0.878899</td>\n",
       "      <td>-1.554780</td>\n",
       "      <td>-0.847609</td>\n",
       "      <td>-0.150480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.853726</td>\n",
       "      <td>0.095309</td>\n",
       "      <td>-0.040793</td>\n",
       "      <td>-0.404032</td>\n",
       "      <td>-0.486408</td>\n",
       "      <td>0.040451</td>\n",
       "      <td>-0.803356</td>\n",
       "      <td>1.489539</td>\n",
       "      <td>-0.659932</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>392441</td>\n",
       "      <td>0.550419</td>\n",
       "      <td>-0.026467</td>\n",
       "      <td>-0.072219</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>-0.976189</td>\n",
       "      <td>1.323495</td>\n",
       "      <td>0.253387</td>\n",
       "      <td>1.844839</td>\n",
       "      <td>1.341516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160816</td>\n",
       "      <td>2.494855</td>\n",
       "      <td>1.591581</td>\n",
       "      <td>-1.216856</td>\n",
       "      <td>1.182917</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>1.575238</td>\n",
       "      <td>-1.000941</td>\n",
       "      <td>1.627632</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>392442</td>\n",
       "      <td>-2.039502</td>\n",
       "      <td>-0.218888</td>\n",
       "      <td>-1.583631</td>\n",
       "      <td>0.768805</td>\n",
       "      <td>-0.438828</td>\n",
       "      <td>0.191468</td>\n",
       "      <td>-0.582467</td>\n",
       "      <td>0.803562</td>\n",
       "      <td>2.687550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465200</td>\n",
       "      <td>0.739912</td>\n",
       "      <td>1.691338</td>\n",
       "      <td>0.422853</td>\n",
       "      <td>2.082296</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.047595</td>\n",
       "      <td>-0.373742</td>\n",
       "      <td>1.331072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>392443</td>\n",
       "      <td>-1.280876</td>\n",
       "      <td>-0.014128</td>\n",
       "      <td>0.404512</td>\n",
       "      <td>1.237853</td>\n",
       "      <td>0.735989</td>\n",
       "      <td>-0.206958</td>\n",
       "      <td>0.707058</td>\n",
       "      <td>0.851077</td>\n",
       "      <td>-1.284993</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140630</td>\n",
       "      <td>-1.158208</td>\n",
       "      <td>-1.326836</td>\n",
       "      <td>1.014244</td>\n",
       "      <td>-0.755766</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>-0.449904</td>\n",
       "      <td>-0.845454</td>\n",
       "      <td>-0.714069</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>392444</td>\n",
       "      <td>0.719944</td>\n",
       "      <td>-0.019219</td>\n",
       "      <td>-0.113005</td>\n",
       "      <td>0.408766</td>\n",
       "      <td>-0.015992</td>\n",
       "      <td>-0.594554</td>\n",
       "      <td>-1.076209</td>\n",
       "      <td>-0.907659</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.196119</td>\n",
       "      <td>-0.549985</td>\n",
       "      <td>-0.236283</td>\n",
       "      <td>0.148215</td>\n",
       "      <td>-0.473299</td>\n",
       "      <td>0.354291</td>\n",
       "      <td>-0.128664</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>392445</td>\n",
       "      <td>0.680960</td>\n",
       "      <td>-0.017012</td>\n",
       "      <td>-0.207428</td>\n",
       "      <td>1.595523</td>\n",
       "      <td>-0.502677</td>\n",
       "      <td>1.371180</td>\n",
       "      <td>-0.136794</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>2.117736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542771</td>\n",
       "      <td>1.364404</td>\n",
       "      <td>1.837216</td>\n",
       "      <td>-0.092271</td>\n",
       "      <td>1.579427</td>\n",
       "      <td>0.319331</td>\n",
       "      <td>0.725922</td>\n",
       "      <td>0.303287</td>\n",
       "      <td>0.658043</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>392446</td>\n",
       "      <td>0.898747</td>\n",
       "      <td>-0.011921</td>\n",
       "      <td>0.137916</td>\n",
       "      <td>-0.924046</td>\n",
       "      <td>1.366975</td>\n",
       "      <td>-0.644433</td>\n",
       "      <td>-0.339379</td>\n",
       "      <td>-0.543002</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>...</td>\n",
       "      <td>2.314266</td>\n",
       "      <td>-0.007253</td>\n",
       "      <td>0.270167</td>\n",
       "      <td>-0.300871</td>\n",
       "      <td>-0.117714</td>\n",
       "      <td>0.296281</td>\n",
       "      <td>-0.369952</td>\n",
       "      <td>2.460227</td>\n",
       "      <td>-0.309228</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>392447</td>\n",
       "      <td>-3.063437</td>\n",
       "      <td>-1.469658</td>\n",
       "      <td>-3.516468</td>\n",
       "      <td>-0.635247</td>\n",
       "      <td>-0.133773</td>\n",
       "      <td>-0.122668</td>\n",
       "      <td>-1.005178</td>\n",
       "      <td>0.913962</td>\n",
       "      <td>-0.488834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.869591</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>-1.168895</td>\n",
       "      <td>-0.187472</td>\n",
       "      <td>1.836652</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>-0.718960</td>\n",
       "      <td>1.157783</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211645</th>\n",
       "      <td>604063</td>\n",
       "      <td>-0.102736</td>\n",
       "      <td>-0.024948</td>\n",
       "      <td>-0.144690</td>\n",
       "      <td>-0.092909</td>\n",
       "      <td>-1.101083</td>\n",
       "      <td>-0.435454</td>\n",
       "      <td>1.259344</td>\n",
       "      <td>-0.404340</td>\n",
       "      <td>-0.731295</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044008</td>\n",
       "      <td>-0.915253</td>\n",
       "      <td>-0.657344</td>\n",
       "      <td>0.702763</td>\n",
       "      <td>-0.406181</td>\n",
       "      <td>-1.008614</td>\n",
       "      <td>-0.788394</td>\n",
       "      <td>-0.715539</td>\n",
       "      <td>-0.390790</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211646</th>\n",
       "      <td>604064</td>\n",
       "      <td>1.210540</td>\n",
       "      <td>-0.015561</td>\n",
       "      <td>0.163281</td>\n",
       "      <td>-1.455785</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>0.794949</td>\n",
       "      <td>-1.119945</td>\n",
       "      <td>0.478652</td>\n",
       "      <td>0.239509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292945</td>\n",
       "      <td>0.695940</td>\n",
       "      <td>0.629866</td>\n",
       "      <td>-0.604865</td>\n",
       "      <td>0.408855</td>\n",
       "      <td>0.366074</td>\n",
       "      <td>0.769230</td>\n",
       "      <td>-0.079748</td>\n",
       "      <td>0.299464</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211647</th>\n",
       "      <td>604065</td>\n",
       "      <td>-0.869097</td>\n",
       "      <td>-0.054769</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>1.494902</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>-0.989741</td>\n",
       "      <td>-0.328674</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126951</td>\n",
       "      <td>0.190282</td>\n",
       "      <td>0.422340</td>\n",
       "      <td>0.559825</td>\n",
       "      <td>0.066547</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>-0.572396</td>\n",
       "      <td>0.299868</td>\n",
       "      <td>0.583064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211648</th>\n",
       "      <td>604066</td>\n",
       "      <td>-0.231139</td>\n",
       "      <td>-0.015213</td>\n",
       "      <td>0.279866</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>-1.602644</td>\n",
       "      <td>-2.899931</td>\n",
       "      <td>2.442186</td>\n",
       "      <td>3.257597</td>\n",
       "      <td>1.868830</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232617</td>\n",
       "      <td>0.328894</td>\n",
       "      <td>3.016022</td>\n",
       "      <td>0.931006</td>\n",
       "      <td>1.950742</td>\n",
       "      <td>2.523793</td>\n",
       "      <td>5.140957</td>\n",
       "      <td>-0.737889</td>\n",
       "      <td>2.032524</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211649</th>\n",
       "      <td>604067</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>0.273728</td>\n",
       "      <td>-0.666374</td>\n",
       "      <td>-0.350906</td>\n",
       "      <td>-0.681330</td>\n",
       "      <td>-0.392137</td>\n",
       "      <td>-0.753316</td>\n",
       "      <td>-0.483230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950815</td>\n",
       "      <td>-0.726685</td>\n",
       "      <td>-0.250510</td>\n",
       "      <td>0.501027</td>\n",
       "      <td>-0.633331</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>-0.199016</td>\n",
       "      <td>-0.789602</td>\n",
       "      <td>-0.406490</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211650</th>\n",
       "      <td>604068</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>0.081079</td>\n",
       "      <td>-0.074227</td>\n",
       "      <td>-0.212162</td>\n",
       "      <td>0.530137</td>\n",
       "      <td>0.579817</td>\n",
       "      <td>-0.549773</td>\n",
       "      <td>-0.327581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590500</td>\n",
       "      <td>-0.542091</td>\n",
       "      <td>-0.008257</td>\n",
       "      <td>0.492198</td>\n",
       "      <td>-0.537215</td>\n",
       "      <td>0.685286</td>\n",
       "      <td>-0.305631</td>\n",
       "      <td>-0.563828</td>\n",
       "      <td>-0.602673</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211651</th>\n",
       "      <td>604069</td>\n",
       "      <td>0.362527</td>\n",
       "      <td>-0.015975</td>\n",
       "      <td>0.236582</td>\n",
       "      <td>-0.601951</td>\n",
       "      <td>-0.313472</td>\n",
       "      <td>0.319458</td>\n",
       "      <td>-0.489490</td>\n",
       "      <td>-0.475623</td>\n",
       "      <td>-0.457444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935122</td>\n",
       "      <td>-0.637660</td>\n",
       "      <td>-0.111482</td>\n",
       "      <td>0.067674</td>\n",
       "      <td>-0.640131</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.571751</td>\n",
       "      <td>-0.523301</td>\n",
       "      <td>-0.548362</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211652</th>\n",
       "      <td>604070</td>\n",
       "      <td>-0.847096</td>\n",
       "      <td>-0.097315</td>\n",
       "      <td>-1.817370</td>\n",
       "      <td>-0.344799</td>\n",
       "      <td>0.533720</td>\n",
       "      <td>-2.352226</td>\n",
       "      <td>-0.291594</td>\n",
       "      <td>-0.093267</td>\n",
       "      <td>1.101918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310306</td>\n",
       "      <td>2.499150</td>\n",
       "      <td>0.138470</td>\n",
       "      <td>-0.099004</td>\n",
       "      <td>7.469451</td>\n",
       "      <td>-0.233889</td>\n",
       "      <td>-0.037993</td>\n",
       "      <td>-0.346893</td>\n",
       "      <td>3.368167</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211653</th>\n",
       "      <td>604071</td>\n",
       "      <td>-1.295880</td>\n",
       "      <td>-0.038054</td>\n",
       "      <td>-0.487036</td>\n",
       "      <td>-0.238179</td>\n",
       "      <td>-0.263573</td>\n",
       "      <td>-0.239702</td>\n",
       "      <td>-0.829190</td>\n",
       "      <td>0.368854</td>\n",
       "      <td>0.090189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242395</td>\n",
       "      <td>-0.275334</td>\n",
       "      <td>-0.846659</td>\n",
       "      <td>0.287407</td>\n",
       "      <td>0.350358</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>-0.439531</td>\n",
       "      <td>-0.232443</td>\n",
       "      <td>-0.128598</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211654</th>\n",
       "      <td>604072</td>\n",
       "      <td>-0.764565</td>\n",
       "      <td>-0.057455</td>\n",
       "      <td>-0.121488</td>\n",
       "      <td>-1.251892</td>\n",
       "      <td>-1.033843</td>\n",
       "      <td>0.840026</td>\n",
       "      <td>-0.452773</td>\n",
       "      <td>0.106175</td>\n",
       "      <td>-0.488507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667566</td>\n",
       "      <td>-0.159060</td>\n",
       "      <td>-0.434500</td>\n",
       "      <td>-0.231960</td>\n",
       "      <td>-0.709123</td>\n",
       "      <td>-0.483247</td>\n",
       "      <td>-0.804724</td>\n",
       "      <td>-0.616550</td>\n",
       "      <td>-0.634480</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211655</th>\n",
       "      <td>604073</td>\n",
       "      <td>-0.211790</td>\n",
       "      <td>-0.095839</td>\n",
       "      <td>-0.693170</td>\n",
       "      <td>-0.793088</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>-0.513209</td>\n",
       "      <td>-1.172506</td>\n",
       "      <td>-0.534579</td>\n",
       "      <td>-0.346006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232747</td>\n",
       "      <td>-0.090356</td>\n",
       "      <td>-0.554379</td>\n",
       "      <td>-0.105029</td>\n",
       "      <td>-0.236655</td>\n",
       "      <td>-0.600404</td>\n",
       "      <td>-0.781847</td>\n",
       "      <td>-0.221404</td>\n",
       "      <td>0.113776</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211656</th>\n",
       "      <td>604074</td>\n",
       "      <td>0.235745</td>\n",
       "      <td>-0.031453</td>\n",
       "      <td>-0.324323</td>\n",
       "      <td>0.888638</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.720081</td>\n",
       "      <td>0.319641</td>\n",
       "      <td>0.639795</td>\n",
       "      <td>2.268958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374858</td>\n",
       "      <td>2.009821</td>\n",
       "      <td>1.619709</td>\n",
       "      <td>-0.527721</td>\n",
       "      <td>2.039762</td>\n",
       "      <td>1.116347</td>\n",
       "      <td>1.229387</td>\n",
       "      <td>0.673996</td>\n",
       "      <td>1.153014</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211657</th>\n",
       "      <td>604075</td>\n",
       "      <td>-1.151422</td>\n",
       "      <td>-0.031676</td>\n",
       "      <td>-0.466968</td>\n",
       "      <td>-0.838578</td>\n",
       "      <td>0.355424</td>\n",
       "      <td>0.171856</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>-0.113150</td>\n",
       "      <td>0.725805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290893</td>\n",
       "      <td>1.191346</td>\n",
       "      <td>-0.379162</td>\n",
       "      <td>-0.933363</td>\n",
       "      <td>2.005905</td>\n",
       "      <td>-0.742228</td>\n",
       "      <td>-0.683476</td>\n",
       "      <td>-0.302671</td>\n",
       "      <td>1.455318</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211658</th>\n",
       "      <td>604076</td>\n",
       "      <td>-1.643983</td>\n",
       "      <td>-0.024830</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>-0.867625</td>\n",
       "      <td>-1.334232</td>\n",
       "      <td>0.516803</td>\n",
       "      <td>0.180368</td>\n",
       "      <td>0.214681</td>\n",
       "      <td>-0.530186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115030</td>\n",
       "      <td>-0.038661</td>\n",
       "      <td>-0.905761</td>\n",
       "      <td>-0.679020</td>\n",
       "      <td>-0.755601</td>\n",
       "      <td>-1.321907</td>\n",
       "      <td>-0.899716</td>\n",
       "      <td>-0.854210</td>\n",
       "      <td>-0.070409</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211659</th>\n",
       "      <td>604077</td>\n",
       "      <td>-0.185171</td>\n",
       "      <td>-0.016721</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>-1.415731</td>\n",
       "      <td>0.176571</td>\n",
       "      <td>-0.478581</td>\n",
       "      <td>-0.439234</td>\n",
       "      <td>-0.131807</td>\n",
       "      <td>-0.396336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181898</td>\n",
       "      <td>-0.816408</td>\n",
       "      <td>-0.313912</td>\n",
       "      <td>1.050003</td>\n",
       "      <td>-0.658853</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>-0.690673</td>\n",
       "      <td>-0.218124</td>\n",
       "      <td>-0.188425</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211660</th>\n",
       "      <td>604078</td>\n",
       "      <td>1.109534</td>\n",
       "      <td>-0.018190</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>-0.955268</td>\n",
       "      <td>-0.031994</td>\n",
       "      <td>1.461562</td>\n",
       "      <td>-1.408107</td>\n",
       "      <td>-0.475621</td>\n",
       "      <td>-0.131553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.281571</td>\n",
       "      <td>0.343386</td>\n",
       "      <td>-1.316260</td>\n",
       "      <td>-0.259890</td>\n",
       "      <td>0.849384</td>\n",
       "      <td>-0.282967</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>-0.808002</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211661</th>\n",
       "      <td>604079</td>\n",
       "      <td>-0.354959</td>\n",
       "      <td>-0.104830</td>\n",
       "      <td>-0.481110</td>\n",
       "      <td>0.532517</td>\n",
       "      <td>-0.055479</td>\n",
       "      <td>0.990390</td>\n",
       "      <td>3.058267</td>\n",
       "      <td>-0.440216</td>\n",
       "      <td>0.822645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047586</td>\n",
       "      <td>1.392516</td>\n",
       "      <td>0.105898</td>\n",
       "      <td>-1.605966</td>\n",
       "      <td>1.114767</td>\n",
       "      <td>-0.029024</td>\n",
       "      <td>-0.779353</td>\n",
       "      <td>-0.131530</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211662</th>\n",
       "      <td>604080</td>\n",
       "      <td>-1.300627</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>0.648890</td>\n",
       "      <td>1.009564</td>\n",
       "      <td>-0.132813</td>\n",
       "      <td>-1.804049</td>\n",
       "      <td>1.991319</td>\n",
       "      <td>0.230198</td>\n",
       "      <td>-0.915582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732460</td>\n",
       "      <td>-1.578003</td>\n",
       "      <td>-1.109370</td>\n",
       "      <td>1.385595</td>\n",
       "      <td>-0.848648</td>\n",
       "      <td>-0.050341</td>\n",
       "      <td>-0.642986</td>\n",
       "      <td>-0.671243</td>\n",
       "      <td>-0.161174</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211663</th>\n",
       "      <td>604081</td>\n",
       "      <td>0.404423</td>\n",
       "      <td>-0.119930</td>\n",
       "      <td>-1.179075</td>\n",
       "      <td>1.730329</td>\n",
       "      <td>-1.223321</td>\n",
       "      <td>1.168269</td>\n",
       "      <td>-1.013117</td>\n",
       "      <td>0.129222</td>\n",
       "      <td>1.281188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>1.247979</td>\n",
       "      <td>1.495700</td>\n",
       "      <td>-1.786872</td>\n",
       "      <td>1.003547</td>\n",
       "      <td>0.590793</td>\n",
       "      <td>0.388370</td>\n",
       "      <td>-0.369971</td>\n",
       "      <td>-0.129248</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211664</th>\n",
       "      <td>604082</td>\n",
       "      <td>0.503981</td>\n",
       "      <td>-0.014440</td>\n",
       "      <td>0.214123</td>\n",
       "      <td>0.992274</td>\n",
       "      <td>0.582839</td>\n",
       "      <td>-0.454562</td>\n",
       "      <td>0.864876</td>\n",
       "      <td>-0.536695</td>\n",
       "      <td>-0.489296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151251</td>\n",
       "      <td>-0.836456</td>\n",
       "      <td>-0.288674</td>\n",
       "      <td>1.283885</td>\n",
       "      <td>-0.544375</td>\n",
       "      <td>0.171521</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>-0.192111</td>\n",
       "      <td>-0.486189</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211665</th>\n",
       "      <td>604083</td>\n",
       "      <td>0.421822</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.452965</td>\n",
       "      <td>-1.465315</td>\n",
       "      <td>-0.639441</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>-0.882634</td>\n",
       "      <td>-0.539281</td>\n",
       "      <td>-0.332060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396353</td>\n",
       "      <td>-0.373046</td>\n",
       "      <td>-0.041698</td>\n",
       "      <td>0.098077</td>\n",
       "      <td>-0.453290</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>-0.291763</td>\n",
       "      <td>-0.255386</td>\n",
       "      <td>-0.567615</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211666</th>\n",
       "      <td>604084</td>\n",
       "      <td>-1.405885</td>\n",
       "      <td>-0.015529</td>\n",
       "      <td>0.081315</td>\n",
       "      <td>0.476284</td>\n",
       "      <td>0.329192</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.231812</td>\n",
       "      <td>0.013826</td>\n",
       "      <td>-0.858074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>-0.796221</td>\n",
       "      <td>-0.819604</td>\n",
       "      <td>2.312094</td>\n",
       "      <td>-0.931063</td>\n",
       "      <td>-0.425722</td>\n",
       "      <td>-0.813524</td>\n",
       "      <td>-0.525662</td>\n",
       "      <td>-0.806874</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211667</th>\n",
       "      <td>604085</td>\n",
       "      <td>-0.255851</td>\n",
       "      <td>-0.015535</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.742090</td>\n",
       "      <td>-1.072810</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.818771</td>\n",
       "      <td>-0.379148</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860600</td>\n",
       "      <td>-0.287712</td>\n",
       "      <td>-0.763121</td>\n",
       "      <td>-0.026385</td>\n",
       "      <td>-0.788844</td>\n",
       "      <td>-0.956820</td>\n",
       "      <td>-0.519904</td>\n",
       "      <td>-0.752493</td>\n",
       "      <td>-0.349251</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211668</th>\n",
       "      <td>604086</td>\n",
       "      <td>0.769109</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.517912</td>\n",
       "      <td>1.362700</td>\n",
       "      <td>-0.433119</td>\n",
       "      <td>-0.423982</td>\n",
       "      <td>-0.356866</td>\n",
       "      <td>0.511168</td>\n",
       "      <td>1.012104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>1.580103</td>\n",
       "      <td>-0.934321</td>\n",
       "      <td>1.041610</td>\n",
       "      <td>0.642434</td>\n",
       "      <td>1.698802</td>\n",
       "      <td>0.791768</td>\n",
       "      <td>-0.283639</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211669</th>\n",
       "      <td>604087</td>\n",
       "      <td>0.539653</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>-1.354061</td>\n",
       "      <td>-0.231431</td>\n",
       "      <td>-2.392217</td>\n",
       "      <td>-0.853211</td>\n",
       "      <td>-0.666104</td>\n",
       "      <td>-0.476928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990602</td>\n",
       "      <td>-0.286132</td>\n",
       "      <td>-0.132026</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>-0.304182</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>-0.573663</td>\n",
       "      <td>1.433907</td>\n",
       "      <td>0.635513</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211670</th>\n",
       "      <td>604088</td>\n",
       "      <td>0.939169</td>\n",
       "      <td>-0.031861</td>\n",
       "      <td>-0.297075</td>\n",
       "      <td>1.627091</td>\n",
       "      <td>1.444664</td>\n",
       "      <td>1.466964</td>\n",
       "      <td>-0.398424</td>\n",
       "      <td>1.083040</td>\n",
       "      <td>1.156888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.687512</td>\n",
       "      <td>1.555102</td>\n",
       "      <td>1.673512</td>\n",
       "      <td>-2.019056</td>\n",
       "      <td>0.793360</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>1.247109</td>\n",
       "      <td>0.743938</td>\n",
       "      <td>0.198913</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211671</th>\n",
       "      <td>604089</td>\n",
       "      <td>-2.738119</td>\n",
       "      <td>-0.023891</td>\n",
       "      <td>-0.079456</td>\n",
       "      <td>0.211851</td>\n",
       "      <td>-0.436666</td>\n",
       "      <td>-1.890149</td>\n",
       "      <td>1.163083</td>\n",
       "      <td>1.270928</td>\n",
       "      <td>0.269453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404973</td>\n",
       "      <td>-0.894813</td>\n",
       "      <td>-0.149381</td>\n",
       "      <td>1.356825</td>\n",
       "      <td>0.412399</td>\n",
       "      <td>-1.335880</td>\n",
       "      <td>-0.595696</td>\n",
       "      <td>-0.326018</td>\n",
       "      <td>0.838165</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211672</th>\n",
       "      <td>604090</td>\n",
       "      <td>0.573479</td>\n",
       "      <td>-0.013914</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>-1.117083</td>\n",
       "      <td>0.346173</td>\n",
       "      <td>1.154490</td>\n",
       "      <td>0.334465</td>\n",
       "      <td>-0.839889</td>\n",
       "      <td>-0.488286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745546</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>-0.119672</td>\n",
       "      <td>-1.101634</td>\n",
       "      <td>-0.688077</td>\n",
       "      <td>-0.118480</td>\n",
       "      <td>-0.746325</td>\n",
       "      <td>0.447293</td>\n",
       "      <td>-0.563384</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211673</th>\n",
       "      <td>604091</td>\n",
       "      <td>0.466841</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.505160</td>\n",
       "      <td>0.648125</td>\n",
       "      <td>-0.650331</td>\n",
       "      <td>-0.081008</td>\n",
       "      <td>0.780131</td>\n",
       "      <td>-0.787532</td>\n",
       "      <td>-0.488666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075811</td>\n",
       "      <td>-0.855960</td>\n",
       "      <td>-0.400367</td>\n",
       "      <td>1.704200</td>\n",
       "      <td>-0.838864</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>-0.712978</td>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.447556</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211674</th>\n",
       "      <td>604092</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>-0.049562</td>\n",
       "      <td>-0.350616</td>\n",
       "      <td>1.418559</td>\n",
       "      <td>0.085509</td>\n",
       "      <td>1.219870</td>\n",
       "      <td>0.943165</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>1.046436</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000828</td>\n",
       "      <td>1.455837</td>\n",
       "      <td>1.320956</td>\n",
       "      <td>-1.608140</td>\n",
       "      <td>0.629994</td>\n",
       "      <td>1.545077</td>\n",
       "      <td>0.835327</td>\n",
       "      <td>0.851544</td>\n",
       "      <td>0.264917</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211675 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature0  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0       392418  0.088970 -0.012451  0.226408 -1.386858 -1.066616  0.636430   \n",
       "1       392419 -1.004904 -0.034484 -0.345187  0.179278 -0.393074  0.752589   \n",
       "2       392420  1.100924 -0.023984 -0.329857  0.661071  1.076176  0.414028   \n",
       "3       392421  0.939863 -0.018097  0.008183 -1.418409  0.359216 -0.135353   \n",
       "4       392422 -0.146653 -0.016357  0.019047  0.035251 -0.577442 -0.068010   \n",
       "5       392423  0.837824 -0.020683  0.273588  1.056372 -0.230143  0.573043   \n",
       "6       392424  1.040767 -0.152174  0.344835 -0.737765  0.245411  1.330195   \n",
       "7       392425 -0.699206 -0.035928  0.175071 -0.173649 -0.001234  0.419827   \n",
       "8       392426 -1.250826 -0.018475  0.129181 -0.010234 -1.590578 -1.054722   \n",
       "9       392427  1.069376  0.019059  0.642103  0.213534 -0.151496 -0.172658   \n",
       "10      392428 -0.917364 -0.118647 -0.285822  0.533232 -0.187045 -0.718213   \n",
       "11      392429 -0.713333 -0.103237 -0.571024  0.984154  0.525436  0.782510   \n",
       "12      392430 -1.046641 -0.016020  0.243694  1.692588  1.320556 -0.212556   \n",
       "13      392431 -1.328634 -0.047121 -0.366175 -1.130283 -0.517681  0.633059   \n",
       "14      392432 -0.819428 -0.018268 -0.047686 -0.471116 -1.190888 -0.608216   \n",
       "15      392433  0.437786 -0.049370 -0.466507  1.514302  2.746221  1.282836   \n",
       "16      392434  0.137740 -0.016819  0.092436 -0.545424  0.131016 -0.506191   \n",
       "17      392435  1.019507 -0.028070  0.019718 -0.421863  0.430075 -2.392677   \n",
       "18      392436 -0.102105 -0.040849 -0.552134  1.862996  1.896060 -2.840276   \n",
       "19      392437  0.775261 -0.016032  0.080540 -0.699094 -0.380927 -0.294925   \n",
       "20      392438 -1.517234 -0.028044 -0.171356  0.688223  0.112646  0.053559   \n",
       "21      392439 -0.119101 -0.027805 -0.476054 -0.387816  0.376931  1.076661   \n",
       "22      392440  0.585500 -0.049330 -0.198842 -0.434550 -0.545066  0.878899   \n",
       "23      392441  0.550419 -0.026467 -0.072219  0.762435 -0.976189  1.323495   \n",
       "24      392442 -2.039502 -0.218888 -1.583631  0.768805 -0.438828  0.191468   \n",
       "25      392443 -1.280876 -0.014128  0.404512  1.237853  0.735989 -0.206958   \n",
       "26      392444  0.719944 -0.019219 -0.113005  0.408766 -0.015992 -0.594554   \n",
       "27      392445  0.680960 -0.017012 -0.207428  1.595523 -0.502677  1.371180   \n",
       "28      392446  0.898747 -0.011921  0.137916 -0.924046  1.366975 -0.644433   \n",
       "29      392447 -3.063437 -1.469658 -3.516468 -0.635247 -0.133773 -0.122668   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "211645  604063 -0.102736 -0.024948 -0.144690 -0.092909 -1.101083 -0.435454   \n",
       "211646  604064  1.210540 -0.015561  0.163281 -1.455785  0.207474  0.794949   \n",
       "211647  604065 -0.869097 -0.054769  0.318353  0.149980  1.494902  0.054499   \n",
       "211648  604066 -0.231139 -0.015213  0.279866  0.023828 -1.602644 -2.899931   \n",
       "211649  604067  0.546341 -0.006732  0.273728 -0.666374 -0.350906 -0.681330   \n",
       "211650  604068  0.963833 -0.015971  0.081079 -0.074227 -0.212162  0.530137   \n",
       "211651  604069  0.362527 -0.015975  0.236582 -0.601951 -0.313472  0.319458   \n",
       "211652  604070 -0.847096 -0.097315 -1.817370 -0.344799  0.533720 -2.352226   \n",
       "211653  604071 -1.295880 -0.038054 -0.487036 -0.238179 -0.263573 -0.239702   \n",
       "211654  604072 -0.764565 -0.057455 -0.121488 -1.251892 -1.033843  0.840026   \n",
       "211655  604073 -0.211790 -0.095839 -0.693170 -0.793088 -0.705000 -0.513209   \n",
       "211656  604074  0.235745 -0.031453 -0.324323  0.888638  0.400635  0.720081   \n",
       "211657  604075 -1.151422 -0.031676 -0.466968 -0.838578  0.355424  0.171856   \n",
       "211658  604076 -1.643983 -0.024830  0.029919 -0.867625 -1.334232  0.516803   \n",
       "211659  604077 -0.185171 -0.016721  0.023699 -1.415731  0.176571 -0.478581   \n",
       "211660  604078  1.109534 -0.018190  0.016222 -0.955268 -0.031994  1.461562   \n",
       "211661  604079 -0.354959 -0.104830 -0.481110  0.532517 -0.055479  0.990390   \n",
       "211662  604080 -1.300627 -0.013230  0.648890  1.009564 -0.132813 -1.804049   \n",
       "211663  604081  0.404423 -0.119930 -1.179075  1.730329 -1.223321  1.168269   \n",
       "211664  604082  0.503981 -0.014440  0.214123  0.992274  0.582839 -0.454562   \n",
       "211665  604083  0.421822 -0.003974  0.452965 -1.465315 -0.639441  0.692669   \n",
       "211666  604084 -1.405885 -0.015529  0.081315  0.476284  0.329192  0.037508   \n",
       "211667  604085 -0.255851 -0.015535  0.071321  0.742090 -1.072810  0.793729   \n",
       "211668  604086  0.769109 -0.052867 -0.517912  1.362700 -0.433119 -0.423982   \n",
       "211669  604087  0.539653 -0.015061  0.160396 -1.354061 -0.231431 -2.392217   \n",
       "211670  604088  0.939169 -0.031861 -0.297075  1.627091  1.444664  1.466964   \n",
       "211671  604089 -2.738119 -0.023891 -0.079456  0.211851 -0.436666 -1.890149   \n",
       "211672  604090  0.573479 -0.013914  0.091884 -1.117083  0.346173  1.154490   \n",
       "211673  604091  0.466841  0.004306  0.505160  0.648125 -0.650331 -0.081008   \n",
       "211674  604092  0.267700 -0.049562 -0.350616  1.418559  0.085509  1.219870   \n",
       "\n",
       "        feature6  feature7  feature8  ...    feature79  feature80  feature81  \\\n",
       "0      -0.805733 -0.478093 -0.536539  ...    -0.785307  -0.491378  -0.291151   \n",
       "1       2.233694  0.651315  1.896860  ...    -0.079682   1.490679  -0.082252   \n",
       "2       0.194951  0.833402  0.778437  ...     1.596572   0.640618   1.219347   \n",
       "3      -1.482310 -0.057569  0.169539  ...     0.110845   0.145179   0.516610   \n",
       "4      -1.572975 -0.329777  0.267620  ...     0.737593   0.037424   0.027635   \n",
       "5       0.645608 -0.483777 -0.217809  ...     0.996371  -0.438168   0.167159   \n",
       "6      -0.122921  0.752297  0.385699  ...     3.819098   1.698990   0.942540   \n",
       "7      -0.073032  0.496059 -0.486717  ...    -0.748197  -0.190228  -0.558712   \n",
       "8      -0.402337  0.551442 -1.204170  ...    -0.653698  -0.896002  -1.498425   \n",
       "9      -0.396895 -0.149623 -0.384482  ...     0.680009   0.175432  -0.185755   \n",
       "10     -1.453297  0.059654 -0.444266  ...    -0.079491  -0.538677  -0.726547   \n",
       "11     -0.287802 -0.262987  0.990423  ...     1.327812   0.662191   0.897151   \n",
       "12     -1.111035 -0.062676 -0.542785  ...    -0.365200  -0.742857  -0.958454   \n",
       "13      0.131175  0.204533 -0.214171  ...    -0.679040  -0.232199  -0.428869   \n",
       "14     -0.839902 -0.018879  0.067261  ...    -0.957400   0.251832  -0.298243   \n",
       "15     -1.215845  0.104863  0.619806  ...     5.654401   0.937721   0.782412   \n",
       "16      0.209493 -0.450209 -0.487388  ...    -0.609673  -0.657740  -0.387053   \n",
       "17     -0.323490  2.167833  0.636916  ...     2.542898   1.390568   1.577312   \n",
       "18      1.624334  1.326741  2.270326  ...     2.179476   0.830638   2.209012   \n",
       "19     -0.590150 -0.495735 -0.337198  ...    -0.978537  -0.407864  -0.045793   \n",
       "20     -0.437092  0.468593 -0.516839  ...    -0.115232  -0.670385  -1.360465   \n",
       "21     -0.485520 -0.137305  0.575163  ...    -0.109986   0.545784  -0.162897   \n",
       "22     -1.554780 -0.847609 -0.150480  ...     1.853726   0.095309  -0.040793   \n",
       "23      0.253387  1.844839  1.341516  ...    -1.160816   2.494855   1.591581   \n",
       "24     -0.582467  0.803562  2.687550  ...    -0.465200   0.739912   1.691338   \n",
       "25      0.707058  0.851077 -1.284993  ...    -1.140630  -1.158208  -1.326836   \n",
       "26     -1.076209 -0.907659  0.060980  ...     0.094755   0.021680   0.196119   \n",
       "27     -0.136794  0.152394  2.117736  ...     0.542771   1.364404   1.837216   \n",
       "28     -0.339379 -0.543002 -0.269487  ...     2.314266  -0.007253   0.270167   \n",
       "29     -1.005178  0.913962 -0.488834  ...    -0.869591   0.114977  -1.168895   \n",
       "...          ...       ...       ...  ...          ...        ...        ...   \n",
       "211645  1.259344 -0.404340 -0.731295  ...    -1.044008  -0.915253  -0.657344   \n",
       "211646 -1.119945  0.478652  0.239509  ...     0.292945   0.695940   0.629866   \n",
       "211647 -0.989741 -0.328674  0.018314  ...     0.126951   0.190282   0.422340   \n",
       "211648  2.442186  3.257597  1.868830  ...    -1.232617   0.328894   3.016022   \n",
       "211649 -0.392137 -0.753316 -0.483230  ...    -0.950815  -0.726685  -0.250510   \n",
       "211650  0.579817 -0.549773 -0.327581  ...    -0.590500  -0.542091  -0.008257   \n",
       "211651 -0.489490 -0.475623 -0.457444  ...    -0.935122  -0.637660  -0.111482   \n",
       "211652 -0.291594 -0.093267  1.101918  ...    -0.310306   2.499150   0.138470   \n",
       "211653 -0.829190  0.368854  0.090189  ...    -0.242395  -0.275334  -0.846659   \n",
       "211654 -0.452773  0.106175 -0.488507  ...    -0.667566  -0.159060  -0.434500   \n",
       "211655 -1.172506 -0.534579 -0.346006  ...    -0.232747  -0.090356  -0.554379   \n",
       "211656  0.319641  0.639795  2.268958  ...     0.374858   2.009821   1.619709   \n",
       "211657  0.013278 -0.113150  0.725805  ...    -0.290893   1.191346  -0.379162   \n",
       "211658  0.180368  0.214681 -0.530186  ...    -1.115030  -0.038661  -0.905761   \n",
       "211659 -0.439234 -0.131807 -0.396336  ...    -0.181898  -0.816408  -0.313912   \n",
       "211660 -1.408107 -0.475621 -0.131553  ...     0.074200   0.281571   0.343386   \n",
       "211661  3.058267 -0.440216  0.822645  ...    -0.047586   1.392516   0.105898   \n",
       "211662  1.991319  0.230198 -0.915582  ...    -0.732460  -1.578003  -1.109370   \n",
       "211663 -1.013117  0.129222  1.281188  ...    -0.351451   1.247979   1.495700   \n",
       "211664  0.864876 -0.536695 -0.489296  ...     0.151251  -0.836456  -0.288674   \n",
       "211665 -0.882634 -0.539281 -0.332060  ...    -0.396353  -0.373046  -0.041698   \n",
       "211666  0.231812  0.013826 -0.858074  ...     0.032755  -0.796221  -0.819604   \n",
       "211667  0.818771 -0.379148 -0.822889  ...    -0.860600  -0.287712  -0.763121   \n",
       "211668 -0.356866  0.511168  1.012104  ...     0.784947   0.858856   1.580103   \n",
       "211669 -0.853211 -0.666104 -0.476928  ...     1.990602  -0.286132  -0.132026   \n",
       "211670 -0.398424  1.083040  1.156888  ...     1.687512   1.555102   1.673512   \n",
       "211671  1.163083  1.270928  0.269453  ...    -0.404973  -0.894813  -0.149381   \n",
       "211672  0.334465 -0.839889 -0.488286  ...     0.745546   0.061967  -0.119672   \n",
       "211673  0.780131 -0.787532 -0.488666  ...    -0.075811  -0.855960  -0.400367   \n",
       "211674  0.943165  0.012985  1.046436  ...     1.000828   1.455837   1.320956   \n",
       "\n",
       "        feature82  feature83  feature84  feature85  feature86  feature87  \\\n",
       "0        0.120415  -0.807633  -0.394544  -0.681540  -0.707518  -0.775872   \n",
       "1       -1.079956   1.607502  -1.805872  -0.149094  -0.108615   1.492027   \n",
       "2       -1.060589   0.290406   0.772820   1.368938   1.088984  -0.433057   \n",
       "3       -0.260976   0.265216   1.133491   0.500493   0.038265  -0.783961   \n",
       "4        0.544575   0.036731  -0.131309  -0.877661   0.461268  -0.238349   \n",
       "5        1.013741  -0.541207  -0.093378  -0.391347   0.692741  -0.636414   \n",
       "6       -1.111067   0.019530   1.077803   1.040696   2.926289   1.866744   \n",
       "7        1.102890  -0.556398   0.783577  -0.040264  -0.633712   0.313645   \n",
       "8        0.071348  -0.934304  -2.766871  -0.817718  -0.609713  -0.771024   \n",
       "9       -0.756882  -0.433311   0.301302   0.215193   0.201869   0.829680   \n",
       "10       0.533653  -0.352214   0.012316  -0.554619  -0.170540  -0.312947   \n",
       "11      -0.068489   0.541205  -0.984759  -0.007678   0.939193   0.218440   \n",
       "12       1.056052  -0.698245   0.012662  -0.373747  -0.296632   0.157238   \n",
       "13      -1.190743  -0.248285  -0.180009  -0.688850  -0.596113  -0.368932   \n",
       "14      -0.469795  -0.308584  -1.365618  -0.215089  -0.847685   0.694955   \n",
       "15      -1.413585   0.208622   0.013578   0.609862   3.137489  -0.137890   \n",
       "16       1.177475  -0.711263   0.013024  -0.687852   3.372954  -0.583500   \n",
       "17      -1.745083   0.672999   0.779755   2.503408   1.873678   0.600182   \n",
       "18       1.485389   1.845857   0.010711   1.684238   0.949540   2.279930   \n",
       "19       0.068662  -0.684786   0.744371  -0.304092  -0.831600  -0.855002   \n",
       "20       0.710794   0.151484  -1.288198  -0.853195  -0.309323   0.055747   \n",
       "21      -1.000919   0.657322  -0.175513  -0.433287  -0.164804  -0.084506   \n",
       "22      -0.404032  -0.486408   0.040451  -0.803356   1.489539  -0.659932   \n",
       "23      -1.216856   1.182917   0.012138   1.575238  -1.000941   1.627632   \n",
       "24       0.422853   2.082296   0.011965   0.047595  -0.373742   1.331072   \n",
       "25       1.014244  -0.755766   0.011154  -0.449904  -0.845454  -0.714069   \n",
       "26      -0.549985  -0.236283   0.148215  -0.473299   0.354291  -0.128664   \n",
       "27      -0.092271   1.579427   0.319331   0.725922   0.303287   0.658043   \n",
       "28      -0.300871  -0.117714   0.296281  -0.369952   2.460227  -0.309228   \n",
       "29      -0.187472   1.836652   0.011324   0.035404  -0.718960   1.157783   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "211645   0.702763  -0.406181  -1.008614  -0.788394  -0.715539  -0.390790   \n",
       "211646  -0.604865   0.408855   0.366074   0.769230  -0.079748   0.299464   \n",
       "211647   0.559825   0.066547   0.011043  -0.572396   0.299868   0.583064   \n",
       "211648   0.931006   1.950742   2.523793   5.140957  -0.737889   2.032524   \n",
       "211649   0.501027  -0.633331   0.212900  -0.199016  -0.789602  -0.406490   \n",
       "211650   0.492198  -0.537215   0.685286  -0.305631  -0.563828  -0.602673   \n",
       "211651   0.067674  -0.640131   0.010026  -0.571751  -0.523301  -0.548362   \n",
       "211652  -0.099004   7.469451  -0.233889  -0.037993  -0.346893   3.368167   \n",
       "211653   0.287407   0.350358   0.013183  -0.439531  -0.232443  -0.128598   \n",
       "211654  -0.231960  -0.709123  -0.483247  -0.804724  -0.616550  -0.634480   \n",
       "211655  -0.105029  -0.236655  -0.600404  -0.781847  -0.221404   0.113776   \n",
       "211656  -0.527721   2.039762   1.116347   1.229387   0.673996   1.153014   \n",
       "211657  -0.933363   2.005905  -0.742228  -0.683476  -0.302671   1.455318   \n",
       "211658  -0.679020  -0.755601  -1.321907  -0.899716  -0.854210  -0.070409   \n",
       "211659   1.050003  -0.658853   0.012438  -0.690673  -0.218124  -0.188425   \n",
       "211660  -1.316260  -0.259890   0.849384  -0.282967  -0.018520  -0.808002   \n",
       "211661  -1.605966   1.114767  -0.029024  -0.779353  -0.131530   0.943299   \n",
       "211662   1.385595  -0.848648  -0.050341  -0.642986  -0.671243  -0.161174   \n",
       "211663  -1.786872   1.003547   0.590793   0.388370  -0.369971  -0.129248   \n",
       "211664   1.283885  -0.544375   0.171521  -0.012841  -0.192111  -0.486189   \n",
       "211665   0.098077  -0.453290   0.011781  -0.291763  -0.255386  -0.567615   \n",
       "211666   2.312094  -0.931063  -0.425722  -0.813524  -0.525662  -0.806874   \n",
       "211667  -0.026385  -0.788844  -0.956820  -0.519904  -0.752493  -0.349251   \n",
       "211668  -0.934321   1.041610   0.642434   1.698802   0.791768  -0.283639   \n",
       "211669   0.005123  -0.304182   0.012896  -0.573663   1.433907   0.635513   \n",
       "211670  -2.019056   0.793360   0.547771   1.247109   0.743938   0.198913   \n",
       "211671   1.356825   0.412399  -1.335880  -0.595696  -0.326018   0.838165   \n",
       "211672  -1.101634  -0.688077  -0.118480  -0.746325   0.447293  -0.563384   \n",
       "211673   1.704200  -0.838864   0.011521  -0.712978  -0.038924  -0.447556   \n",
       "211674  -1.608140   0.629994   1.545077   0.835327   0.851544   0.264917   \n",
       "\n",
       "        group  \n",
       "0          18  \n",
       "1          14  \n",
       "2           8  \n",
       "3          13  \n",
       "4          14  \n",
       "5           0  \n",
       "6          20  \n",
       "7          18  \n",
       "8           6  \n",
       "9           6  \n",
       "10         12  \n",
       "11         15  \n",
       "12         13  \n",
       "13         14  \n",
       "14          3  \n",
       "15          0  \n",
       "16         23  \n",
       "17         14  \n",
       "18          5  \n",
       "19          0  \n",
       "20          5  \n",
       "21          1  \n",
       "22         16  \n",
       "23         12  \n",
       "24          6  \n",
       "25         15  \n",
       "26         19  \n",
       "27         26  \n",
       "28         15  \n",
       "29         20  \n",
       "...       ...  \n",
       "211645     26  \n",
       "211646     10  \n",
       "211647      2  \n",
       "211648      6  \n",
       "211649     16  \n",
       "211650     14  \n",
       "211651     16  \n",
       "211652     22  \n",
       "211653     22  \n",
       "211654      2  \n",
       "211655     19  \n",
       "211656     14  \n",
       "211657     14  \n",
       "211658     13  \n",
       "211659     16  \n",
       "211660     14  \n",
       "211661      5  \n",
       "211662     11  \n",
       "211663     20  \n",
       "211664     14  \n",
       "211665      3  \n",
       "211666     26  \n",
       "211667     12  \n",
       "211668     11  \n",
       "211669      9  \n",
       "211670     20  \n",
       "211671     19  \n",
       "211672     21  \n",
       "211673      4  \n",
       "211674      9  \n",
       "\n",
       "[211675 rows x 90 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392418, 93)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature82</th>\n",
       "      <th>feature83</th>\n",
       "      <th>feature84</th>\n",
       "      <th>feature85</th>\n",
       "      <th>feature86</th>\n",
       "      <th>feature87</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.614041</td>\n",
       "      <td>0.114416</td>\n",
       "      <td>0.231052</td>\n",
       "      <td>1.273933</td>\n",
       "      <td>-0.299535</td>\n",
       "      <td>-0.076514</td>\n",
       "      <td>0.128355</td>\n",
       "      <td>-0.053832</td>\n",
       "      <td>-0.572873</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134926</td>\n",
       "      <td>-0.755843</td>\n",
       "      <td>0.317429</td>\n",
       "      <td>-0.241113</td>\n",
       "      <td>-0.746367</td>\n",
       "      <td>-0.365467</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986737</td>\n",
       "      <td>-0.276118</td>\n",
       "      <td>-0.626683</td>\n",
       "      <td>1.366301</td>\n",
       "      <td>-0.588178</td>\n",
       "      <td>1.323094</td>\n",
       "      <td>-0.808199</td>\n",
       "      <td>-0.177238</td>\n",
       "      <td>0.951274</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053611</td>\n",
       "      <td>0.567973</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.325993</td>\n",
       "      <td>1.038188</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.396707</td>\n",
       "      <td>-1.748540</td>\n",
       "      <td>-2.120154</td>\n",
       "      <td>1.226534</td>\n",
       "      <td>0.398690</td>\n",
       "      <td>1.069129</td>\n",
       "      <td>-0.635431</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>2.277830</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.786568</td>\n",
       "      <td>2.328527</td>\n",
       "      <td>0.444290</td>\n",
       "      <td>1.362455</td>\n",
       "      <td>0.097616</td>\n",
       "      <td>0.614781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.686342</td>\n",
       "      <td>0.119166</td>\n",
       "      <td>-0.141433</td>\n",
       "      <td>0.546838</td>\n",
       "      <td>2.436892</td>\n",
       "      <td>1.194097</td>\n",
       "      <td>-0.671772</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>0.369298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278068</td>\n",
       "      <td>0.306136</td>\n",
       "      <td>-0.026526</td>\n",
       "      <td>0.502339</td>\n",
       "      <td>0.116241</td>\n",
       "      <td>-0.915358</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.488483</td>\n",
       "      <td>0.090380</td>\n",
       "      <td>0.074291</td>\n",
       "      <td>0.088601</td>\n",
       "      <td>-1.108423</td>\n",
       "      <td>-0.147028</td>\n",
       "      <td>-0.463876</td>\n",
       "      <td>-0.267537</td>\n",
       "      <td>-0.772068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182212</td>\n",
       "      <td>-1.162430</td>\n",
       "      <td>-0.564973</td>\n",
       "      <td>-1.000597</td>\n",
       "      <td>-0.544647</td>\n",
       "      <td>-0.990627</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.151643</td>\n",
       "      <td>0.137570</td>\n",
       "      <td>0.399777</td>\n",
       "      <td>-1.400313</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>-0.323754</td>\n",
       "      <td>0.168058</td>\n",
       "      <td>-0.280357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>-0.255070</td>\n",
       "      <td>-0.026942</td>\n",
       "      <td>0.599934</td>\n",
       "      <td>-0.105256</td>\n",
       "      <td>-0.497817</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.862462</td>\n",
       "      <td>0.074743</td>\n",
       "      <td>-0.756178</td>\n",
       "      <td>0.714230</td>\n",
       "      <td>-0.227506</td>\n",
       "      <td>1.269414</td>\n",
       "      <td>-0.200736</td>\n",
       "      <td>0.234439</td>\n",
       "      <td>0.888671</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.676531</td>\n",
       "      <td>0.446269</td>\n",
       "      <td>0.031392</td>\n",
       "      <td>0.781035</td>\n",
       "      <td>1.225703</td>\n",
       "      <td>-0.695879</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.271582</td>\n",
       "      <td>-0.012460</td>\n",
       "      <td>-0.103276</td>\n",
       "      <td>-0.911698</td>\n",
       "      <td>-0.242800</td>\n",
       "      <td>0.992016</td>\n",
       "      <td>-0.618712</td>\n",
       "      <td>-1.130434</td>\n",
       "      <td>-0.462614</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.016529</td>\n",
       "      <td>-0.636494</td>\n",
       "      <td>-0.284672</td>\n",
       "      <td>-0.707933</td>\n",
       "      <td>-0.466095</td>\n",
       "      <td>-1.530306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.985132</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>-0.176043</td>\n",
       "      <td>1.380970</td>\n",
       "      <td>0.492982</td>\n",
       "      <td>1.321854</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.357832</td>\n",
       "      <td>0.709694</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.710409</td>\n",
       "      <td>-0.038793</td>\n",
       "      <td>-0.026687</td>\n",
       "      <td>0.235733</td>\n",
       "      <td>1.336808</td>\n",
       "      <td>-0.924962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.273723</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>-0.455830</td>\n",
       "      <td>1.090874</td>\n",
       "      <td>-0.614171</td>\n",
       "      <td>1.018233</td>\n",
       "      <td>1.139140</td>\n",
       "      <td>0.344746</td>\n",
       "      <td>0.933291</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.350233</td>\n",
       "      <td>0.874880</td>\n",
       "      <td>-0.025257</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>-0.387662</td>\n",
       "      <td>-0.257792</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.807069</td>\n",
       "      <td>0.123885</td>\n",
       "      <td>1.080072</td>\n",
       "      <td>1.624313</td>\n",
       "      <td>0.681922</td>\n",
       "      <td>-1.009065</td>\n",
       "      <td>-0.216578</td>\n",
       "      <td>1.036015</td>\n",
       "      <td>-1.909669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613530</td>\n",
       "      <td>-1.216052</td>\n",
       "      <td>-1.224894</td>\n",
       "      <td>-1.018993</td>\n",
       "      <td>-0.733822</td>\n",
       "      <td>0.097809</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.176996</td>\n",
       "      <td>0.055128</td>\n",
       "      <td>0.268626</td>\n",
       "      <td>1.626769</td>\n",
       "      <td>0.654820</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>-0.012363</td>\n",
       "      <td>-1.062414</td>\n",
       "      <td>-0.782823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421035</td>\n",
       "      <td>-1.190525</td>\n",
       "      <td>-0.027763</td>\n",
       "      <td>-0.973241</td>\n",
       "      <td>-0.893666</td>\n",
       "      <td>-0.796483</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.079347</td>\n",
       "      <td>0.080459</td>\n",
       "      <td>-0.550909</td>\n",
       "      <td>1.456825</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.934255</td>\n",
       "      <td>-0.796674</td>\n",
       "      <td>0.177838</td>\n",
       "      <td>0.674036</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242730</td>\n",
       "      <td>1.067333</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>-0.332729</td>\n",
       "      <td>-0.136988</td>\n",
       "      <td>-0.377262</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.324080</td>\n",
       "      <td>1.003313</td>\n",
       "      <td>-0.238043</td>\n",
       "      <td>1.301369</td>\n",
       "      <td>1.346139</td>\n",
       "      <td>-1.070045</td>\n",
       "      <td>0.394656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728983</td>\n",
       "      <td>-0.049093</td>\n",
       "      <td>-0.028142</td>\n",
       "      <td>-0.462700</td>\n",
       "      <td>0.854792</td>\n",
       "      <td>-1.003725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.726673</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>-0.162168</td>\n",
       "      <td>1.034116</td>\n",
       "      <td>-0.471118</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>0.658852</td>\n",
       "      <td>0.280108</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214733</td>\n",
       "      <td>1.101647</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>0.955306</td>\n",
       "      <td>1.560998</td>\n",
       "      <td>0.347138</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.608095</td>\n",
       "      <td>0.120443</td>\n",
       "      <td>0.506499</td>\n",
       "      <td>0.474668</td>\n",
       "      <td>0.468329</td>\n",
       "      <td>-0.072309</td>\n",
       "      <td>-0.153253</td>\n",
       "      <td>1.023858</td>\n",
       "      <td>-0.571696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582178</td>\n",
       "      <td>-0.310366</td>\n",
       "      <td>0.562462</td>\n",
       "      <td>0.507383</td>\n",
       "      <td>-0.598276</td>\n",
       "      <td>-0.163197</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>-0.038557</td>\n",
       "      <td>-0.053306</td>\n",
       "      <td>-0.309341</td>\n",
       "      <td>-0.451864</td>\n",
       "      <td>0.912437</td>\n",
       "      <td>1.096082</td>\n",
       "      <td>-1.184281</td>\n",
       "      <td>-0.348734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972589</td>\n",
       "      <td>-0.690223</td>\n",
       "      <td>-0.023980</td>\n",
       "      <td>-0.334356</td>\n",
       "      <td>-0.499823</td>\n",
       "      <td>-1.458170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.726983</td>\n",
       "      <td>0.172668</td>\n",
       "      <td>0.807782</td>\n",
       "      <td>-1.487305</td>\n",
       "      <td>-0.052809</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>-0.142895</td>\n",
       "      <td>-0.724678</td>\n",
       "      <td>-0.294431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693337</td>\n",
       "      <td>-0.787544</td>\n",
       "      <td>-0.027002</td>\n",
       "      <td>-0.295944</td>\n",
       "      <td>-0.173144</td>\n",
       "      <td>-1.096423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.091464</td>\n",
       "      <td>-6.622505</td>\n",
       "      <td>-4.137620</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.443319</td>\n",
       "      <td>1.366554</td>\n",
       "      <td>-0.374422</td>\n",
       "      <td>0.052184</td>\n",
       "      <td>0.650934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387075</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>0.184065</td>\n",
       "      <td>0.061090</td>\n",
       "      <td>0.669543</td>\n",
       "      <td>-1.139660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.730268</td>\n",
       "      <td>0.107589</td>\n",
       "      <td>0.252051</td>\n",
       "      <td>-1.426742</td>\n",
       "      <td>2.324433</td>\n",
       "      <td>0.923627</td>\n",
       "      <td>-0.476804</td>\n",
       "      <td>2.169406</td>\n",
       "      <td>0.937559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>0.892921</td>\n",
       "      <td>1.073479</td>\n",
       "      <td>2.532546</td>\n",
       "      <td>0.553153</td>\n",
       "      <td>-0.465658</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>-1.596008</td>\n",
       "      <td>0.064934</td>\n",
       "      <td>-0.075605</td>\n",
       "      <td>-1.489223</td>\n",
       "      <td>-1.298810</td>\n",
       "      <td>-0.031031</td>\n",
       "      <td>-0.650175</td>\n",
       "      <td>0.631035</td>\n",
       "      <td>-1.143585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840921</td>\n",
       "      <td>-1.197245</td>\n",
       "      <td>-2.394109</td>\n",
       "      <td>-1.239462</td>\n",
       "      <td>-1.148002</td>\n",
       "      <td>-0.981447</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.690482</td>\n",
       "      <td>0.097908</td>\n",
       "      <td>0.103474</td>\n",
       "      <td>-0.582799</td>\n",
       "      <td>0.781289</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>-0.420613</td>\n",
       "      <td>-1.100405</td>\n",
       "      <td>-0.433948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492959</td>\n",
       "      <td>-0.456686</td>\n",
       "      <td>-0.027114</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>-0.284436</td>\n",
       "      <td>-1.081466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.117758</td>\n",
       "      <td>0.203698</td>\n",
       "      <td>0.022555</td>\n",
       "      <td>1.495451</td>\n",
       "      <td>0.734431</td>\n",
       "      <td>-0.263161</td>\n",
       "      <td>-0.639095</td>\n",
       "      <td>-0.429803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229424</td>\n",
       "      <td>-0.699633</td>\n",
       "      <td>-0.026340</td>\n",
       "      <td>-0.148686</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>-0.861009</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.281340</td>\n",
       "      <td>0.190811</td>\n",
       "      <td>1.742359</td>\n",
       "      <td>-1.484460</td>\n",
       "      <td>0.458192</td>\n",
       "      <td>-0.615315</td>\n",
       "      <td>2.232514</td>\n",
       "      <td>2.325675</td>\n",
       "      <td>1.099900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453255</td>\n",
       "      <td>3.037939</td>\n",
       "      <td>3.499362</td>\n",
       "      <td>3.737089</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>2.392014</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.092803</td>\n",
       "      <td>0.111077</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>-0.182142</td>\n",
       "      <td>-0.043867</td>\n",
       "      <td>1.368148</td>\n",
       "      <td>-0.609990</td>\n",
       "      <td>-0.628217</td>\n",
       "      <td>0.141497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814595</td>\n",
       "      <td>-0.249040</td>\n",
       "      <td>0.626294</td>\n",
       "      <td>0.153753</td>\n",
       "      <td>0.253852</td>\n",
       "      <td>-1.306674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.489703</td>\n",
       "      <td>0.075335</td>\n",
       "      <td>-0.128944</td>\n",
       "      <td>0.691909</td>\n",
       "      <td>0.423212</td>\n",
       "      <td>0.907310</td>\n",
       "      <td>0.578446</td>\n",
       "      <td>0.637477</td>\n",
       "      <td>0.876819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223662</td>\n",
       "      <td>0.288307</td>\n",
       "      <td>-0.028721</td>\n",
       "      <td>0.642818</td>\n",
       "      <td>-0.135541</td>\n",
       "      <td>-0.467704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.810164</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>0.073955</td>\n",
       "      <td>-0.272472</td>\n",
       "      <td>-0.600905</td>\n",
       "      <td>0.703975</td>\n",
       "      <td>0.553190</td>\n",
       "      <td>-1.269708</td>\n",
       "      <td>-0.572511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204354</td>\n",
       "      <td>-0.758891</td>\n",
       "      <td>-0.094726</td>\n",
       "      <td>-0.778054</td>\n",
       "      <td>-0.611517</td>\n",
       "      <td>-1.199727</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1.297688</td>\n",
       "      <td>0.112578</td>\n",
       "      <td>0.087095</td>\n",
       "      <td>-1.096863</td>\n",
       "      <td>-0.826911</td>\n",
       "      <td>1.067548</td>\n",
       "      <td>-0.637575</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>0.250118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055161</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.898459</td>\n",
       "      <td>0.408985</td>\n",
       "      <td>-0.320850</td>\n",
       "      <td>-0.966587</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.223837</td>\n",
       "      <td>0.109078</td>\n",
       "      <td>-0.031426</td>\n",
       "      <td>-0.039285</td>\n",
       "      <td>-0.034862</td>\n",
       "      <td>1.262590</td>\n",
       "      <td>-0.940652</td>\n",
       "      <td>-0.647764</td>\n",
       "      <td>0.302088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339254</td>\n",
       "      <td>-0.148354</td>\n",
       "      <td>1.436954</td>\n",
       "      <td>0.295247</td>\n",
       "      <td>1.084135</td>\n",
       "      <td>-1.268919</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.336581</td>\n",
       "      <td>-0.041707</td>\n",
       "      <td>-0.296148</td>\n",
       "      <td>0.908039</td>\n",
       "      <td>-1.018932</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>-0.559477</td>\n",
       "      <td>-0.917238</td>\n",
       "      <td>0.194306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683024</td>\n",
       "      <td>0.562734</td>\n",
       "      <td>0.098669</td>\n",
       "      <td>-0.333542</td>\n",
       "      <td>-0.607518</td>\n",
       "      <td>-0.096619</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392388</th>\n",
       "      <td>392388</td>\n",
       "      <td>-1.423513</td>\n",
       "      <td>0.167308</td>\n",
       "      <td>0.534701</td>\n",
       "      <td>0.607736</td>\n",
       "      <td>0.234851</td>\n",
       "      <td>-0.471805</td>\n",
       "      <td>1.049298</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>-0.670134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564033</td>\n",
       "      <td>-0.533693</td>\n",
       "      <td>-0.290298</td>\n",
       "      <td>0.132533</td>\n",
       "      <td>-0.896669</td>\n",
       "      <td>-0.381180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392389</th>\n",
       "      <td>392389</td>\n",
       "      <td>0.743905</td>\n",
       "      <td>0.104801</td>\n",
       "      <td>0.132121</td>\n",
       "      <td>-0.374262</td>\n",
       "      <td>0.224657</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>-0.147488</td>\n",
       "      <td>-0.574485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>-0.750212</td>\n",
       "      <td>-0.029958</td>\n",
       "      <td>-0.230185</td>\n",
       "      <td>0.276216</td>\n",
       "      <td>-0.734549</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392390</th>\n",
       "      <td>392390</td>\n",
       "      <td>-5.704098</td>\n",
       "      <td>0.151951</td>\n",
       "      <td>0.842026</td>\n",
       "      <td>0.427951</td>\n",
       "      <td>-0.714916</td>\n",
       "      <td>-2.347634</td>\n",
       "      <td>1.908877</td>\n",
       "      <td>5.834639</td>\n",
       "      <td>-4.143913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.853727</td>\n",
       "      <td>-1.346327</td>\n",
       "      <td>-3.836482</td>\n",
       "      <td>-1.236660</td>\n",
       "      <td>-1.306840</td>\n",
       "      <td>0.294507</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392391</th>\n",
       "      <td>392391</td>\n",
       "      <td>0.948755</td>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.108863</td>\n",
       "      <td>0.473294</td>\n",
       "      <td>-0.717875</td>\n",
       "      <td>0.267308</td>\n",
       "      <td>1.340968</td>\n",
       "      <td>-0.922652</td>\n",
       "      <td>-0.493807</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178015</td>\n",
       "      <td>-0.791031</td>\n",
       "      <td>0.557796</td>\n",
       "      <td>-0.303601</td>\n",
       "      <td>-0.687063</td>\n",
       "      <td>-1.009316</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392392</th>\n",
       "      <td>392392</td>\n",
       "      <td>-1.333350</td>\n",
       "      <td>0.171777</td>\n",
       "      <td>0.936693</td>\n",
       "      <td>0.478916</td>\n",
       "      <td>-1.175617</td>\n",
       "      <td>-1.893116</td>\n",
       "      <td>2.043470</td>\n",
       "      <td>0.452646</td>\n",
       "      <td>-1.515132</td>\n",
       "      <td>...</td>\n",
       "      <td>2.459347</td>\n",
       "      <td>-0.691054</td>\n",
       "      <td>-1.720078</td>\n",
       "      <td>-0.134671</td>\n",
       "      <td>-0.982414</td>\n",
       "      <td>-0.381718</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392393</th>\n",
       "      <td>392393</td>\n",
       "      <td>-4.127799</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.459564</td>\n",
       "      <td>0.703371</td>\n",
       "      <td>-0.508658</td>\n",
       "      <td>-1.675315</td>\n",
       "      <td>1.643614</td>\n",
       "      <td>3.737716</td>\n",
       "      <td>-3.002158</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151693</td>\n",
       "      <td>-1.207385</td>\n",
       "      <td>-1.796986</td>\n",
       "      <td>-1.000024</td>\n",
       "      <td>-0.966943</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392394</th>\n",
       "      <td>392394</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.116630</td>\n",
       "      <td>0.499814</td>\n",
       "      <td>0.805903</td>\n",
       "      <td>-0.283270</td>\n",
       "      <td>-1.125711</td>\n",
       "      <td>1.935802</td>\n",
       "      <td>-1.065917</td>\n",
       "      <td>-0.373331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312751</td>\n",
       "      <td>-0.717083</td>\n",
       "      <td>0.503641</td>\n",
       "      <td>-0.178116</td>\n",
       "      <td>-0.717436</td>\n",
       "      <td>0.696621</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392395</th>\n",
       "      <td>392395</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.511256</td>\n",
       "      <td>1.399988</td>\n",
       "      <td>-0.293710</td>\n",
       "      <td>0.055457</td>\n",
       "      <td>0.681978</td>\n",
       "      <td>-0.563605</td>\n",
       "      <td>-1.106505</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056458</td>\n",
       "      <td>-1.292010</td>\n",
       "      <td>-0.830400</td>\n",
       "      <td>-1.143411</td>\n",
       "      <td>-0.731965</td>\n",
       "      <td>-1.078094</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392396</th>\n",
       "      <td>392396</td>\n",
       "      <td>0.404972</td>\n",
       "      <td>0.174811</td>\n",
       "      <td>0.769204</td>\n",
       "      <td>-1.313354</td>\n",
       "      <td>-0.860703</td>\n",
       "      <td>-0.322756</td>\n",
       "      <td>2.102622</td>\n",
       "      <td>-0.919118</td>\n",
       "      <td>-0.596633</td>\n",
       "      <td>...</td>\n",
       "      <td>1.723006</td>\n",
       "      <td>-1.102629</td>\n",
       "      <td>-0.611061</td>\n",
       "      <td>-1.031839</td>\n",
       "      <td>-0.975698</td>\n",
       "      <td>-0.362183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392397</th>\n",
       "      <td>392397</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>0.142937</td>\n",
       "      <td>0.460761</td>\n",
       "      <td>1.393494</td>\n",
       "      <td>-0.367823</td>\n",
       "      <td>-0.614452</td>\n",
       "      <td>2.293238</td>\n",
       "      <td>-0.383296</td>\n",
       "      <td>-0.959929</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677219</td>\n",
       "      <td>-1.035007</td>\n",
       "      <td>-0.029001</td>\n",
       "      <td>-0.710333</td>\n",
       "      <td>-0.713922</td>\n",
       "      <td>-0.341215</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392398</th>\n",
       "      <td>392398</td>\n",
       "      <td>0.519993</td>\n",
       "      <td>0.464176</td>\n",
       "      <td>1.734429</td>\n",
       "      <td>1.119610</td>\n",
       "      <td>-0.248078</td>\n",
       "      <td>-0.456025</td>\n",
       "      <td>1.906114</td>\n",
       "      <td>-1.359212</td>\n",
       "      <td>-0.521557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534360</td>\n",
       "      <td>-0.742136</td>\n",
       "      <td>0.135905</td>\n",
       "      <td>-0.221013</td>\n",
       "      <td>-0.666344</td>\n",
       "      <td>-0.090718</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392399</th>\n",
       "      <td>392399</td>\n",
       "      <td>0.818064</td>\n",
       "      <td>0.126621</td>\n",
       "      <td>0.445923</td>\n",
       "      <td>0.516672</td>\n",
       "      <td>-0.034336</td>\n",
       "      <td>-1.602195</td>\n",
       "      <td>1.691172</td>\n",
       "      <td>-0.612964</td>\n",
       "      <td>-0.140444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462911</td>\n",
       "      <td>-0.379237</td>\n",
       "      <td>1.131560</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>-0.410324</td>\n",
       "      <td>0.529508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392400</th>\n",
       "      <td>392400</td>\n",
       "      <td>-0.794797</td>\n",
       "      <td>0.339065</td>\n",
       "      <td>1.877315</td>\n",
       "      <td>1.502383</td>\n",
       "      <td>-1.140633</td>\n",
       "      <td>-1.151178</td>\n",
       "      <td>2.229915</td>\n",
       "      <td>-0.085625</td>\n",
       "      <td>-0.570693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.978062</td>\n",
       "      <td>-0.596482</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>-0.951174</td>\n",
       "      <td>-0.060551</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392401</th>\n",
       "      <td>392401</td>\n",
       "      <td>-0.422043</td>\n",
       "      <td>0.117488</td>\n",
       "      <td>0.301211</td>\n",
       "      <td>1.473337</td>\n",
       "      <td>1.814799</td>\n",
       "      <td>-0.339720</td>\n",
       "      <td>2.353862</td>\n",
       "      <td>-0.553891</td>\n",
       "      <td>-0.847717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.482119</td>\n",
       "      <td>-1.189733</td>\n",
       "      <td>-0.383259</td>\n",
       "      <td>-0.971284</td>\n",
       "      <td>-0.795181</td>\n",
       "      <td>-0.401173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392402</th>\n",
       "      <td>392402</td>\n",
       "      <td>0.775894</td>\n",
       "      <td>0.554009</td>\n",
       "      <td>1.310673</td>\n",
       "      <td>-1.271971</td>\n",
       "      <td>-0.585672</td>\n",
       "      <td>-1.271932</td>\n",
       "      <td>2.558080</td>\n",
       "      <td>-0.474688</td>\n",
       "      <td>0.043839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977996</td>\n",
       "      <td>-0.363002</td>\n",
       "      <td>0.609188</td>\n",
       "      <td>0.419275</td>\n",
       "      <td>-0.509522</td>\n",
       "      <td>0.757966</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392403</th>\n",
       "      <td>392403</td>\n",
       "      <td>0.208247</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>0.408663</td>\n",
       "      <td>0.233220</td>\n",
       "      <td>-0.818471</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>2.161562</td>\n",
       "      <td>-0.812121</td>\n",
       "      <td>-0.984756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.643891</td>\n",
       "      <td>-1.128402</td>\n",
       "      <td>-1.177932</td>\n",
       "      <td>-0.870991</td>\n",
       "      <td>-1.008515</td>\n",
       "      <td>-0.825045</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392404</th>\n",
       "      <td>392404</td>\n",
       "      <td>-0.212098</td>\n",
       "      <td>0.699584</td>\n",
       "      <td>4.875106</td>\n",
       "      <td>0.950824</td>\n",
       "      <td>0.082870</td>\n",
       "      <td>-1.757507</td>\n",
       "      <td>0.907291</td>\n",
       "      <td>-0.535618</td>\n",
       "      <td>-0.611391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>-0.969896</td>\n",
       "      <td>-0.136670</td>\n",
       "      <td>-0.603604</td>\n",
       "      <td>-0.939758</td>\n",
       "      <td>0.839890</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392405</th>\n",
       "      <td>392405</td>\n",
       "      <td>0.696054</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.590442</td>\n",
       "      <td>0.346495</td>\n",
       "      <td>3.390678</td>\n",
       "      <td>-0.659072</td>\n",
       "      <td>1.371766</td>\n",
       "      <td>-0.988596</td>\n",
       "      <td>-0.570178</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436345</td>\n",
       "      <td>-0.993734</td>\n",
       "      <td>-0.042190</td>\n",
       "      <td>-0.643818</td>\n",
       "      <td>0.212623</td>\n",
       "      <td>-0.306333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392406</th>\n",
       "      <td>392406</td>\n",
       "      <td>-0.478733</td>\n",
       "      <td>0.201436</td>\n",
       "      <td>0.808623</td>\n",
       "      <td>0.652776</td>\n",
       "      <td>1.577076</td>\n",
       "      <td>-1.512189</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.577090</td>\n",
       "      <td>-1.201249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763845</td>\n",
       "      <td>-0.996271</td>\n",
       "      <td>0.480942</td>\n",
       "      <td>-0.647538</td>\n",
       "      <td>0.564862</td>\n",
       "      <td>-0.817512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392407</th>\n",
       "      <td>392407</td>\n",
       "      <td>-0.597892</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>0.284487</td>\n",
       "      <td>0.958503</td>\n",
       "      <td>0.841165</td>\n",
       "      <td>-0.558920</td>\n",
       "      <td>1.793998</td>\n",
       "      <td>0.334268</td>\n",
       "      <td>-0.658402</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534844</td>\n",
       "      <td>-0.668305</td>\n",
       "      <td>0.211856</td>\n",
       "      <td>-0.096405</td>\n",
       "      <td>-0.636644</td>\n",
       "      <td>-0.433108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392408</th>\n",
       "      <td>392408</td>\n",
       "      <td>0.311886</td>\n",
       "      <td>0.189731</td>\n",
       "      <td>0.573437</td>\n",
       "      <td>0.587021</td>\n",
       "      <td>0.254437</td>\n",
       "      <td>-1.751570</td>\n",
       "      <td>2.057687</td>\n",
       "      <td>-0.164465</td>\n",
       "      <td>-0.809398</td>\n",
       "      <td>...</td>\n",
       "      <td>1.664669</td>\n",
       "      <td>-0.817795</td>\n",
       "      <td>0.778147</td>\n",
       "      <td>-0.346729</td>\n",
       "      <td>-0.532107</td>\n",
       "      <td>-0.520551</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392409</th>\n",
       "      <td>392409</td>\n",
       "      <td>-1.056754</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>0.255655</td>\n",
       "      <td>1.648514</td>\n",
       "      <td>-0.595412</td>\n",
       "      <td>-0.973809</td>\n",
       "      <td>2.538426</td>\n",
       "      <td>0.091854</td>\n",
       "      <td>-1.361443</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336302</td>\n",
       "      <td>-1.035028</td>\n",
       "      <td>-0.997675</td>\n",
       "      <td>-0.710584</td>\n",
       "      <td>-0.777240</td>\n",
       "      <td>-0.620751</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392410</th>\n",
       "      <td>392410</td>\n",
       "      <td>1.139487</td>\n",
       "      <td>0.121127</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.153762</td>\n",
       "      <td>-0.317403</td>\n",
       "      <td>1.191220</td>\n",
       "      <td>-0.999144</td>\n",
       "      <td>-1.120671</td>\n",
       "      <td>-0.296637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393990</td>\n",
       "      <td>-0.740681</td>\n",
       "      <td>0.243385</td>\n",
       "      <td>-0.689720</td>\n",
       "      <td>-0.490139</td>\n",
       "      <td>-1.473238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392411</th>\n",
       "      <td>392411</td>\n",
       "      <td>-0.089265</td>\n",
       "      <td>0.208287</td>\n",
       "      <td>0.515470</td>\n",
       "      <td>-0.901561</td>\n",
       "      <td>-0.558776</td>\n",
       "      <td>-0.953002</td>\n",
       "      <td>0.937919</td>\n",
       "      <td>-0.705813</td>\n",
       "      <td>-0.883156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.619779</td>\n",
       "      <td>-1.074890</td>\n",
       "      <td>-0.859521</td>\n",
       "      <td>-1.124992</td>\n",
       "      <td>-0.697059</td>\n",
       "      <td>-0.756308</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392412</th>\n",
       "      <td>392412</td>\n",
       "      <td>-0.148131</td>\n",
       "      <td>0.110577</td>\n",
       "      <td>0.212749</td>\n",
       "      <td>1.220278</td>\n",
       "      <td>2.282164</td>\n",
       "      <td>0.194610</td>\n",
       "      <td>1.287463</td>\n",
       "      <td>-0.576610</td>\n",
       "      <td>-0.990503</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606360</td>\n",
       "      <td>-1.138052</td>\n",
       "      <td>-0.028545</td>\n",
       "      <td>-0.884170</td>\n",
       "      <td>-0.791694</td>\n",
       "      <td>-0.945065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392413</th>\n",
       "      <td>392413</td>\n",
       "      <td>1.036691</td>\n",
       "      <td>0.103932</td>\n",
       "      <td>-0.012405</td>\n",
       "      <td>-0.646588</td>\n",
       "      <td>-1.019443</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>1.237977</td>\n",
       "      <td>-1.405691</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>-0.880991</td>\n",
       "      <td>0.187720</td>\n",
       "      <td>-0.778109</td>\n",
       "      <td>-0.988713</td>\n",
       "      <td>-0.616302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392414</th>\n",
       "      <td>392414</td>\n",
       "      <td>0.100422</td>\n",
       "      <td>0.120304</td>\n",
       "      <td>0.450308</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>-0.180320</td>\n",
       "      <td>-2.278920</td>\n",
       "      <td>-0.022596</td>\n",
       "      <td>-0.052790</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269637</td>\n",
       "      <td>-0.497870</td>\n",
       "      <td>-0.536995</td>\n",
       "      <td>0.192007</td>\n",
       "      <td>-0.142911</td>\n",
       "      <td>-0.273740</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392415</th>\n",
       "      <td>392415</td>\n",
       "      <td>0.692381</td>\n",
       "      <td>0.115213</td>\n",
       "      <td>0.142474</td>\n",
       "      <td>-1.421107</td>\n",
       "      <td>0.308732</td>\n",
       "      <td>-0.414836</td>\n",
       "      <td>-0.838686</td>\n",
       "      <td>-0.072933</td>\n",
       "      <td>-0.129907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>-0.518387</td>\n",
       "      <td>-0.025108</td>\n",
       "      <td>0.155050</td>\n",
       "      <td>-0.930533</td>\n",
       "      <td>-0.397628</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392416</th>\n",
       "      <td>392416</td>\n",
       "      <td>0.274162</td>\n",
       "      <td>0.094467</td>\n",
       "      <td>0.071979</td>\n",
       "      <td>0.701495</td>\n",
       "      <td>0.038264</td>\n",
       "      <td>0.435481</td>\n",
       "      <td>-1.122645</td>\n",
       "      <td>-1.145916</td>\n",
       "      <td>-0.608864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172655</td>\n",
       "      <td>-1.103282</td>\n",
       "      <td>-0.028422</td>\n",
       "      <td>-1.170172</td>\n",
       "      <td>-0.757993</td>\n",
       "      <td>-1.454178</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392417</th>\n",
       "      <td>392417</td>\n",
       "      <td>-0.515426</td>\n",
       "      <td>0.130562</td>\n",
       "      <td>0.264915</td>\n",
       "      <td>1.576235</td>\n",
       "      <td>0.076662</td>\n",
       "      <td>0.128618</td>\n",
       "      <td>0.353430</td>\n",
       "      <td>-0.153576</td>\n",
       "      <td>-1.045631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.646194</td>\n",
       "      <td>-1.243300</td>\n",
       "      <td>-0.345492</td>\n",
       "      <td>-1.064571</td>\n",
       "      <td>-0.891534</td>\n",
       "      <td>-1.038859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392418 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature0  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0            0 -0.614041  0.114416  0.231052  1.273933 -0.299535 -0.076514   \n",
       "1            1  0.986737 -0.276118 -0.626683  1.366301 -0.588178  1.323094   \n",
       "2            2  0.396707 -1.748540 -2.120154  1.226534  0.398690  1.069129   \n",
       "3            3  0.686342  0.119166 -0.141433  0.546838  2.436892  1.194097   \n",
       "4            4 -0.488483  0.090380  0.074291  0.088601 -1.108423 -0.147028   \n",
       "5            5  0.151643  0.137570  0.399777 -1.400313  0.812501  0.098386   \n",
       "6            6  0.862462  0.074743 -0.756178  0.714230 -0.227506  1.269414   \n",
       "7            7  0.271582 -0.012460 -0.103276 -0.911698 -0.242800  0.992016   \n",
       "8            8  0.985132  0.010269 -0.176043  1.380970  0.492982  1.321854   \n",
       "9            9  0.273723 -0.018082 -0.455830  1.090874 -0.614171  1.018233   \n",
       "10          10 -1.807069  0.123885  1.080072  1.624313  0.681922 -1.009065   \n",
       "11          11 -0.176996  0.055128  0.268626  1.626769  0.654820 -0.004577   \n",
       "12          12  0.079347  0.080459 -0.550909  1.456825  0.117941  0.934255   \n",
       "13          13  0.978869 -0.000524 -0.324080  1.003313 -0.238043  1.301369   \n",
       "14          14  0.726673  0.046700 -0.162168  1.034116 -0.471118  0.068612   \n",
       "15          15 -0.608095  0.120443  0.506499  0.474668  0.468329 -0.072309   \n",
       "16          16  0.980556 -0.038557 -0.053306 -0.309341 -0.451864  0.912437   \n",
       "17          17  0.726983  0.172668  0.807782 -1.487305 -0.052809  0.604789   \n",
       "18          18  1.091464 -6.622505 -4.137620  0.557441  0.443319  1.366554   \n",
       "19          19  0.730268  0.107589  0.252051 -1.426742  2.324433  0.923627   \n",
       "20          20 -1.596008  0.064934 -0.075605 -1.489223 -1.298810 -0.031031   \n",
       "21          21  0.690482  0.097908  0.103474 -0.582799  0.781289  0.657999   \n",
       "22          22  0.743749  0.117758  0.203698  0.022555  1.495451  0.734431   \n",
       "23          23  1.281340  0.190811  1.742359 -1.484460  0.458192 -0.615315   \n",
       "24          24  1.092803  0.111077  0.004493 -0.182142 -0.043867  1.368148   \n",
       "25          25  0.489703  0.075335 -0.128944  0.691909  0.423212  0.907310   \n",
       "26          26  0.810164  0.107501  0.073955 -0.272472 -0.600905  0.703975   \n",
       "27          27  1.297688  0.112578  0.087095 -1.096863 -0.826911  1.067548   \n",
       "28          28  1.223837  0.109078 -0.031426 -0.039285 -0.034862  1.262590   \n",
       "29          29  0.336581 -0.041707 -0.296148  0.908039 -1.018932  0.029081   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "392388  392388 -1.423513  0.167308  0.534701  0.607736  0.234851 -0.471805   \n",
       "392389  392389  0.743905  0.104801  0.132121 -0.374262  0.224657  0.005030   \n",
       "392390  392390 -5.704098  0.151951  0.842026  0.427951 -0.714916 -2.347634   \n",
       "392391  392391  0.948755  0.118488  0.108863  0.473294 -0.717875  0.267308   \n",
       "392392  392392 -1.333350  0.171777  0.936693  0.478916 -1.175617 -1.893116   \n",
       "392393  392393 -4.127799  0.116352  0.459564  0.703371 -0.508658 -1.675315   \n",
       "392394  392394  0.003342  0.116630  0.499814  0.805903 -0.283270 -1.125711   \n",
       "392395  392395  0.044499  0.143284  0.511256  1.399988 -0.293710  0.055457   \n",
       "392396  392396  0.404972  0.174811  0.769204 -1.313354 -0.860703 -0.322756   \n",
       "392397  392397 -0.290924  0.142937  0.460761  1.393494 -0.367823 -0.614452   \n",
       "392398  392398  0.519993  0.464176  1.734429  1.119610 -0.248078 -0.456025   \n",
       "392399  392399  0.818064  0.126621  0.445923  0.516672 -0.034336 -1.602195   \n",
       "392400  392400 -0.794797  0.339065  1.877315  1.502383 -1.140633 -1.151178   \n",
       "392401  392401 -0.422043  0.117488  0.301211  1.473337  1.814799 -0.339720   \n",
       "392402  392402  0.775894  0.554009  1.310673 -1.271971 -0.585672 -1.271932   \n",
       "392403  392403  0.208247  0.123565  0.408663  0.233220 -0.818471  0.028769   \n",
       "392404  392404 -0.212098  0.699584  4.875106  0.950824  0.082870 -1.757507   \n",
       "392405  392405  0.696054  0.187256  0.590442  0.346495  3.390678 -0.659072   \n",
       "392406  392406 -0.478733  0.201436  0.808623  0.652776  1.577076 -1.512189   \n",
       "392407  392407 -0.597892  0.134353  0.284487  0.958503  0.841165 -0.558920   \n",
       "392408  392408  0.311886  0.189731  0.573437  0.587021  0.254437 -1.751570   \n",
       "392409  392409 -1.056754  0.113205  0.255655  1.648514 -0.595412 -0.973809   \n",
       "392410  392410  1.139487  0.121127  0.012242  0.153762 -0.317403  1.191220   \n",
       "392411  392411 -0.089265  0.208287  0.515470 -0.901561 -0.558776 -0.953002   \n",
       "392412  392412 -0.148131  0.110577  0.212749  1.220278  2.282164  0.194610   \n",
       "392413  392413  1.036691  0.103932 -0.012405 -0.646588 -1.019443  0.271354   \n",
       "392414  392414  0.100422  0.120304  0.450308  0.016195 -0.180320 -2.278920   \n",
       "392415  392415  0.692381  0.115213  0.142474 -1.421107  0.308732 -0.414836   \n",
       "392416  392416  0.274162  0.094467  0.071979  0.701495  0.038264  0.435481   \n",
       "392417  392417 -0.515426  0.130562  0.264915  1.576235  0.076662  0.128618   \n",
       "\n",
       "        feature6  feature7  feature8 ...   feature82  feature83  feature84  \\\n",
       "0       0.128355 -0.053832 -0.572873 ...    1.134926  -0.755843   0.317429   \n",
       "1      -0.808199 -0.177238  0.951274 ...   -1.053611   0.567973   0.000057   \n",
       "2      -0.635431  0.747981  2.277830 ...   -1.786568   2.328527   0.444290   \n",
       "3      -0.671772  0.356273  0.369298 ...   -0.278068   0.306136  -0.026526   \n",
       "4      -0.463876 -0.267537 -0.772068 ...   -0.182212  -1.162430  -0.564973   \n",
       "5      -0.323754  0.168058 -0.280357 ...    0.600144  -0.255070  -0.026942   \n",
       "6      -0.200736  0.234439  0.888671 ...   -1.676531   0.446269   0.031392   \n",
       "7      -0.618712 -1.130434 -0.462614 ...   -1.016529  -0.636494  -0.284672   \n",
       "8       0.977000  0.357832  0.709694 ...   -1.710409  -0.038793  -0.026687   \n",
       "9       1.139140  0.344746  0.933291 ...   -1.350233   0.874880  -0.025257   \n",
       "10     -0.216578  1.036015 -1.909669 ...    0.613530  -1.216052  -1.224894   \n",
       "11     -0.012363 -1.062414 -0.782823 ...    0.421035  -1.190525  -0.027763   \n",
       "12     -0.796674  0.177838  0.674036 ...   -1.242730   1.067333  -0.323565   \n",
       "13      1.346139 -1.070045  0.394656 ...   -0.728983  -0.049093  -0.028142   \n",
       "14      0.658852  0.280108  0.903776 ...    1.214733   1.101647  -0.027325   \n",
       "15     -0.153253  1.023858 -0.571696 ...    0.582178  -0.310366   0.562462   \n",
       "16      1.096082 -1.184281 -0.348734 ...   -0.972589  -0.690223  -0.023980   \n",
       "17     -0.142895 -0.724678 -0.294431 ...    0.693337  -0.787544  -0.027002   \n",
       "18     -0.374422  0.052184  0.650934 ...   -0.387075   0.017338   0.184065   \n",
       "19     -0.476804  2.169406  0.937559 ...   -0.315313   0.892921   1.073479   \n",
       "20     -0.650175  0.631035 -1.143585 ...    0.840921  -1.197245  -2.394109   \n",
       "21     -0.420613 -1.100405 -0.433948 ...   -0.492959  -0.456686  -0.027114   \n",
       "22     -0.263161 -0.639095 -0.429803 ...   -0.229424  -0.699633  -0.026340   \n",
       "23      2.232514  2.325675  1.099900 ...    0.453255   3.037939   3.499362   \n",
       "24     -0.609990 -0.628217  0.141497 ...   -0.814595  -0.249040   0.626294   \n",
       "25      0.578446  0.637477  0.876819 ...    0.223662   0.288307  -0.028721   \n",
       "26      0.553190 -1.269708 -0.572511 ...    0.204354  -0.758891  -0.094726   \n",
       "27     -0.637575  0.211941  0.250118 ...   -0.055161   0.023338   0.898459   \n",
       "28     -0.940652 -0.647764  0.302088 ...   -0.339254  -0.148354   1.436954   \n",
       "29     -0.559477 -0.917238  0.194306 ...    0.683024   0.562734   0.098669   \n",
       "...          ...       ...       ... ...         ...        ...        ...   \n",
       "392388  1.049298 -0.096002 -0.670134 ...    0.564033  -0.533693  -0.290298   \n",
       "392389  0.636559 -0.147488 -0.574485 ...    0.713415  -0.750212  -0.029958   \n",
       "392390  1.908877  5.834639 -4.143913 ...    1.853727  -1.346327  -3.836482   \n",
       "392391  1.340968 -0.922652 -0.493807 ...    1.178015  -0.791031   0.557796   \n",
       "392392  2.043470  0.452646 -1.515132 ...    2.459347  -0.691054  -1.720078   \n",
       "392393  1.643614  3.737716 -3.002158 ...    2.151693  -1.207385  -1.796986   \n",
       "392394  1.935802 -1.065917 -0.373331 ...    1.312751  -0.717083   0.503641   \n",
       "392395  0.681978 -0.563605 -1.106505 ...    1.056458  -1.292010  -0.830400   \n",
       "392396  2.102622 -0.919118 -0.596633 ...    1.723006  -1.102629  -0.611061   \n",
       "392397  2.293238 -0.383296 -0.959929 ...    1.677219  -1.035007  -0.029001   \n",
       "392398  1.906114 -1.359212 -0.521557 ...    1.534360  -0.742136   0.135905   \n",
       "392399  1.691172 -0.612964 -0.140444 ...    1.462911  -0.379237   1.131560   \n",
       "392400  2.229915 -0.085625 -0.570693 ...    1.978062  -0.596482   0.057100   \n",
       "392401  2.353862 -0.553891 -0.847717 ...    2.482119  -1.189733  -0.383259   \n",
       "392402  2.558080 -0.474688  0.043839 ...    0.977996  -0.363002   0.609188   \n",
       "392403  2.161562 -0.812121 -0.984756 ...    1.643891  -1.128402  -1.177932   \n",
       "392404  0.907291 -0.535618 -0.611391 ...    1.167900  -0.969896  -0.136670   \n",
       "392405  1.371766 -0.988596 -0.570178 ...    1.436345  -0.993734  -0.042190   \n",
       "392406  0.530733  0.577090 -1.201249 ...    0.763845  -0.996271   0.480942   \n",
       "392407  1.793998  0.334268 -0.658402 ...    1.534844  -0.668305   0.211856   \n",
       "392408  2.057687 -0.164465 -0.809398 ...    1.664669  -0.817795   0.778147   \n",
       "392409  2.538426  0.091854 -1.361443 ...    2.336302  -1.035028  -0.997675   \n",
       "392410 -0.999144 -1.120671 -0.296637 ...   -0.393990  -0.740681   0.243385   \n",
       "392411  0.937919 -0.705813 -0.883156 ...    1.619779  -1.074890  -0.859521   \n",
       "392412  1.287463 -0.576610 -0.990503 ...    1.606360  -1.138052  -0.028545   \n",
       "392413  1.237977 -1.405691 -0.331746 ...    0.622222  -0.880991   0.187720   \n",
       "392414 -0.022596 -0.052790 -0.751063 ...    0.269637  -0.497870  -0.536995   \n",
       "392415 -0.838686 -0.072933 -0.129907 ...    0.095086  -0.518387  -0.025108   \n",
       "392416 -1.122645 -1.145916 -0.608864 ...    0.172655  -1.103282  -0.028422   \n",
       "392417  0.353430 -0.153576 -1.045631 ...    1.646194  -1.243300  -0.345492   \n",
       "\n",
       "        feature85  feature86  feature87  weight  label  group  era  \n",
       "0       -0.241113  -0.746367  -0.365467     4.0    0.0     20    1  \n",
       "1        0.325993   1.038188  -0.680053     6.0    0.0      4    1  \n",
       "2        1.362455   0.097616   0.614781     2.0    0.0     11    1  \n",
       "3        0.502339   0.116241  -0.915358     2.0    0.0     20    1  \n",
       "4       -1.000597  -0.544647  -0.990627     7.0    0.0      3    1  \n",
       "5        0.599934  -0.105256  -0.497817     5.0    0.0      6    1  \n",
       "6        0.781035   1.225703  -0.695879     8.0    0.0     13    1  \n",
       "7       -0.707933  -0.466095  -1.530306     1.0    0.0      7    1  \n",
       "8        0.235733   1.336808  -0.924962     0.0    0.0     14    1  \n",
       "9        0.242308  -0.387662  -0.257792     9.0    0.0     20    1  \n",
       "10      -1.018993  -0.733822   0.097809     5.0    0.0     13    1  \n",
       "11      -0.973241  -0.893666  -0.796483     4.0    0.0     14    1  \n",
       "12      -0.332729  -0.136988  -0.377262     4.0    0.0     22    1  \n",
       "13      -0.462700   0.854792  -1.003725     4.0    0.0     27    1  \n",
       "14       0.955306   1.560998   0.347138     3.0    1.0     14    1  \n",
       "15       0.507383  -0.598276  -0.163197     9.0    0.0     13    1  \n",
       "16      -0.334356  -0.499823  -1.458170     4.0    1.0     12    1  \n",
       "17      -0.295944  -0.173144  -1.096423     0.0    0.0     18    1  \n",
       "18       0.061090   0.669543  -1.139660     0.0    0.0      3    1  \n",
       "19       2.532546   0.553153  -0.465658     2.0    1.0      5    1  \n",
       "20      -1.239462  -1.148002  -0.981447     4.0    0.0      4    1  \n",
       "21       0.109524  -0.284436  -1.081466     1.0    1.0      3    1  \n",
       "22      -0.148686   0.132829  -0.861009     5.0    1.0     12    1  \n",
       "23       3.737089   0.039480   2.392014    11.0    1.0      9    1  \n",
       "24       0.153753   0.253852  -1.306674     0.0    1.0      9    1  \n",
       "25       0.642818  -0.135541  -0.467704     1.0    1.0     22    1  \n",
       "26      -0.778054  -0.611517  -1.199727     4.0    0.0     16    1  \n",
       "27       0.408985  -0.320850  -0.966587     3.0    0.0     17    1  \n",
       "28       0.295247   1.084135  -1.268919     3.0    0.0     14    1  \n",
       "29      -0.333542  -0.607518  -0.096619     3.0    0.0     15    1  \n",
       "...           ...        ...        ...     ...    ...    ...  ...  \n",
       "392388   0.132533  -0.896669  -0.381180     1.0    1.0     27   20  \n",
       "392389  -0.230185   0.276216  -0.734549     4.0    1.0      9   20  \n",
       "392390  -1.236660  -1.306840   0.294507     2.0    1.0      3   20  \n",
       "392391  -0.303601  -0.687063  -1.009316     3.0    0.0      3   20  \n",
       "392392  -0.134671  -0.982414  -0.381718     5.0    0.0      6   20  \n",
       "392393  -1.000024  -0.966943  -0.000349     7.0    1.0     12   20  \n",
       "392394  -0.178116  -0.717436   0.696621     9.0    1.0     26   20  \n",
       "392395  -1.143411  -0.731965  -1.078094     7.0    1.0     21   20  \n",
       "392396  -1.031839  -0.975698  -0.362183     1.0    1.0     20   20  \n",
       "392397  -0.710333  -0.713922  -0.341215     5.0    1.0      5   20  \n",
       "392398  -0.221013  -0.666344  -0.090718     5.0    0.0      7   20  \n",
       "392399   0.097846  -0.410324   0.529508     1.0    1.0      6   20  \n",
       "392400   0.025061  -0.951174  -0.060551     4.0    0.0      6   20  \n",
       "392401  -0.971284  -0.795181  -0.401173     2.0    1.0     18   20  \n",
       "392402   0.419275  -0.509522   0.757966    10.0    1.0     12   20  \n",
       "392403  -0.870991  -1.008515  -0.825045     5.0    0.0     15   20  \n",
       "392404  -0.603604  -0.939758   0.839890     8.0    0.0     15   20  \n",
       "392405  -0.643818   0.212623  -0.306333     2.0    1.0     14   20  \n",
       "392406  -0.647538   0.564862  -0.817512     0.0    1.0     17   20  \n",
       "392407  -0.096405  -0.636644  -0.433108     2.0    1.0     13   20  \n",
       "392408  -0.346729  -0.532107  -0.520551     2.0    1.0      0   20  \n",
       "392409  -0.710584  -0.777240  -0.620751     2.0    1.0     10   20  \n",
       "392410  -0.689720  -0.490139  -1.473238     0.0    0.0     27   20  \n",
       "392411  -1.124992  -0.697059  -0.756308     4.0    1.0      9   20  \n",
       "392412  -0.884170  -0.791694  -0.945065     1.0    0.0      4   20  \n",
       "392413  -0.778109  -0.988713  -0.616302     1.0    0.0      0   20  \n",
       "392414   0.192007  -0.142911  -0.273740     4.0    0.0     22   20  \n",
       "392415   0.155050  -0.930533  -0.397628     4.0    0.0      5   20  \n",
       "392416  -1.170172  -0.757993  -1.454178     2.0    1.0     27   20  \n",
       "392417  -1.064571  -0.891534  -1.038859     0.0    0.0     11   20  \n",
       "\n",
       "[392418 rows x 93 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1              1\n",
       "2              2\n",
       "3              3\n",
       "4              4\n",
       "5              5\n",
       "6              6\n",
       "7              7\n",
       "8              8\n",
       "9              9\n",
       "10            10\n",
       "11            11\n",
       "12            12\n",
       "13            13\n",
       "14            14\n",
       "15            15\n",
       "16            16\n",
       "17            17\n",
       "18            18\n",
       "19            19\n",
       "20            20\n",
       "21            21\n",
       "22            22\n",
       "23            23\n",
       "24            24\n",
       "25            25\n",
       "26            26\n",
       "27            27\n",
       "28            28\n",
       "29            29\n",
       "           ...  \n",
       "392388    392388\n",
       "392389    392389\n",
       "392390    392390\n",
       "392391    392391\n",
       "392392    392392\n",
       "392393    392393\n",
       "392394    392394\n",
       "392395    392395\n",
       "392396    392396\n",
       "392397    392397\n",
       "392398    392398\n",
       "392399    392399\n",
       "392400    392400\n",
       "392401    392401\n",
       "392402    392402\n",
       "392403    392403\n",
       "392404    392404\n",
       "392405    392405\n",
       "392406    392406\n",
       "392407    392407\n",
       "392408    392408\n",
       "392409    392409\n",
       "392410    392410\n",
       "392411    392411\n",
       "392412    392412\n",
       "392413    392413\n",
       "392414    392414\n",
       "392415    392415\n",
       "392416    392416\n",
       "392417    392417\n",
       "Name: id, Length: 392418, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ini.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.delete(arr, [0,89,90,91,92], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4],\n",
       "       [ 6,  7,  8],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(arr, 0, 1) #np.delete(arr, 0, 1(0:row,1:col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nearest Neighbors\n",
    "http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1],\n",
       "       [1, 2, 3],\n",
       "       [2, 1, 3],\n",
       "       [3, 2, 1],\n",
       "       [4, 5, 6],\n",
       "       [5, 4, 6],\n",
       "       [6, 5, 4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.neighbors import NearestNeighbors\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[-4, 4],[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    ">>> nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(X)\n",
    ">>> distances, indices = nbrs.kneighbors(X)\n",
    ">>> indices                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  5.38516481,  5.83095189],\n",
       "       [ 0.        ,  1.        ,  2.23606798],\n",
       "       [ 0.        ,  1.        ,  1.41421356],\n",
       "       [ 0.        ,  1.41421356,  2.23606798],\n",
       "       [ 0.        ,  1.        ,  2.23606798],\n",
       "       [ 0.        ,  1.        ,  1.41421356],\n",
       "       [ 0.        ,  1.41421356,  2.23606798]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs.kneighbors_graph(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQDKEHQCS+T8wRtDdAQnAuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa027e87a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X[:,0], X[:,1], 'ro')\n",
    "plt.axis([-5, 5, -5, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1],\n",
       "       [1, 2, 3],\n",
       "       [2, 1, 3],\n",
       "       [3, 2, 1],\n",
       "       [4, 5, 6],\n",
       "       [5, 4, 6],\n",
       "       [6, 5, 4]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.neighbors import KDTree\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[-4, 4],[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    ">>> kdt = KDTree(X, leaf_size=30, metric='euclidean')\n",
    ">>> kdt.query(X, k=3, return_distance=False)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN預測+畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    ">>> y = np.array([1, 1, 1, 2, 2, 3])\n",
    ">>> clf = NearestCentroid()\n",
    ">>> clf.fit(X, y)\n",
    ">>> print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1],\n",
       "       [-2, -1],\n",
       "       [-3, -2],\n",
       "       [ 1,  1],\n",
       "       [ 2,  1],\n",
       "       [ 3,  2]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1.0\n",
      "0.2 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa027124208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa02b1892e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h=0.01\n",
    "for shrinkage in [None, .2]:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = NearestCentroid(shrink_threshold=shrinkage)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    print(shrinkage, np.mean(y == y_pred))\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='b', s=20)\n",
    "    plt.title(\"3-Class classification (shrink_threshold=%r)\"\n",
    "              % shrinkage)\n",
    "    plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改原本model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "data = np.random.random((N, 7))\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "points = data[:,2:4]\n",
    "# color is the length of each vector in `points`\n",
    "color = np.sqrt((points**2).sum(axis = 1))/np.sqrt(2.0)\n",
    "rgb = plt.get_cmap('jet')(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " X=[[0,3,4,0,1,1],\n",
    "    [0,0,0,5,1,1],\n",
    "    [6,7,0,8,1,1],\n",
    "    [3,6,1,5,6,1]]\n",
    "\n",
    "Y=[12,15,11,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC12SCmGhS1IhLHRJKoSFLkmF+P/Z/4c8H2NkFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa02b90e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_arr = np.array(X)\n",
    "y = np.array(Y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors=list('bgrcmykw')\n",
    "\n",
    "for i, x in enumerate(x_arr.T):\n",
    "    ax.scatter(x,y, c=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0H3+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa02b217518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1,2,3,4], [1,4,9,16], 'ro')\n",
    "plt.axis([0, 6, 0, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6483 samples, validate on 4322 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.6244 - acc: 0.5049 - val_loss: 2.6343 - val_acc: 0.4958\n",
      "Epoch 2/10\n",
      "0s - loss: 2.5648 - acc: 0.5285 - val_loss: 2.6101 - val_acc: 0.4963\n",
      "Epoch 3/10\n",
      "0s - loss: 2.5026 - acc: 0.5556 - val_loss: 2.6280 - val_acc: 0.5217\n",
      "Epoch 4/10\n",
      "0s - loss: 2.4134 - acc: 0.5828 - val_loss: 2.6595 - val_acc: 0.5303\n",
      "Epoch 5/10\n",
      "0s - loss: 2.3376 - acc: 0.5979 - val_loss: 2.6938 - val_acc: 0.5308\n",
      "Epoch 6/10\n",
      "0s - loss: 2.2918 - acc: 0.6003 - val_loss: 2.6906 - val_acc: 0.5310\n",
      "Epoch 7/10\n",
      "0s - loss: 2.2450 - acc: 0.6128 - val_loss: 2.6589 - val_acc: 0.5456\n",
      "Epoch 8/10\n",
      "0s - loss: 2.2063 - acc: 0.6281 - val_loss: 2.6991 - val_acc: 0.5444\n",
      "Epoch 9/10\n",
      "0s - loss: 2.1411 - acc: 0.6377 - val_loss: 2.7309 - val_acc: 0.5386\n",
      "Epoch 10/10\n",
      "0s - loss: 2.1034 - acc: 0.6437 - val_loss: 2.7804 - val_acc: 0.5382\n",
      "6336/7106 [=========================>....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2035 samples, validate on 1357 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.6259 - acc: 0.5263 - val_loss: 2.5909 - val_acc: 0.5188\n",
      "Epoch 2/10\n",
      "0s - loss: 2.5978 - acc: 0.5558 - val_loss: 2.5809 - val_acc: 0.5203\n",
      "Epoch 3/10\n",
      "0s - loss: 2.5726 - acc: 0.5523 - val_loss: 2.5724 - val_acc: 0.5254\n",
      "Epoch 4/10\n",
      "0s - loss: 2.5518 - acc: 0.5494 - val_loss: 2.5604 - val_acc: 0.5313\n",
      "Epoch 5/10\n",
      "0s - loss: 2.5172 - acc: 0.5735 - val_loss: 2.5463 - val_acc: 0.5490\n",
      "Epoch 6/10\n",
      "0s - loss: 2.4748 - acc: 0.5892 - val_loss: 2.5354 - val_acc: 0.5461\n",
      "Epoch 7/10\n",
      "0s - loss: 2.4187 - acc: 0.6015 - val_loss: 2.5288 - val_acc: 0.5483\n",
      "Epoch 8/10\n",
      "0s - loss: 2.4041 - acc: 0.6074 - val_loss: 2.5284 - val_acc: 0.5483\n",
      "Epoch 9/10\n",
      "0s - loss: 2.3491 - acc: 0.6192 - val_loss: 2.5336 - val_acc: 0.5380\n",
      "Epoch 10/10\n",
      "0s - loss: 2.2988 - acc: 0.6216 - val_loss: 2.5526 - val_acc: 0.5556\n",
      "  32/2166 [..............................] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5589 samples, validate on 3726 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.4143 - acc: 0.5203 - val_loss: 3.2829 - val_acc: 0.5641\n",
      "Epoch 2/10\n",
      "0s - loss: 3.3177 - acc: 0.5346 - val_loss: 3.2792 - val_acc: 0.5424\n",
      "Epoch 3/10\n",
      "0s - loss: 3.2375 - acc: 0.5565 - val_loss: 3.2342 - val_acc: 0.5633\n",
      "Epoch 4/10\n",
      "0s - loss: 3.1438 - acc: 0.5690 - val_loss: 3.2742 - val_acc: 0.5550\n",
      "Epoch 5/10\n",
      "0s - loss: 3.0594 - acc: 0.5919 - val_loss: 3.2651 - val_acc: 0.5655\n",
      "Epoch 6/10\n",
      "0s - loss: 3.0044 - acc: 0.6046 - val_loss: 3.3458 - val_acc: 0.5746\n",
      "Epoch 7/10\n",
      "0s - loss: 2.9397 - acc: 0.6162 - val_loss: 3.3148 - val_acc: 0.5682\n",
      "Epoch 8/10\n",
      "0s - loss: 2.8926 - acc: 0.6159 - val_loss: 3.3945 - val_acc: 0.5682\n",
      "Epoch 9/10\n",
      "0s - loss: 2.8514 - acc: 0.6282 - val_loss: 3.4137 - val_acc: 0.5655\n",
      "Epoch 10/10\n",
      "0s - loss: 2.8078 - acc: 0.6336 - val_loss: 3.4998 - val_acc: 0.5725\n",
      "6176/6744 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 8120 samples, validate on 5414 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.7999 - acc: 0.5413 - val_loss: 2.6661 - val_acc: 0.5028\n",
      "Epoch 2/10\n",
      "0s - loss: 2.7041 - acc: 0.5743 - val_loss: 2.7692 - val_acc: 0.4891\n",
      "Epoch 3/10\n",
      "0s - loss: 2.6217 - acc: 0.5900 - val_loss: 2.7700 - val_acc: 0.4932\n",
      "Epoch 4/10\n",
      "0s - loss: 2.5557 - acc: 0.5998 - val_loss: 2.8290 - val_acc: 0.4946\n",
      "Epoch 5/10\n",
      "0s - loss: 2.4892 - acc: 0.6105 - val_loss: 2.8810 - val_acc: 0.4989\n",
      "Epoch 6/10\n",
      "0s - loss: 2.4597 - acc: 0.6106 - val_loss: 2.9080 - val_acc: 0.5031\n",
      "Epoch 7/10\n",
      "0s - loss: 2.4049 - acc: 0.6201 - val_loss: 2.9351 - val_acc: 0.5035\n",
      "Epoch 8/10\n",
      "0s - loss: 2.3642 - acc: 0.6245 - val_loss: 2.9452 - val_acc: 0.5100\n",
      "Epoch 9/10\n",
      "0s - loss: 2.3289 - acc: 0.6326 - val_loss: 3.0465 - val_acc: 0.4946\n",
      "Epoch 10/10\n",
      "0s - loss: 2.2952 - acc: 0.6336 - val_loss: 3.0998 - val_acc: 0.4939\n",
      "7648/9447 [=======================>......] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5755 samples, validate on 3838 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.0104 - acc: 0.5406 - val_loss: 2.8882 - val_acc: 0.4958\n",
      "Epoch 2/10\n",
      "0s - loss: 2.9547 - acc: 0.5578 - val_loss: 2.8535 - val_acc: 0.5146\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8792 - acc: 0.5812 - val_loss: 2.8756 - val_acc: 0.5375\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7999 - acc: 0.5852 - val_loss: 2.9358 - val_acc: 0.5135\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7312 - acc: 0.5998 - val_loss: 2.9801 - val_acc: 0.5143\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6815 - acc: 0.6075 - val_loss: 2.8814 - val_acc: 0.5443\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6342 - acc: 0.6189 - val_loss: 2.9688 - val_acc: 0.5193\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6071 - acc: 0.6202 - val_loss: 2.9380 - val_acc: 0.5472\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5677 - acc: 0.6264 - val_loss: 3.0076 - val_acc: 0.5331\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5104 - acc: 0.6377 - val_loss: 2.9693 - val_acc: 0.5367\n",
      "3680/6176 [================>.............] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 16032 samples, validate on 10688 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 2.9568 - acc: 0.5504 - val_loss: 2.9255 - val_acc: 0.5687\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8565 - acc: 0.5757 - val_loss: 2.9164 - val_acc: 0.5568\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8000 - acc: 0.5869 - val_loss: 2.8708 - val_acc: 0.5651\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7522 - acc: 0.5907 - val_loss: 2.8375 - val_acc: 0.5814\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7127 - acc: 0.5987 - val_loss: 2.8278 - val_acc: 0.5874\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6747 - acc: 0.6067 - val_loss: 2.7979 - val_acc: 0.5922\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6399 - acc: 0.6136 - val_loss: 2.7818 - val_acc: 0.5930\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6070 - acc: 0.6145 - val_loss: 2.7700 - val_acc: 0.5950\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5793 - acc: 0.6216 - val_loss: 2.7973 - val_acc: 0.5924\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5446 - acc: 0.6238 - val_loss: 2.7948 - val_acc: 0.5967\n",
      "15072/18424 [=======================>......] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 12944 samples, validate on 8630 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9161 - acc: 0.5629 - val_loss: 3.1179 - val_acc: 0.5353\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8234 - acc: 0.5746 - val_loss: 3.2423 - val_acc: 0.5171\n",
      "Epoch 3/10\n",
      "0s - loss: 2.7513 - acc: 0.5866 - val_loss: 3.1885 - val_acc: 0.5301\n",
      "Epoch 4/10\n",
      "0s - loss: 2.6950 - acc: 0.5965 - val_loss: 3.2606 - val_acc: 0.5190\n",
      "Epoch 5/10\n",
      "0s - loss: 2.6341 - acc: 0.6167 - val_loss: 3.2398 - val_acc: 0.5140\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6028 - acc: 0.6158 - val_loss: 3.3752 - val_acc: 0.5276\n",
      "Epoch 7/10\n",
      "0s - loss: 2.5663 - acc: 0.6199 - val_loss: 3.4203 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "0s - loss: 2.5262 - acc: 0.6279 - val_loss: 3.4623 - val_acc: 0.5316\n",
      "Epoch 9/10\n",
      "0s - loss: 2.4880 - acc: 0.6299 - val_loss: 3.4730 - val_acc: 0.5205\n",
      "Epoch 10/10\n",
      "0s - loss: 2.4681 - acc: 0.6343 - val_loss: 3.5459 - val_acc: 0.5191\n",
      "14016/16741 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6385 samples, validate on 4258 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.7943 - acc: 0.5195 - val_loss: 2.7534 - val_acc: 0.5648\n",
      "Epoch 2/10\n",
      "0s - loss: 2.7546 - acc: 0.5591 - val_loss: 2.7474 - val_acc: 0.5496\n",
      "Epoch 3/10\n",
      "0s - loss: 2.7020 - acc: 0.5624 - val_loss: 2.7462 - val_acc: 0.5402\n",
      "Epoch 4/10\n",
      "0s - loss: 2.6603 - acc: 0.5765 - val_loss: 2.7484 - val_acc: 0.5524\n",
      "Epoch 5/10\n",
      "0s - loss: 2.6175 - acc: 0.5854 - val_loss: 2.7402 - val_acc: 0.5580\n",
      "Epoch 6/10\n",
      "0s - loss: 2.5778 - acc: 0.5878 - val_loss: 2.7298 - val_acc: 0.5660\n",
      "Epoch 7/10\n",
      "0s - loss: 2.5265 - acc: 0.5972 - val_loss: 2.7197 - val_acc: 0.5698\n",
      "Epoch 8/10\n",
      "0s - loss: 2.4979 - acc: 0.6034 - val_loss: 2.6799 - val_acc: 0.5676\n",
      "Epoch 9/10\n",
      "0s - loss: 2.4688 - acc: 0.6085 - val_loss: 2.6928 - val_acc: 0.5721\n",
      "Epoch 10/10\n",
      "0s - loss: 2.4292 - acc: 0.6117 - val_loss: 2.7181 - val_acc: 0.5740\n",
      "3584/6603 [===============>..............] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2658 samples, validate on 1772 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.3004 - acc: 0.5038 - val_loss: 3.1919 - val_acc: 0.5169\n",
      "Epoch 2/10\n",
      "0s - loss: 3.2209 - acc: 0.5508 - val_loss: 3.1897 - val_acc: 0.5237\n",
      "Epoch 3/10\n",
      "0s - loss: 3.1723 - acc: 0.5557 - val_loss: 3.1931 - val_acc: 0.5237\n",
      "Epoch 4/10\n",
      "0s - loss: 3.1009 - acc: 0.5899 - val_loss: 3.1610 - val_acc: 0.5231\n",
      "Epoch 5/10\n",
      "0s - loss: 3.0252 - acc: 0.6035 - val_loss: 3.1927 - val_acc: 0.5339\n",
      "Epoch 6/10\n",
      "0s - loss: 2.9367 - acc: 0.6166 - val_loss: 3.1458 - val_acc: 0.5429\n",
      "Epoch 7/10\n",
      "0s - loss: 2.8287 - acc: 0.6351 - val_loss: 3.1417 - val_acc: 0.5468\n",
      "Epoch 8/10\n",
      "0s - loss: 2.7399 - acc: 0.6351 - val_loss: 3.1007 - val_acc: 0.5429\n",
      "Epoch 9/10\n",
      "0s - loss: 2.6510 - acc: 0.6426 - val_loss: 3.1693 - val_acc: 0.5463\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5543 - acc: 0.6606 - val_loss: 3.1803 - val_acc: 0.5559\n",
      "  32/3153 [..............................] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3417 samples, validate on 2279 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9124 - acc: 0.5429 - val_loss: 2.9737 - val_acc: 0.5283\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8756 - acc: 0.5525 - val_loss: 2.9568 - val_acc: 0.5410\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8364 - acc: 0.5645 - val_loss: 2.9632 - val_acc: 0.5401\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7843 - acc: 0.5733 - val_loss: 2.9231 - val_acc: 0.5511\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7391 - acc: 0.5859 - val_loss: 2.9187 - val_acc: 0.5568\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6890 - acc: 0.5941 - val_loss: 2.8956 - val_acc: 0.5577\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6444 - acc: 0.6017 - val_loss: 2.8819 - val_acc: 0.5652\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6044 - acc: 0.6099 - val_loss: 3.0004 - val_acc: 0.5485\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5718 - acc: 0.6111 - val_loss: 2.8984 - val_acc: 0.5647\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5132 - acc: 0.6225 - val_loss: 2.9397 - val_acc: 0.5687\n",
      "3648/4014 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4499 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9239 - acc: 0.5299 - val_loss: 2.9452 - val_acc: 0.5480\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 2.8854 - acc: 0.5523 - val_loss: 2.9333 - val_acc: 0.5713\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8206 - acc: 0.5757 - val_loss: 2.8928 - val_acc: 0.5877\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7678 - acc: 0.5832 - val_loss: 2.9136 - val_acc: 0.5793\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7058 - acc: 0.5928 - val_loss: 2.9219 - val_acc: 0.5880\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6734 - acc: 0.6017 - val_loss: 2.9369 - val_acc: 0.5803\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6191 - acc: 0.6088 - val_loss: 2.9040 - val_acc: 0.5930\n",
      "Epoch 8/10\n",
      "0s - loss: 2.5867 - acc: 0.6175 - val_loss: 2.8899 - val_acc: 0.5903\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5204 - acc: 0.6208 - val_loss: 2.8547 - val_acc: 0.5980\n",
      "Epoch 10/10\n",
      "0s - loss: 2.4917 - acc: 0.6199 - val_loss: 2.9514 - val_acc: 0.5907\n",
      "3552/4620 [======================>.......] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4870 samples, validate on 3247 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9720 - acc: 0.5259 - val_loss: 2.7200 - val_acc: 0.5152\n",
      "Epoch 2/10\n",
      "0s - loss: 2.9291 - acc: 0.5480 - val_loss: 2.6990 - val_acc: 0.5350\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8784 - acc: 0.5565 - val_loss: 2.6817 - val_acc: 0.5380\n",
      "Epoch 4/10\n",
      "0s - loss: 2.8320 - acc: 0.5780 - val_loss: 2.6916 - val_acc: 0.5491\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7829 - acc: 0.5975 - val_loss: 2.6734 - val_acc: 0.5476\n",
      "Epoch 6/10\n",
      "0s - loss: 2.7391 - acc: 0.5924 - val_loss: 2.6912 - val_acc: 0.5577\n",
      "Epoch 7/10\n",
      "0s - loss: 2.7081 - acc: 0.5984 - val_loss: 2.6735 - val_acc: 0.5682\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6723 - acc: 0.6086 - val_loss: 2.6809 - val_acc: 0.5624\n",
      "Epoch 9/10\n",
      "0s - loss: 2.6329 - acc: 0.6127 - val_loss: 2.6985 - val_acc: 0.5611\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5894 - acc: 0.6228 - val_loss: 2.7100 - val_acc: 0.5661\n",
      "3392/6801 [=============>................] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 10183 samples, validate on 6790 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9868 - acc: 0.5233 - val_loss: 2.8293 - val_acc: 0.5280\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8430 - acc: 0.5740 - val_loss: 2.7373 - val_acc: 0.5582\n",
      "Epoch 3/10\n",
      "0s - loss: 2.6999 - acc: 0.6003 - val_loss: 2.7424 - val_acc: 0.5592\n",
      "Epoch 4/10\n",
      "0s - loss: 2.6139 - acc: 0.6188 - val_loss: 2.7587 - val_acc: 0.5763\n",
      "Epoch 5/10\n",
      "0s - loss: 2.5549 - acc: 0.6242 - val_loss: 2.7802 - val_acc: 0.5708\n",
      "Epoch 6/10\n",
      "0s - loss: 2.4963 - acc: 0.6347 - val_loss: 2.8453 - val_acc: 0.5610\n",
      "Epoch 7/10\n",
      "0s - loss: 2.4598 - acc: 0.6372 - val_loss: 2.7464 - val_acc: 0.5698\n",
      "Epoch 8/10\n",
      "0s - loss: 2.4036 - acc: 0.6434 - val_loss: 2.7958 - val_acc: 0.5673\n",
      "Epoch 9/10\n",
      "0s - loss: 2.3810 - acc: 0.6491 - val_loss: 2.8653 - val_acc: 0.5619\n",
      "Epoch 10/10\n",
      "0s - loss: 2.3450 - acc: 0.6549 - val_loss: 2.8713 - val_acc: 0.5607\n",
      "6944/9572 [====================>.........] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6411 samples, validate on 4275 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.8286 - acc: 0.5291 - val_loss: 2.8994 - val_acc: 0.5296\n",
      "Epoch 2/10\n",
      "0s - loss: 2.7139 - acc: 0.5746 - val_loss: 2.8753 - val_acc: 0.5572\n",
      "Epoch 3/10\n",
      "0s - loss: 2.6213 - acc: 0.5884 - val_loss: 2.8568 - val_acc: 0.5469\n",
      "Epoch 4/10\n",
      "0s - loss: 2.5787 - acc: 0.5912 - val_loss: 2.8265 - val_acc: 0.5593\n",
      "Epoch 5/10\n",
      "0s - loss: 2.5297 - acc: 0.5985 - val_loss: 2.8230 - val_acc: 0.5621\n",
      "Epoch 6/10\n",
      "0s - loss: 2.4863 - acc: 0.6104 - val_loss: 2.8206 - val_acc: 0.5691\n",
      "Epoch 7/10\n",
      "0s - loss: 2.4360 - acc: 0.6141 - val_loss: 2.8755 - val_acc: 0.5579\n",
      "Epoch 8/10\n",
      "0s - loss: 2.4167 - acc: 0.6225 - val_loss: 2.8014 - val_acc: 0.5766\n",
      "Epoch 9/10\n",
      "0s - loss: 2.3676 - acc: 0.6281 - val_loss: 2.8712 - val_acc: 0.5754\n",
      "Epoch 10/10\n",
      "0s - loss: 2.3636 - acc: 0.6378 - val_loss: 2.8002 - val_acc: 0.5890\n",
      "6592/7064 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14363 samples, validate on 9576 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.0034 - acc: 0.5491 - val_loss: 3.0679 - val_acc: 0.5661\n",
      "Epoch 2/10\n",
      "0s - loss: 2.9220 - acc: 0.5691 - val_loss: 3.0299 - val_acc: 0.5680\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8663 - acc: 0.5829 - val_loss: 3.0125 - val_acc: 0.5783\n",
      "Epoch 4/10\n",
      "0s - loss: 2.8205 - acc: 0.5928 - val_loss: 2.9941 - val_acc: 0.5850\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7750 - acc: 0.6029 - val_loss: 3.0085 - val_acc: 0.5850\n",
      "Epoch 6/10\n",
      "0s - loss: 2.7388 - acc: 0.6089 - val_loss: 2.9999 - val_acc: 0.5864\n",
      "Epoch 7/10\n",
      "0s - loss: 2.7027 - acc: 0.6171 - val_loss: 3.0155 - val_acc: 0.5914\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6654 - acc: 0.6190 - val_loss: 3.0099 - val_acc: 0.5970\n",
      "Epoch 9/10\n",
      "0s - loss: 2.6432 - acc: 0.6248 - val_loss: 3.1286 - val_acc: 0.5830\n",
      "Epoch 10/10\n",
      "0s - loss: 2.6184 - acc: 0.6286 - val_loss: 3.0431 - val_acc: 0.5847\n",
      "16704/18878 [=========================>....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7167 samples, validate on 4778 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9640 - acc: 0.5352 - val_loss: 2.9318 - val_acc: 0.5345\n",
      "Epoch 2/10\n",
      "0s - loss: 2.9171 - acc: 0.5504 - val_loss: 2.8976 - val_acc: 0.5653\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 2.8522 - acc: 0.5687 - val_loss: 2.8740 - val_acc: 0.5682\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7871 - acc: 0.5828 - val_loss: 2.8789 - val_acc: 0.5770\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7400 - acc: 0.5859 - val_loss: 2.8881 - val_acc: 0.5674\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6863 - acc: 0.5952 - val_loss: 2.8528 - val_acc: 0.5789\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6596 - acc: 0.6019 - val_loss: 2.8299 - val_acc: 0.5835\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6063 - acc: 0.6106 - val_loss: 2.8662 - val_acc: 0.5726\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5900 - acc: 0.6152 - val_loss: 2.8640 - val_acc: 0.5774\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5400 - acc: 0.6189 - val_loss: 2.8306 - val_acc: 0.5751\n",
      "7360/9094 [=======================>......] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 9610 samples, validate on 6408 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.2796 - acc: 0.5642 - val_loss: 3.4639 - val_acc: 0.5432\n",
      "Epoch 2/10\n",
      "0s - loss: 3.1396 - acc: 0.5883 - val_loss: 3.4692 - val_acc: 0.5428\n",
      "Epoch 3/10\n",
      "0s - loss: 3.0765 - acc: 0.5954 - val_loss: 3.4662 - val_acc: 0.5532\n",
      "Epoch 4/10\n",
      "0s - loss: 3.0147 - acc: 0.6057 - val_loss: 3.4910 - val_acc: 0.5534\n",
      "Epoch 5/10\n",
      "0s - loss: 2.9625 - acc: 0.6152 - val_loss: 3.4468 - val_acc: 0.5630\n",
      "Epoch 6/10\n",
      "0s - loss: 2.9062 - acc: 0.6238 - val_loss: 3.5149 - val_acc: 0.5581\n",
      "Epoch 7/10\n",
      "0s - loss: 2.8644 - acc: 0.6261 - val_loss: 3.4578 - val_acc: 0.5693\n",
      "Epoch 8/10\n",
      "0s - loss: 2.8211 - acc: 0.6311 - val_loss: 3.4899 - val_acc: 0.5694\n",
      "Epoch 9/10\n",
      "0s - loss: 2.7745 - acc: 0.6399 - val_loss: 3.4806 - val_acc: 0.5629\n",
      "Epoch 10/10\n",
      "0s - loss: 2.7432 - acc: 0.6430 - val_loss: 3.5476 - val_acc: 0.5624\n",
      "10208/11326 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 9615 samples, validate on 6411 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.0235 - acc: 0.5296 - val_loss: 3.0431 - val_acc: 0.5406\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8895 - acc: 0.5777 - val_loss: 3.2168 - val_acc: 0.5016\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8125 - acc: 0.5902 - val_loss: 3.1295 - val_acc: 0.5193\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7542 - acc: 0.6016 - val_loss: 3.1496 - val_acc: 0.5213\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7023 - acc: 0.6148 - val_loss: 3.1313 - val_acc: 0.5286\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6546 - acc: 0.6166 - val_loss: 3.2283 - val_acc: 0.5191\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6177 - acc: 0.6246 - val_loss: 3.1810 - val_acc: 0.5328\n",
      "Epoch 8/10\n",
      "0s - loss: 2.5841 - acc: 0.6288 - val_loss: 3.1418 - val_acc: 0.5338\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5526 - acc: 0.6306 - val_loss: 3.1903 - val_acc: 0.5275\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5047 - acc: 0.6451 - val_loss: 3.1517 - val_acc: 0.5447\n",
      " 9632/11260 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4695 samples, validate on 3130 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.8339 - acc: 0.5263 - val_loss: 2.8657 - val_acc: 0.5505\n",
      "Epoch 2/10\n",
      "0s - loss: 2.7911 - acc: 0.5474 - val_loss: 2.8479 - val_acc: 0.5530\n",
      "Epoch 3/10\n",
      "0s - loss: 2.7574 - acc: 0.5636 - val_loss: 2.8518 - val_acc: 0.5518\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7289 - acc: 0.5717 - val_loss: 2.8228 - val_acc: 0.5623\n",
      "Epoch 5/10\n",
      "0s - loss: 2.6841 - acc: 0.5783 - val_loss: 2.8173 - val_acc: 0.5524\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6556 - acc: 0.5823 - val_loss: 2.7823 - val_acc: 0.5613\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6092 - acc: 0.5951 - val_loss: 2.7870 - val_acc: 0.5597\n",
      "Epoch 8/10\n",
      "0s - loss: 2.5827 - acc: 0.5932 - val_loss: 2.7770 - val_acc: 0.5661\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5320 - acc: 0.6019 - val_loss: 2.7683 - val_acc: 0.5712\n",
      "Epoch 10/10\n",
      "0s - loss: 2.4940 - acc: 0.6143 - val_loss: 2.7626 - val_acc: 0.5725\n",
      "3424/5440 [=================>............] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3047 samples, validate on 2032 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9271 - acc: 0.5212 - val_loss: 2.9919 - val_acc: 0.5202\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8849 - acc: 0.5409 - val_loss: 2.9765 - val_acc: 0.5404\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8478 - acc: 0.5530 - val_loss: 2.9646 - val_acc: 0.5522\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7936 - acc: 0.5609 - val_loss: 2.9362 - val_acc: 0.5507\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7396 - acc: 0.5743 - val_loss: 2.9364 - val_acc: 0.5477\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6855 - acc: 0.5783 - val_loss: 2.9320 - val_acc: 0.5605\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6412 - acc: 0.5832 - val_loss: 2.9915 - val_acc: 0.5674\n",
      "Epoch 8/10\n",
      "0s - loss: 2.5944 - acc: 0.5944 - val_loss: 2.9537 - val_acc: 0.5753\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5389 - acc: 0.6091 - val_loss: 2.9835 - val_acc: 0.5655\n",
      "Epoch 10/10\n",
      "0s - loss: 2.4909 - acc: 0.6068 - val_loss: 2.9751 - val_acc: 0.5792\n",
      "2176/3228 [===================>..........] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 8511 samples, validate on 5675 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.3992 - acc: 0.5607 - val_loss: 3.5255 - val_acc: 0.5332\n",
      "Epoch 2/10\n",
      "0s - loss: 3.2687 - acc: 0.5811 - val_loss: 3.5879 - val_acc: 0.5348\n",
      "Epoch 3/10\n",
      "0s - loss: 3.1892 - acc: 0.5989 - val_loss: 3.4625 - val_acc: 0.5596\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 3.1102 - acc: 0.6110 - val_loss: 3.4559 - val_acc: 0.5690\n",
      "Epoch 5/10\n",
      "0s - loss: 3.0343 - acc: 0.6176 - val_loss: 3.5077 - val_acc: 0.5709\n",
      "Epoch 6/10\n",
      "0s - loss: 2.9726 - acc: 0.6264 - val_loss: 3.6041 - val_acc: 0.5496\n",
      "Epoch 7/10\n",
      "0s - loss: 2.9003 - acc: 0.6398 - val_loss: 3.4736 - val_acc: 0.5700\n",
      "Epoch 8/10\n",
      "0s - loss: 2.8795 - acc: 0.6450 - val_loss: 3.5222 - val_acc: 0.5797\n",
      "Epoch 9/10\n",
      "0s - loss: 2.8159 - acc: 0.6477 - val_loss: 3.5412 - val_acc: 0.5730\n",
      "Epoch 10/10\n",
      "0s - loss: 2.7939 - acc: 0.6475 - val_loss: 3.5162 - val_acc: 0.5706\n",
      " 9632/11309 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5311 samples, validate on 3541 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9441 - acc: 0.5297 - val_loss: 2.9625 - val_acc: 0.5143\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8964 - acc: 0.5385 - val_loss: 2.9739 - val_acc: 0.5120\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8475 - acc: 0.5592 - val_loss: 2.9500 - val_acc: 0.5352\n",
      "Epoch 4/10\n",
      "0s - loss: 2.7966 - acc: 0.5786 - val_loss: 2.9593 - val_acc: 0.5383\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7456 - acc: 0.5895 - val_loss: 3.0120 - val_acc: 0.5445\n",
      "Epoch 6/10\n",
      "0s - loss: 2.7131 - acc: 0.5946 - val_loss: 3.0109 - val_acc: 0.5467\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6735 - acc: 0.6005 - val_loss: 3.0800 - val_acc: 0.5417\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6377 - acc: 0.6076 - val_loss: 3.0401 - val_acc: 0.5414\n",
      "Epoch 9/10\n",
      "0s - loss: 2.6101 - acc: 0.6085 - val_loss: 3.0817 - val_acc: 0.5504\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5671 - acc: 0.6116 - val_loss: 3.1032 - val_acc: 0.5450\n",
      "6656/6770 [============================>.] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4528 samples, validate on 3020 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 3.2090 - acc: 0.5417 - val_loss: 3.2772 - val_acc: 0.5550\n",
      "Epoch 2/10\n",
      "0s - loss: 3.1629 - acc: 0.5523 - val_loss: 3.2506 - val_acc: 0.5669\n",
      "Epoch 3/10\n",
      "0s - loss: 3.1022 - acc: 0.5707 - val_loss: 3.2547 - val_acc: 0.5715\n",
      "Epoch 4/10\n",
      "0s - loss: 3.0522 - acc: 0.5784 - val_loss: 3.2309 - val_acc: 0.5748\n",
      "Epoch 5/10\n",
      "0s - loss: 3.0054 - acc: 0.5817 - val_loss: 3.2178 - val_acc: 0.5613\n",
      "Epoch 6/10\n",
      "0s - loss: 2.9682 - acc: 0.5877 - val_loss: 3.1797 - val_acc: 0.5755\n",
      "Epoch 7/10\n",
      "0s - loss: 2.9162 - acc: 0.6034 - val_loss: 3.2215 - val_acc: 0.5728\n",
      "Epoch 8/10\n",
      "0s - loss: 2.8967 - acc: 0.6005 - val_loss: 3.2581 - val_acc: 0.5715\n",
      "Epoch 9/10\n",
      "0s - loss: 2.8441 - acc: 0.6089 - val_loss: 3.1857 - val_acc: 0.5719\n",
      "Epoch 10/10\n",
      "0s - loss: 2.8103 - acc: 0.6175 - val_loss: 3.2041 - val_acc: 0.5828\n",
      "3328/4715 [====================>.........] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3899 samples, validate on 2600 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.7153 - acc: 0.5389 - val_loss: 2.8807 - val_acc: 0.4769\n",
      "Epoch 2/10\n",
      "0s - loss: 2.6377 - acc: 0.5663 - val_loss: 2.8927 - val_acc: 0.5196\n",
      "Epoch 3/10\n",
      "0s - loss: 2.5510 - acc: 0.5791 - val_loss: 2.8868 - val_acc: 0.5354\n",
      "Epoch 4/10\n",
      "0s - loss: 2.4612 - acc: 0.5912 - val_loss: 3.0843 - val_acc: 0.5285\n",
      "Epoch 5/10\n",
      "0s - loss: 2.3908 - acc: 0.6025 - val_loss: 3.1441 - val_acc: 0.5346\n",
      "Epoch 6/10\n",
      "0s - loss: 2.3179 - acc: 0.6232 - val_loss: 3.1215 - val_acc: 0.5485\n",
      "Epoch 7/10\n",
      "0s - loss: 2.2592 - acc: 0.6420 - val_loss: 3.0403 - val_acc: 0.5427\n",
      "Epoch 8/10\n",
      "0s - loss: 2.1957 - acc: 0.6479 - val_loss: 3.2087 - val_acc: 0.5435\n",
      "Epoch 9/10\n",
      "0s - loss: 2.1302 - acc: 0.6650 - val_loss: 3.3211 - val_acc: 0.5438\n",
      "Epoch 10/10\n",
      "0s - loss: 2.0745 - acc: 0.6745 - val_loss: 3.2949 - val_acc: 0.5431\n",
      "3200/4166 [======================>.......] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2480 samples, validate on 1654 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.4005 - acc: 0.5468 - val_loss: 2.3824 - val_acc: 0.5133\n",
      "Epoch 2/10\n",
      "0s - loss: 2.3578 - acc: 0.5548 - val_loss: 2.4189 - val_acc: 0.4994\n",
      "Epoch 3/10\n",
      "0s - loss: 2.3001 - acc: 0.5746 - val_loss: 2.4046 - val_acc: 0.5381\n",
      "Epoch 4/10\n",
      "0s - loss: 2.2389 - acc: 0.5919 - val_loss: 2.4120 - val_acc: 0.5429\n",
      "Epoch 5/10\n",
      "0s - loss: 2.1903 - acc: 0.5948 - val_loss: 2.4478 - val_acc: 0.5393\n",
      "Epoch 6/10\n",
      "0s - loss: 2.1384 - acc: 0.6089 - val_loss: 2.4536 - val_acc: 0.5478\n",
      "Epoch 7/10\n",
      "0s - loss: 2.0815 - acc: 0.6048 - val_loss: 2.4814 - val_acc: 0.5441\n",
      "Epoch 8/10\n",
      "0s - loss: 2.0514 - acc: 0.6210 - val_loss: 2.5106 - val_acc: 0.5466\n",
      "Epoch 9/10\n",
      "0s - loss: 1.9905 - acc: 0.6302 - val_loss: 2.5720 - val_acc: 0.5393\n",
      "Epoch 10/10\n",
      "0s - loss: 1.9577 - acc: 0.6298 - val_loss: 2.6092 - val_acc: 0.5484\n",
      "  32/2265 [..............................] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1296 samples, validate on 864 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 1.8734 - acc: 0.5610 - val_loss: 2.0656 - val_acc: 0.5313\n",
      "Epoch 2/10\n",
      "0s - loss: 1.8435 - acc: 0.5802 - val_loss: 2.0700 - val_acc: 0.5255\n",
      "Epoch 3/10\n",
      "0s - loss: 1.8168 - acc: 0.6003 - val_loss: 2.0827 - val_acc: 0.5255\n",
      "Epoch 4/10\n",
      "0s - loss: 1.7686 - acc: 0.6080 - val_loss: 2.0595 - val_acc: 0.5197\n",
      "Epoch 5/10\n",
      "0s - loss: 1.6830 - acc: 0.6165 - val_loss: 2.0890 - val_acc: 0.5162\n",
      "Epoch 6/10\n",
      "0s - loss: 1.6100 - acc: 0.6204 - val_loss: 2.1051 - val_acc: 0.5058\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 1.5284 - acc: 0.6119 - val_loss: 2.1043 - val_acc: 0.5185\n",
      "Epoch 8/10\n",
      "0s - loss: 1.4589 - acc: 0.6474 - val_loss: 2.0678 - val_acc: 0.5324\n",
      "Epoch 9/10\n",
      "0s - loss: 1.3878 - acc: 0.6343 - val_loss: 2.1356 - val_acc: 0.5185\n",
      "Epoch 10/10\n",
      "0s - loss: 1.3316 - acc: 0.6458 - val_loss: 2.1990 - val_acc: 0.5324\n",
      "  32/1620 [..............................] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3116 samples, validate on 2078 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9272 - acc: 0.4939 - val_loss: 3.3596 - val_acc: 0.5241\n",
      "Epoch 2/10\n",
      "0s - loss: 2.8643 - acc: 0.5372 - val_loss: 3.3433 - val_acc: 0.5520\n",
      "Epoch 3/10\n",
      "0s - loss: 2.7750 - acc: 0.6033 - val_loss: 3.3259 - val_acc: 0.5452\n",
      "Epoch 4/10\n",
      "0s - loss: 2.6758 - acc: 0.6306 - val_loss: 3.4075 - val_acc: 0.5486\n",
      "Epoch 5/10\n",
      "0s - loss: 2.6239 - acc: 0.6390 - val_loss: 3.3968 - val_acc: 0.5414\n",
      "Epoch 6/10\n",
      "0s - loss: 2.5539 - acc: 0.6406 - val_loss: 3.4345 - val_acc: 0.5486\n",
      "Epoch 7/10\n",
      "0s - loss: 2.5079 - acc: 0.6512 - val_loss: 3.4095 - val_acc: 0.5510\n",
      "Epoch 8/10\n",
      "0s - loss: 2.4462 - acc: 0.6617 - val_loss: 3.4749 - val_acc: 0.5433\n",
      "Epoch 9/10\n",
      "0s - loss: 2.4105 - acc: 0.6730 - val_loss: 3.4514 - val_acc: 0.5486\n",
      "Epoch 10/10\n",
      "0s - loss: 2.3532 - acc: 0.6752 - val_loss: 3.4219 - val_acc: 0.5597\n",
      "3072/3649 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4633 samples, validate on 3089 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 2.9758 - acc: 0.5236 - val_loss: 2.9180 - val_acc: 0.5254\n",
      "Epoch 2/10\n",
      "0s - loss: 2.9303 - acc: 0.5554 - val_loss: 2.9096 - val_acc: 0.5277\n",
      "Epoch 3/10\n",
      "0s - loss: 2.8798 - acc: 0.5769 - val_loss: 2.9064 - val_acc: 0.5342\n",
      "Epoch 4/10\n",
      "0s - loss: 2.8114 - acc: 0.5722 - val_loss: 2.9334 - val_acc: 0.5325\n",
      "Epoch 5/10\n",
      "0s - loss: 2.7450 - acc: 0.5929 - val_loss: 2.9790 - val_acc: 0.5196\n",
      "Epoch 6/10\n",
      "0s - loss: 2.6990 - acc: 0.5985 - val_loss: 2.9702 - val_acc: 0.5277\n",
      "Epoch 7/10\n",
      "0s - loss: 2.6710 - acc: 0.5990 - val_loss: 2.9988 - val_acc: 0.5257\n",
      "Epoch 8/10\n",
      "0s - loss: 2.6221 - acc: 0.6059 - val_loss: 3.0380 - val_acc: 0.5354\n",
      "Epoch 9/10\n",
      "0s - loss: 2.5967 - acc: 0.6074 - val_loss: 3.0587 - val_acc: 0.5410\n",
      "Epoch 10/10\n",
      "0s - loss: 2.5671 - acc: 0.6180 - val_loss: 3.0754 - val_acc: 0.5299\n",
      "6016/6032 [============================>.] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 50)                4450      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,512\n",
      "Trainable params: 5,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_save=[]\n",
    "for BIGI in range(0,1,1):\n",
    "\n",
    "    #testxx=test_ini.sort_values('group')\n",
    "    #testxx_list = []\n",
    "    for i in range(len(testxx.group.unique())):\n",
    "        testxx_list.append(testxx[testxx['group']==i+1])\n",
    "    test=testxx_list[BIGI]\n",
    "\n",
    "    trainxx=train_ini.sort_values('group')\n",
    "    df_list = []\n",
    "    for i in range(len(trainxx.group.unique())):\n",
    "        df_list.append(trainxx[trainxx['group']==i+1])\n",
    "    train=df_list[BIGI]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=50,input_dim=88,kernel_initializer='normal',activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=20, activation='sigmoid'))\n",
    "    #model.add(Dropout(0.45))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.45))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.45))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.45))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(Dense(50))\n",
    "    \n",
    "    #import functools\n",
    "    #ncce=functools.partial(w_categorical_crossentropy, weights=np.array(train['weight']))\n",
    "\n",
    "    #model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    trainx=train.copy(deep=True)\n",
    "    testx=test.copy(deep=True)\n",
    "    trainx.drop(['id', 'weight', 'label', 'era', 'group'],  axis=1, inplace=True )\n",
    "    testx.drop(['id', 'group'], axis=1, inplace=True)\n",
    "    \n",
    "    x_Train_normalize = trainx.as_matrix()\n",
    "    x_Test_normalize = testx.as_matrix()\n",
    "    y_Train_Onehot_temp=train['label'].as_matrix()\n",
    "    \n",
    "    # Create label used for validation\n",
    "    label_mat=train['label'].as_matrix()\n",
    "    labels = [[1, 0] if label_mat[i] == 0 else [0, 1] for i in range(len(label_mat))]\n",
    "    #labels = [[1, 0] if label_mat[i] == 0 else [0, 1] for i in range(len(label_mat))]\n",
    "    \n",
    "    \n",
    "    #model.add(Dense(units=1,kernel_initializer='normal',activation='softmax'))\n",
    "    model.add(Dense(units=2,kernel_initializer='normal',activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    #model.compile(loss=x_categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    #model.compile(loss='log_loss',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    #model.load_weights(train['weight']);\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_history=model.fit(x=x_Train_normalize,y=labels,validation_split=0.4,sample_weight=np.array(train['weight']), epochs=10, batch_size=40\n",
    "                            , verbose=2)\n",
    "    #train_history=model.fit(x=x_Train_normalize,y=labels,validation_split=0.4, epochs=10, batch_size=200, verbose=2)\n",
    "    prediction=model.predict_classes(x_Test_normalize)\n",
    "    proba=model.predict_proba(x_Test_normalize)[:,1];\n",
    "    #proba=model.predict_proba(x_Test_normalize)[:,0];\n",
    "    \n",
    "    test = test.assign(proba=(pd.Series(proba)).values)\n",
    "    #test = test.sort_values('id');\n",
    "    test.drop(test.columns[1:90],  axis=1, inplace=True )\n",
    "\n",
    "    test_save.append(test)\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc909262908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8d4188f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output and save it\n",
    "\n",
    "result = pd.concat(test_save)\n",
    "result = result.sort_values('id');\n",
    "result.to_csv(\"answer0916.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296104</td>\n",
       "      <td>0.802402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296105</td>\n",
       "      <td>0.668149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296106</td>\n",
       "      <td>0.691602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296107</td>\n",
       "      <td>0.147286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296108</td>\n",
       "      <td>0.511898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>296109</td>\n",
       "      <td>0.798943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>296110</td>\n",
       "      <td>0.909317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>296111</td>\n",
       "      <td>0.489411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>296112</td>\n",
       "      <td>0.280552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>296113</td>\n",
       "      <td>0.800137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>296114</td>\n",
       "      <td>0.239736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>296115</td>\n",
       "      <td>0.697259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>296116</td>\n",
       "      <td>0.411563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>296117</td>\n",
       "      <td>0.298304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>296118</td>\n",
       "      <td>0.248960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>296119</td>\n",
       "      <td>0.555442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>296120</td>\n",
       "      <td>0.903564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>296121</td>\n",
       "      <td>0.600111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>296122</td>\n",
       "      <td>0.663724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>296123</td>\n",
       "      <td>0.926631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>296124</td>\n",
       "      <td>0.747160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>296125</td>\n",
       "      <td>0.568546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>296126</td>\n",
       "      <td>0.699796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>296127</td>\n",
       "      <td>0.774550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>296128</td>\n",
       "      <td>0.299085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>296129</td>\n",
       "      <td>0.816123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>296130</td>\n",
       "      <td>0.453003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>296131</td>\n",
       "      <td>0.479374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>296132</td>\n",
       "      <td>0.760356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>296133</td>\n",
       "      <td>0.842354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208353</th>\n",
       "      <td>504457</td>\n",
       "      <td>0.621860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208354</th>\n",
       "      <td>504458</td>\n",
       "      <td>0.828934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208355</th>\n",
       "      <td>504459</td>\n",
       "      <td>0.233790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208356</th>\n",
       "      <td>504460</td>\n",
       "      <td>0.744223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208357</th>\n",
       "      <td>504461</td>\n",
       "      <td>0.306685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208358</th>\n",
       "      <td>504462</td>\n",
       "      <td>0.506527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208359</th>\n",
       "      <td>504463</td>\n",
       "      <td>0.749055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208360</th>\n",
       "      <td>504464</td>\n",
       "      <td>0.456411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208361</th>\n",
       "      <td>504465</td>\n",
       "      <td>0.526705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208362</th>\n",
       "      <td>504466</td>\n",
       "      <td>0.964390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208363</th>\n",
       "      <td>504467</td>\n",
       "      <td>0.143498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208364</th>\n",
       "      <td>504468</td>\n",
       "      <td>0.445888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208365</th>\n",
       "      <td>504469</td>\n",
       "      <td>0.754549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208366</th>\n",
       "      <td>504470</td>\n",
       "      <td>0.353833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208367</th>\n",
       "      <td>504471</td>\n",
       "      <td>0.926395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208368</th>\n",
       "      <td>504472</td>\n",
       "      <td>0.559863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208369</th>\n",
       "      <td>504473</td>\n",
       "      <td>0.365997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208370</th>\n",
       "      <td>504474</td>\n",
       "      <td>0.594842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208371</th>\n",
       "      <td>504475</td>\n",
       "      <td>0.663350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208372</th>\n",
       "      <td>504476</td>\n",
       "      <td>0.575475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208373</th>\n",
       "      <td>504477</td>\n",
       "      <td>0.507171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208374</th>\n",
       "      <td>504478</td>\n",
       "      <td>0.622024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208375</th>\n",
       "      <td>504479</td>\n",
       "      <td>0.721512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208376</th>\n",
       "      <td>504480</td>\n",
       "      <td>0.646728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208377</th>\n",
       "      <td>504481</td>\n",
       "      <td>0.297903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208378</th>\n",
       "      <td>504482</td>\n",
       "      <td>0.243570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208379</th>\n",
       "      <td>504483</td>\n",
       "      <td>0.880149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208380</th>\n",
       "      <td>504484</td>\n",
       "      <td>0.697675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208381</th>\n",
       "      <td>504485</td>\n",
       "      <td>0.566002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208382</th>\n",
       "      <td>504486</td>\n",
       "      <td>0.756418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208383 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     proba\n",
       "0       296104  0.802402\n",
       "1       296105  0.668149\n",
       "2       296106  0.691602\n",
       "3       296107  0.147286\n",
       "4       296108  0.511898\n",
       "5       296109  0.798943\n",
       "6       296110  0.909317\n",
       "7       296111  0.489411\n",
       "8       296112  0.280552\n",
       "9       296113  0.800137\n",
       "10      296114  0.239736\n",
       "11      296115  0.697259\n",
       "12      296116  0.411563\n",
       "13      296117  0.298304\n",
       "14      296118  0.248960\n",
       "15      296119  0.555442\n",
       "16      296120  0.903564\n",
       "17      296121  0.600111\n",
       "18      296122  0.663724\n",
       "19      296123  0.926631\n",
       "20      296124  0.747160\n",
       "21      296125  0.568546\n",
       "22      296126  0.699796\n",
       "23      296127  0.774550\n",
       "24      296128  0.299085\n",
       "25      296129  0.816123\n",
       "26      296130  0.453003\n",
       "27      296131  0.479374\n",
       "28      296132  0.760356\n",
       "29      296133  0.842354\n",
       "...        ...       ...\n",
       "208353  504457  0.621860\n",
       "208354  504458  0.828934\n",
       "208355  504459  0.233790\n",
       "208356  504460  0.744223\n",
       "208357  504461  0.306685\n",
       "208358  504462  0.506527\n",
       "208359  504463  0.749055\n",
       "208360  504464  0.456411\n",
       "208361  504465  0.526705\n",
       "208362  504466  0.964390\n",
       "208363  504467  0.143498\n",
       "208364  504468  0.445888\n",
       "208365  504469  0.754549\n",
       "208366  504470  0.353833\n",
       "208367  504471  0.926395\n",
       "208368  504472  0.559863\n",
       "208369  504473  0.365997\n",
       "208370  504474  0.594842\n",
       "208371  504475  0.663350\n",
       "208372  504476  0.575475\n",
       "208373  504477  0.507171\n",
       "208374  504478  0.622024\n",
       "208375  504479  0.721512\n",
       "208376  504480  0.646728\n",
       "208377  504481  0.297903\n",
       "208378  504482  0.243570\n",
       "208379  504483  0.880149\n",
       "208380  504484  0.697675\n",
       "208381  504485  0.566002\n",
       "208382  504486  0.756418\n",
       "\n",
       "[208383 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-0915cc70fab7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-0915cc70fab7>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    test_image =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "def get_layer_outputs():\n",
    "    test_image = \n",
    "    outputs    = [layer.output for layer in model.layers]          # all layer outputs\n",
    "    comp_graph = [K.function([model.input]+ [K.learning_phase()], [output]) for output in outputs]  # evaluation functions\n",
    "\n",
    "    # Testing\n",
    "    layer_outputs_list = [op([test_image, 1.]) for op in comp_graph]\n",
    "    layer_outputs = []\n",
    "\n",
    "    for layer_output in layer_outputs_list:\n",
    "        print(layer_output[0][0].shape, end='\\n-------------------\\n')\n",
    "        layer_outputs.append(layer_output[0][0])\n",
    "\n",
    "    return layer_outputs\n",
    "\n",
    "def plot_layer_outputs(layer_number):    \n",
    "    layer_outputs = get_layer_outputs()\n",
    "\n",
    "    x_max = layer_outputs[layer_number].shape[0]\n",
    "    y_max = layer_outputs[layer_number].shape[1]\n",
    "    n     = layer_outputs[layer_number].shape[2]\n",
    "\n",
    "    L = []\n",
    "    for i in range(n):\n",
    "        L.append(np.zeros((x_max, y_max)))\n",
    "\n",
    "    for i in range(n):\n",
    "        for x in range(x_max):\n",
    "            for y in range(y_max):\n",
    "                L[i][x][y] = layer_outputs[layer_number][x][y][i]\n",
    "\n",
    "\n",
    "    for img in L:\n",
    "        plt.figure()\n",
    "        plt.imshow(img, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
